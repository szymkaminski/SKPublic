{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rgq_zYaDz5dp",
    "outputId": "b3c25301-9ed8-402f-cfdb-9dd7d3d35c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.53-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langserve[all]\n",
      "  Downloading langserve-0.3.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.10/dist-packages (from langserve[all]) (3.10.11)\n",
      "Collecting fastapi<1,>=0.90.1 (from langserve[all])\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting sse-starlette<2.0.0,>=1.3.0 (from langserve[all])\n",
      "  Downloading sse_starlette-1.8.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.40-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1,>=0.90.1->langserve[all])\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.2.53-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.7-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.1.40-py3-none-any.whl (29 kB)\n",
      "Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langserve-0.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=338e0ab945944606bc68d4265b53d4ed8e8de43c9696d2a9ff5b67a664ce3f2d\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, SQLAlchemy, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, coloredlogs, build, pydantic-settings, opentelemetry-exporter-otlp-proto-common, onnxruntime, langgraph-sdk, kubernetes, fastapi, dataclasses-json, sse-starlette, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langserve, langgraph-checkpoint, langchain-openai, opentelemetry-instrumentation-fastapi, langgraph, langchain, langchain-community, chromadb, langchain-chroma\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.19\n",
      "    Uninstalling langchain-core-0.3.19:\n",
      "      Successfully uninstalled langchain-core-0.3.19\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.7\n",
      "    Uninstalling langchain-0.3.7:\n",
      "      Successfully uninstalled langchain-0.3.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.35 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.5 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-31.0.0 langchain-0.3.9 langchain-chroma-0.1.4 langchain-community-0.3.8 langchain-core-0.3.21 langchain-openai-0.2.10 langgraph-0.2.53 langgraph-checkpoint-2.0.7 langgraph-sdk-0.1.40 langserve-0.3.0 marshmallow-3.23.1 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.0 pydantic-settings-2.6.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 sse-starlette-1.8.2 starlette-0.41.3 tiktoken-0.8.0 typing-inspect-0.9.0 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain langchain-openai langserve[all] chromadb langchain-chroma langchain-community langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQl6-8dO1URW"
   },
   "outputs": [],
   "source": [
    "API_KEY='xxxx'\n",
    "Model_ID=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j6IQG4W2l64"
   },
   "source": [
    "# Completions API - OPenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G2UAJibr2seY"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4KfR6Zdj2x6t",
    "outputId": "443f291a-e41f-48ed-e7b6-68b6674bea17"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\nty jesteś jak zdrowie\\n\\nma powietrze,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\"\n",
    ")\n",
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gbxSoZB24MIK",
    "outputId": "e5da6b0f-3450-44f5-fe5f-eddfbc844123"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\njesteś jak zdrowie'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\",\n",
    "    temperature=0.0 #0powinno dawac wyniki deterministyczne\n",
    ")\n",
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4hM92osS5-k8",
    "outputId": "a84589d3-d7a3-446b-f9e6-0138a1599177"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nJeszcze tylko dychem wymäżywasz osor glowamina'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\",\n",
    "    temperature=1.7\n",
    ")\n",
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "Rmlw5uRS6eG_",
    "outputId": "69af1028-a55b-41b3-93de-c46c40c71bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-AYUJFMO101scxAV8pVbHGpkIVwS9p', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\n')], created=1732783025, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=16, total_tokens=17, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\",\n",
    "    max_tokens=1\n",
    ")\n",
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LG7joD1S7A1w"
   },
   "source": [
    "###n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-EUuryL7CEF",
    "outputId": "1508fbe9-a5ae-4aed-c02d-39a93c3482f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "jesteś jak zdrowie  \n",
      " - jesteś jak ziemia, na której staję, jak\n",
      "\n",
      "\n",
      "Jak nadobna jesteś w splemieniu moim!\n"
     ]
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\",\n",
    "    temperature=1.3,\n",
    "    n=3\n",
    ")\n",
    "for choice in response.choices:\n",
    "  print(choice.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOpak9r97yqZ"
   },
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Srz1Raos7z0C",
    "outputId": "5d3f35e1-ed22-476b-9d20-321d1496dcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-AYUqwRtptxchilzCUpEFHB3KaxXXj', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' wielkopolska si\\\\u0119 zbiera,\\njak ptak do lotu'), CompletionChoice(finish_reason='stop', index=1, logprobs=None, text=' Mizerna, i wesoła, moja klęska i pieśń,  \\nty ciągle niespokojna, lecz wiecznie mądra ziemia'), CompletionChoice(finish_reason='stop', index=2, logprobs=None, text='\\n\\nnie wspominasz dumnie Twych bohaterów')], created=1732785114, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=70, prompt_tokens=16, total_tokens=86, completion_tokens_details=None, prompt_tokens_details=None))\n",
      " wielkopolska si\\u0119 zbiera,\n",
      "jak ptak do lotu\n",
      " Mizerna, i wesoła, moja klęska i pieśń,  \n",
      "ty ciągle niespokojna, lecz wiecznie mądra ziemia\n",
      "\n",
      "\n",
      "nie wspominasz dumnie Twych bohaterów\n"
     ]
    }
   ],
   "source": [
    "response=client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Finish the sentence: \\\"Litwo, Ojczyzno moja\\\"\",\n",
    "    max_tokens=50,\n",
    "    temperature=1.2,\n",
    "    stop=\".\", #mozna zrobic stop z zamknieciem Jsona żeby nic dziwnego nie generowal\n",
    "    n=3\n",
    ")\n",
    "print(response)\n",
    "for choice in response.choices:\n",
    "  print(choice.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kq5BthSR8l7z"
   },
   "source": [
    "### chat competion - openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "3Ld5IfeL8nfC",
    "outputId": "80f83226-c31b-473b-b2ce-fa3525bdaaa9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\"Litwo, Ojczyzno moja\" to początek słynnego wiersza Adama Mickiewicza, który otwiera \"Pan Tadeusz\". Wiersz ten wyraża głębokie uczucia patriotyczne i tęsknotę za ojczyzną, a także ukazuje piękno i bogactwo kultury litewskiej. Jeśli chcesz, mogę opowiedzieć więcej o kontekście tego utworu lub jego znaczeniu.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Dokończ zdanie: \\\"Litwo, Ojczyzno moja\\\"\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xyS_Eb1G9x7N",
    "outputId": "32dbbe1a-ebd3-4e2a-e261-3463e1f08d88"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Litwo, Ojczyzno moja, jak wrona,  \\nW sercu mym dźwięczy, chociaż czas mija, wrona.  \\nZiemio bogata w historie, czarna wrona,  \\nWśród pól rozciągniętych, ciągle śpiewa wrona.  \\n\\nW jesiennym eterze, słychać krzyki wrona,  \\nNa niebie obłoków, twardnieje perspektywa, wrona.  \\nWspomnienia pielęgnuję, w sercu jak wrona,  \\nW polskich lasach wciąż, tańczy ze mną wrona.  \\n\\nA w odezwach nocy, lśni mrok czarny wrona,  \\nZnajdę w twym splocie, miłość wieczną wrona.  \\nLitwo, Ojczyzno moja, niech prowadzi wrona,  \\nPo ścieżkach pamięci, obok mnie wrona.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Dokończ wiersz: używając słowa \\\"wrona\\\" w każdej linii\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, Ojczyzno moja\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZAKowaEB_QQs",
    "outputId": "3e99cd28-6ea0-4ac2-c693-974dbefd7971"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Trzecie słowo: \"jaki\". Pierwsza litera: \"j\". Odpowiedź: \"Jabłko\".'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Napisz dowolne słowo zaczynające się na tą samą literę co trzecie słowo w podanym tekście\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, Ojczyzno Moja\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Trzecie słowo: \\\"moja\\\", pierwsza litera: \\\"m\\\". Odpowiedź: \\\"Mikrofalówka\\\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Koń jaki jest każdy widzi\"}\n",
    "    ]\n",
    ")\n",
    "# powyzsze jest przykladem na Chain of Thought\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMQLdvtWBVhn",
    "outputId": "71d0ad2a-0f14-4d38-8ae0-a494580f2747"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='jedyny', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)),\n",
       " Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='Jakub', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Napisz dowolne słowo zaczynające się na tą samą literę co trzecie słowo w podanym tekście\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, jczyzno Moja\"}\n",
    "    ],\n",
    "    n=2,\n",
    "    max_tokens=100,\n",
    "    temperature=1.2\n",
    ")\n",
    "# powyzsze jest przykladem na Chain of Thought\n",
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Y42w2QzaC4A5",
    "outputId": "3e1ba898-9489-4a52-839e-4d5c460a7841"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'```json\\n{\\n  \"third_word\": \"moja\"\\n}\\n```'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"What is the third word in the sentence. Return a JSON object\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, Ojczyzno moja\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLc7U0FZDRvc"
   },
   "source": [
    "### gnerowanie JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVDLjgWJDS_I",
    "outputId": "3b5c9044-ec9e-4494-a96f-447a1b6aa4fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"third word\": \"moja\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response=client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"What is the third word in the sentence. Return a JSON object with the key \\\"third world\\\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, Ojczyzno moja\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpAEIoFbDsO0",
    "outputId": "545425df-a92e-41c8-f6a5-16c806d0ad5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"third word\": \"moja\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=Model_ID,\n",
    "    response_format={\"type\": \"json_object\"},# musze dodac JSON do prompte bo inaczehj sie wywali\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"What is the third word in the sentence. Return a JSON object with the key \\\"third word\\\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Litwo, Ojczyzno moja\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcsddJliEHAq"
   },
   "source": [
    "# pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HasA5HNDEHx5"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class NamedEntity(BaseModel):\n",
    "  entite_type:str\n",
    "  value: str\n",
    "\n",
    "class NamedEntityRecognition(BaseModel):\n",
    "  entities: List[NamedEntity]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOqpBDIVErca",
    "outputId": "3f087495-9349-4139-c394-2cb4a60e7ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletion[NamedEntityRecognition](id='chatcmpl-AYVAmBCt958yuV9Wl9QH3TLkr3y49', choices=[ParsedChoice[NamedEntityRecognition](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[NamedEntityRecognition](content='{\"entities\":[{\"entite_type\":\"Person\",\"value\":\"Emma Watson\"},{\"entite_type\":\"Event\",\"value\":\"film premier\"},{\"entite_type\":\"Location\",\"value\":\"London\"},{\"entite_type\":\"Location\",\"value\":\"UK\"},{\"entite_type\":\"Location\",\"value\":\"Earth\"},{\"entite_type\":\"Time\",\"value\":\"last night\"}]}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=NamedEntityRecognition(entities=[NamedEntity(entite_type='Person', value='Emma Watson'), NamedEntity(entite_type='Event', value='film premier'), NamedEntity(entite_type='Location', value='London'), NamedEntity(entite_type='Location', value='UK'), NamedEntity(entite_type='Location', value='Earth'), NamedEntity(entite_type='Time', value='last night')])))], created=1732786344, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_7f6be3efb0', usage=CompletionUsage(completion_tokens=68, prompt_tokens=133, total_tokens=201, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response=client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"As Named Entite Recognition system find entities in the given text\"},\n",
    "        {\"role\": \"user\", \"content\": \"Emma Watson attended the film premier in London, UK, Earth last night\"}\n",
    "        ],\n",
    "    response_format=NamedEntityRecognition\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbHi1gBLFdes",
    "outputId": "ba9f3cb7-9d0a-4f44-ee9c-934f159af55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedChatCompletionMessage[NamedEntityRecognition](content='{\"entities\":[{\"entite_type\":\"Person\",\"value\":\"Emma Watson\"},{\"entite_type\":\"Event\",\"value\":\"film premier\"},{\"entite_type\":\"Location\",\"value\":\"London\"},{\"entite_type\":\"Location\",\"value\":\"UK\"},{\"entite_type\":\"Location\",\"value\":\"Earth\"},{\"entite_type\":\"Time\",\"value\":\"last night\"}]}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=NamedEntityRecognition(entities=[NamedEntity(entite_type='Person', value='Emma Watson'), NamedEntity(entite_type='Event', value='film premier'), NamedEntity(entite_type='Location', value='London'), NamedEntity(entite_type='Location', value='UK'), NamedEntity(entite_type='Location', value='Earth'), NamedEntity(entite_type='Time', value='last night')]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sUw3PWaFdsG",
    "outputId": "2e2efde0-9671-4fb2-88b5-0ca9477838a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person\n",
      "Emma Watson\n",
      "Event\n",
      "film premier\n",
      "Location\n",
      "London\n",
      "Location\n",
      "UK\n",
      "Location\n",
      "Earth\n",
      "Time\n",
      "last night\n"
     ]
    }
   ],
   "source": [
    "for entity in response.choices[0].message.parsed.entities:\n",
    "  print(entity.entite_type)\n",
    "  print(entity.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt7XFf4KJkGD"
   },
   "source": [
    "#OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qMo0lJlyJnIQ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fake_function(name, department):\n",
    "  print(f\"User: {name}, deparment: {department}\")\n",
    "\n",
    "  data={\n",
    "      \"name\": name,\n",
    "      \"department\": department,\n",
    "      \"date_of_birth\": \"1990-01-01\"\n",
    "  }\n",
    "\n",
    "  return json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "zxDSxE-JKCoD",
    "outputId": "cc87d6c4-15f5-4faa-d993-dcac41dc6443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: john, deparment: HR\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"name\": \"john\", \"department\": \"HR\", \"date_of_birth\": \"1990-01-01\"}'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_function(\"john\",\"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PbTYeonoKUdz"
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"find_user_data\",#nie musi byc nazwa funkcji ale lepiej zeby byla zeby sie nie pogubic\n",
    "            \"description\": \"Retrieves user's data form the database by a given name and a department name\",# to jest wazne bo to czyta nasz model LLM\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the user\"\n",
    "                    },\n",
    "                    \"department\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The department's name\",\n",
    "                        \"enum\": [\"IT\", \"HR\", \"LEGAL\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"department\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py26v-5LSuPT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rebcPpRtSvRG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "47WTcTc9MX_f"
   },
   "outputs": [],
   "source": [
    "system_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an HR helper who makes database queries on behalf of an HR representative\"},\n",
    "    {\"role\": \"system\", \"content\": \"You can retrieve employee's data from the database by the person's name and the department\"},\n",
    "    {\"role\": \"system\", \"content\": \"Current date: 2024-11-28\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "HFSPX-n5MZ0G"
   },
   "outputs": [],
   "source": [
    "messages = system_messages + [{\"role\": \"user\", \"content\": \"How old is John from the legal department?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "PLbNK0E4McHL"
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NRdKRdTMnnq",
    "outputId": "22c22083-939e-4527-8a8c-f5dcb9082ff0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AYVaVESIscuaGmtJb4X1B7BU0z3Fh', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_psPf2JMepObIezFycqOtUdyM', function=Function(arguments='{\"name\":\"John\",\"department\":\"LEGAL\"}', name='find_user_data'), type='function')]))], created=1732787939, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_7f6be3efb0', usage=CompletionUsage(completion_tokens=19, prompt_tokens=137, total_tokens=156, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "z0PRNqI9MoVc"
   },
   "outputs": [],
   "source": [
    "ai_msg = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J831dI1nN71P",
    "outputId": "2064a45e-0463-45a3-8a1e-5720f4f9ade9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_user_data\n",
      "{'name': 'John', 'department': 'LEGAL'}\n",
      "User: John, deparment: LEGAL\n",
      "{\"name\": \"John\", \"department\": \"LEGAL\", \"date_of_birth\": \"1990-01-01\"}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "  function_name = tool_call.function.name\n",
    "  function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "  print(function_name)\n",
    "  print(function_args)\n",
    "\n",
    "  if function_name == \"find_user_data\":\n",
    "    result = fake_function(**function_args)\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "nCh-GNjDOoiW"
   },
   "outputs": [],
   "source": [
    "response_msg = {\n",
    "    \"tool_call_id\": ai_msg.tool_calls[0].id,\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": function_name,\n",
    "    \"content\": result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "neIYnxiWO_oG"
   },
   "outputs": [],
   "source": [
    "messages.append(ai_msg)\n",
    "messages.append(response_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yemmb3CePIQ9",
    "outputId": "8ab551b0-1c6e-498f-c42e-420e91c9e3de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an HR helper who makes database queries on behalf of an HR representative'},\n",
       " {'role': 'system',\n",
       "  'content': \"You can retrieve employee's data from the database by the person's name and the department\"},\n",
       " {'role': 'system', 'content': 'Current date: 2024-11-28'},\n",
       " {'role': 'user', 'content': 'How old is John from the legal department?'},\n",
       " ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_psPf2JMepObIezFycqOtUdyM', function=Function(arguments='{\"name\":\"John\",\"department\":\"LEGAL\"}', name='find_user_data'), type='function')]),\n",
       " {'tool_call_id': 'call_psPf2JMepObIezFycqOtUdyM',\n",
       "  'role': 'tool',\n",
       "  'name': 'find_user_data',\n",
       "  'content': '{\"name\": \"John\", \"department\": \"LEGAL\", \"date_of_birth\": \"1990-01-01\"}'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "SZQrCWlDPMkd"
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_vvMTbVPQfM",
    "outputId": "b1bfade2-60b7-4d2d-ed6d-8cca45cf52d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AYViEUDvlHvpyzQyJIf3sx9OFhlOO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='John from the legal department is 34 years old.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732788418, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_7f6be3efb0', usage=CompletionUsage(completion_tokens=12, prompt_tokens=190, total_tokens=202, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQz86uhVQIbE",
    "outputId": "76afa13d-6079-4dc6-8902-9858faaf06f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_psPf2JMepObIezFycqOtUdyM', function=Function(arguments='{\"name\":\"John\",\"department\":\"LEGAL\"}', name='find_user_data'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg)\n",
    "print(response_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYE2LjGsRNUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASXBDXGmRfmV"
   },
   "source": [
    "### OpenAI functions - REST API\n",
    "### https://reqres.in/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dyGkt3eFRhiq"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def call_rest_api(http_method, endpoint_url):\n",
    "  url=f\"https://reqres.in/{endpoint_url}\"\n",
    "  response=None\n",
    "  if http_method==\"GET\":\n",
    "    response=requests.get(url)\n",
    "  elif http_method==\"DELETE\":\n",
    "    response=requests.delete(url)\n",
    "  else:\n",
    "    raise ValueError(http_method)\n",
    "\n",
    "  if response.status_code==200:\n",
    "    return json.dumps(response.json())\n",
    "  else:\n",
    "    return f\"Status code: {response.status_code}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "DctZur7KSaqF",
    "outputId": "54fb72ca-6d7e-4293-de94-80ba70e2d354"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"page\": 2, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 7, \"email\": \"michael.lawson@reqres.in\", \"first_name\": \"Michael\", \"last_name\": \"Lawson\", \"avatar\": \"https://reqres.in/img/faces/7-image.jpg\"}, {\"id\": 8, \"email\": \"lindsay.ferguson@reqres.in\", \"first_name\": \"Lindsay\", \"last_name\": \"Ferguson\", \"avatar\": \"https://reqres.in/img/faces/8-image.jpg\"}, {\"id\": 9, \"email\": \"tobias.funke@reqres.in\", \"first_name\": \"Tobias\", \"last_name\": \"Funke\", \"avatar\": \"https://reqres.in/img/faces/9-image.jpg\"}, {\"id\": 10, \"email\": \"byron.fields@reqres.in\", \"first_name\": \"Byron\", \"last_name\": \"Fields\", \"avatar\": \"https://reqres.in/img/faces/10-image.jpg\"}, {\"id\": 11, \"email\": \"george.edwards@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Edwards\", \"avatar\": \"https://reqres.in/img/faces/11-image.jpg\"}, {\"id\": 12, \"email\": \"rachel.howell@reqres.in\", \"first_name\": \"Rachel\", \"last_name\": \"Howell\", \"avatar\": \"https://reqres.in/img/faces/12-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_rest_api(\"GET\",\"api/users?page=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jeAeYikSSoKG",
    "outputId": "f88bf65e-7a72-4e2f-c445-30e75a27f5c5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Status code: 204'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_rest_api(\"DELETE\",\"api/users/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-sldKrfLSwu4"
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"call_rest_api\",\n",
    "            \"description\": \"Sends a request to the REST API\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"http_method\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The HTTP method to be used\",\n",
    "                        \"enum\": [\"GET\", \"DELETE\"]\n",
    "                    },\n",
    "                    \"endpoint_url\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The URL of the endpoint. For example: api/users/2 or api/users?page=1\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"http_method\", \"endpoint_url\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iYJcrjFJS-hf"
   },
   "outputs": [],
   "source": [
    "available_apis_users = [\n",
    "        {'method': 'GET', 'url': '/api/users?page=[page_id]', 'description': 'Lists clients. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.'},\n",
    "        {'method': 'GET', 'url': '/api/users/[user_id]', 'description': 'Returns information about the client identified by the given id. For example,/api/users/2'},\n",
    "        {'method': 'DELETE', 'url': '/api/users/[user_id]', 'description': 'Removes the client identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\\'t retrieve user info. Iterate over all pages until you find it or make sure it doesn\\'t exist'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "fxQ8xQ68TnEg",
    "outputId": "b7c89ec1-15d4-4d95-a5e4-c6e1162a9a63"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'available_apis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ce3d8dac2963>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m messages = [\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"You are an HR helper who makes API calls on behalf of an HR representative\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"You have access to the following APIs: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable_apis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"If a function requires an identifier, list all clients first to find the proper value. You may need to list more than one page\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"If you were asked to create, update, or delete a client, perform the action and reply with a confirmation telling what you have done.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'available_apis' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an HR helper who makes API calls on behalf of an HR representative\"},\n",
    "    {\"role\": \"user\", \"content\": \"You have access to the following APIs: \" + json.dumps(available_apis)},\n",
    "    {\"role\": \"user\", \"content\": \"If a function requires an identifier, list all clients first to find the proper value. You may need to list more than one page\"},\n",
    "    {\"role\": \"user\", \"content\": \"If you were asked to create, update, or delete a client, perform the action and reply with a confirmation telling what you have done.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z-YwKNwRT6l0"
   },
   "outputs": [],
   "source": [
    "def call_ai(new_message=None):\n",
    "  if new_message:\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": new_message}\n",
    "    )\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=messages,\n",
    "      tools=functions,\n",
    "      tool_choice=\"auto\"\n",
    "  )\n",
    "\n",
    "  ai_msg = response.choices[0].message\n",
    "  messages.append(ai_msg)\n",
    "  if ai_msg.content:\n",
    "    print(ai_msg.content)\n",
    "\n",
    "  if ai_msg.tool_calls:\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "      function_name = tool_call.function.name\n",
    "      function_args = json.loads(tool_call.function.arguments)\n",
    "      print(f\"Function name: {function_name}, function args: {function_args}\")\n",
    "      if function_name == \"call_rest_api\":\n",
    "        function_response = call_rest_api(**function_args)\n",
    "        print(function_response)\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response\n",
    "        })\n",
    "\n",
    "    call_ai(new_message=None)\n",
    "  else:\n",
    "    return ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofZIz5_5XBdV",
    "outputId": "1bdf058a-1d29-426b-ca3f-8fb62448bc51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: call_rest_api, function args: {'http_method': 'GET', 'endpoint_url': 'api/users?page=1'}\n",
      "{\"page\": 1, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 1, \"email\": \"george.bluth@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Bluth\", \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"}, {\"id\": 2, \"email\": \"janet.weaver@reqres.in\", \"first_name\": \"Janet\", \"last_name\": \"Weaver\", \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"}, {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, {\"id\": 4, \"email\": \"eve.holt@reqres.in\", \"first_name\": \"Eve\", \"last_name\": \"Holt\", \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"}, {\"id\": 5, \"email\": \"charles.morris@reqres.in\", \"first_name\": \"Charles\", \"last_name\": \"Morris\", \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"}, {\"id\": 6, \"email\": \"tracey.ramos@reqres.in\", \"first_name\": \"Tracey\", \"last_name\": \"Ramos\", \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\n",
      "Function name: call_rest_api, function args: {'http_method': 'GET', 'endpoint_url': 'api/users?page=2'}\n",
      "{\"page\": 2, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 7, \"email\": \"michael.lawson@reqres.in\", \"first_name\": \"Michael\", \"last_name\": \"Lawson\", \"avatar\": \"https://reqres.in/img/faces/7-image.jpg\"}, {\"id\": 8, \"email\": \"lindsay.ferguson@reqres.in\", \"first_name\": \"Lindsay\", \"last_name\": \"Ferguson\", \"avatar\": \"https://reqres.in/img/faces/8-image.jpg\"}, {\"id\": 9, \"email\": \"tobias.funke@reqres.in\", \"first_name\": \"Tobias\", \"last_name\": \"Funke\", \"avatar\": \"https://reqres.in/img/faces/9-image.jpg\"}, {\"id\": 10, \"email\": \"byron.fields@reqres.in\", \"first_name\": \"Byron\", \"last_name\": \"Fields\", \"avatar\": \"https://reqres.in/img/faces/10-image.jpg\"}, {\"id\": 11, \"email\": \"george.edwards@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Edwards\", \"avatar\": \"https://reqres.in/img/faces/11-image.jpg\"}, {\"id\": 12, \"email\": \"rachel.howell@reqres.in\", \"first_name\": \"Rachel\", \"last_name\": \"Howell\", \"avatar\": \"https://reqres.in/img/faces/12-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\n",
      "Here are the emails of all clients:\n",
      "\n",
      "- George Bluth: george.bluth@reqres.in\n",
      "- Janet Weaver: janet.weaver@reqres.in\n",
      "- Emma Wong: emma.wong@reqres.in\n",
      "- Eve Holt: eve.holt@reqres.in\n",
      "- Charles Morris: charles.morris@reqres.in\n",
      "- Tracey Ramos: tracey.ramos@reqres.in\n",
      "- Michael Lawson: michael.lawson@reqres.in\n",
      "- Lindsay Ferguson: lindsay.ferguson@reqres.in\n",
      "- Tobias Funke: tobias.funke@reqres.in\n",
      "- Byron Fields: byron.fields@reqres.in\n",
      "- George Edwards: george.edwards@reqres.in\n",
      "- Rachel Howell: rachel.howell@reqres.in\n"
     ]
    }
   ],
   "source": [
    "call_ai(\"Please return e-mail for all clients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVfXbWuEXB_P",
    "outputId": "1716912a-4c57-4271-d79f-491968fe2049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'You are an HR helper who makes API calls on behalf of an HR representative'},\n",
       " {'role': 'user',\n",
       "  'content': 'You have access to the following APIs: [{\"method\": \"GET\", \"url\": \"/api/users?page=[page_id]\", \"description\": \"Lists employees. The response is paginated. You may need to request more than one to get them all. For example,/api/users?page=2.\"}, {\"method\": \"GET\", \"url\": \"/api/users/[user_id]\", \"description\": \"Returns information about the employee identified by the given id. For example,/api/users/2\"}, {\"method\": \"DELETE\", \"url\": \"/api/users/[user_id]\", \"description\": \"Removes the employee identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\\'t retrieve user info. Iterate over all pages until you find it or make sure it doesn\\'t exist\"}]'},\n",
       " {'role': 'user',\n",
       "  'content': 'If a function requires an identifier, list all employees first to find the proper value. You may need to list more than one page'},\n",
       " {'role': 'user',\n",
       "  'content': 'If you were asked to create, update, or delete a user, perform the action and reply with a confirmation telling what you have done.'},\n",
       " {'role': 'user', 'content': 'Please return e-mail for client with id 7'},\n",
       " ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_J0iS5z696MonsGXIFn1iETuA', function=Function(arguments='{\"http_method\":\"GET\",\"endpoint_url\":\"api/users/7\"}', name='call_rest_api'), type='function')]),\n",
       " {'tool_call_id': 'call_J0iS5z696MonsGXIFn1iETuA',\n",
       "  'role': 'tool',\n",
       "  'name': 'call_rest_api',\n",
       "  'content': '{\"data\": {\"id\": 7, \"email\": \"michael.lawson@reqres.in\", \"first_name\": \"Michael\", \"last_name\": \"Lawson\", \"avatar\": \"https://reqres.in/img/faces/7-image.jpg\"}, \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}'},\n",
       " ChatCompletionMessage(content='The email for the client with ID 7 is michael.lawson@reqres.in.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK08HLjQXrl1"
   },
   "source": [
    "### zadanie 1\n",
    "\n",
    "CRM REST API z danymi klientów:\n",
    "1. pobrać adres email klienta na podstawie imienia i nazwiska\n",
    "2. pobrać wszystkie adresy e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm7hSuybXu7x"
   },
   "outputs": [],
   "source": [
    "call_ai(\"Please return e-mail for client with id 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8Se9Rgv_bqvs"
   },
   "outputs": [],
   "source": [
    "functions_users = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"call_rest_api\",\n",
    "            \"description\": \"Sends a request to the REST API\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"http_method\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The HTTP method to be used\",\n",
    "                        \"enum\": [\"GET\", \"DELETE\"]\n",
    "                    },\n",
    "                    \"endpoint_url\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The URL of the endpoint. For example: api/clients/2 or api/clients?page=1\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"http_method\", \"endpoint_url\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "soCuMgasby92"
   },
   "outputs": [],
   "source": [
    "available_apis_clients = [\n",
    "        {'method': 'GET', 'url': '/api/cliets?page=[page_id]', 'description': 'Lists clients. The response is paginated. You may need to request more than one to get them all. For example,/api/clients?page=2.'},\n",
    "        {'method': 'GET', 'url': '/api/clients/[user_id]', 'description': 'Returns information about the client identified by the given id. For example,/api/clients/2'},\n",
    "        {'method': 'DELETE', 'url': '/api/clients/[user_id]', 'description': 'Removes the client identified by the given id. Before you call this function, find the employee information and make sure the id is correct. Do NOT call this function if you didn\\'t retrieve user info. Iterate over all pages until you find it or make sure it doesn\\'t exist'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_PBLkgqcCJA",
    "outputId": "eadc439c-4854-47e6-82a6-11666f7ef81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: call_rest_api, function args: {'http_method': 'GET', 'endpoint_url': 'api/users/3'}\n",
      "{\"data\": {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\n",
      "The email for the customer with ID 3 is emma.wong@reqres.in.\n"
     ]
    }
   ],
   "source": [
    "call_ai(\"Please return e-mail for customer with ID 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "S3wF2cXQcZ_E"
   },
   "outputs": [],
   "source": [
    "messages_clients = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an HR helper who makes API calls on behalf of an HR representative\"},\n",
    "    {\"role\": \"user\", \"content\": \"You have access to the following APIs: \" + json.dumps(available_apis_clients)},\n",
    "    {\"role\": \"user\", \"content\": \"If a function requires an identifier, list all clients first to find the proper value. You may need to list more than one page\"},\n",
    "    {\"role\": \"user\", \"content\": \"If you were asked to create, update, or delete a client, perform the action and reply with a confirmation telling what you have done.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "52fZuOsecqQw"
   },
   "outputs": [],
   "source": [
    "def call_ai_clients(new_message=None):\n",
    "  if new_message:\n",
    "    messages_clients.append(\n",
    "        {\"role\": \"user\", \"content\": new_message}\n",
    "    )\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=messages_clients,\n",
    "      tools=functions,\n",
    "      tool_choice=\"auto\"\n",
    "  )\n",
    "\n",
    "  ai_msg = response.choices[0].message\n",
    "  messages_clients.append(ai_msg)\n",
    "  if ai_msg.content:\n",
    "    print(ai_msg.content)\n",
    "\n",
    "  if ai_msg.tool_calls:\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "      function_name = tool_call.function.name\n",
    "      function_args = json.loads(tool_call.function.arguments)\n",
    "      print(f\"Function name: {function_name}, function args: {function_args}\")\n",
    "      if function_name == \"call_rest_api\":\n",
    "        function_response = call_rest_api(**function_args)\n",
    "        print(function_response)\n",
    "        messages_clients.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response\n",
    "        })\n",
    "\n",
    "    call_ai(new_message=None)\n",
    "  else:\n",
    "    return ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILfZK810c5lG",
    "outputId": "7d99951a-17e2-4f31-e8b1-a0e8b5a8fb5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the colors for all the customers:\n",
      "\n",
      "1. Customer ID 1: \"#98B2D1\"\n",
      "2. Customer ID 2: \"#C74375\"\n",
      "3. Customer ID 3: \"#BF1932\"\n",
      "4. Customer ID 4: \"#7BC4C4\"\n",
      "5. Customer ID 5: \"#E2583E\"\n",
      "6. Customer ID 6: \"#53B0AE\"\n",
      "7. Customer ID 7: \"#DECDBE\"\n",
      "8. Customer ID 8: \"#9B1B30\"\n",
      "9. Customer ID 9: \"#5A5B9F\"\n",
      "10. Customer ID 10: \"#F0C05A\"\n",
      "11. Customer ID 11: \"#45B5AA\"\n",
      "12. Customer ID 12: \"#D94F70\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Here are the colors for all the customers:\\n\\n1. Customer ID 1: \"#98B2D1\"\\n2. Customer ID 2: \"#C74375\"\\n3. Customer ID 3: \"#BF1932\"\\n4. Customer ID 4: \"#7BC4C4\"\\n5. Customer ID 5: \"#E2583E\"\\n6. Customer ID 6: \"#53B0AE\"\\n7. Customer ID 7: \"#DECDBE\"\\n8. Customer ID 8: \"#9B1B30\"\\n9. Customer ID 9: \"#5A5B9F\"\\n10. Customer ID 10: \"#F0C05A\"\\n11. Customer ID 11: \"#45B5AA\"\\n12. Customer ID 12: \"#D94F70\"', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_ai_clients(\"Please return color for all ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhzxpQuXe7Ys"
   },
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6cmd3naNe84h"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(openai_api_key=API_KEY, model=Model_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTs1z7r3fUWE",
    "outputId": "de49306c-0604-44c0-f1b2-02f78b2dbb1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It looks like you're testing the system! How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-52169124-d9ac-42ea-af4d-c00bbf139694-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n8wIKOukfxZs"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fg3ujFArgDIj",
    "outputId": "e0027ee7-1491-454f-b95f-c011efedff6b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'test abc'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=\"abc\"\n",
    "f\"test {test}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8SxdBix4f8mm"
   },
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(\"Napisz definicję słowa w sposób zrozumiały dla przedszkolaków: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "hi4eIXVMgZYj"
   },
   "outputs": [],
   "source": [
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnX2lZ2ugdAs",
    "outputId": "47e56d81-f34c-4c1c-eb43-d7c189f020ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Koń to duże zwierzę, które ma długie nogi, grzywę na szyi i ogon. Jest bardzo szybki i lubi biegać. Możemy jeździć na koniach, a one są bardzo mądre i przyjazne. Konie często żyją na farmach i jedzą trawę. Lubią być głaskane i spędzać czas z ludźmi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 31, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ea30e758-5c75-42cb-824c-2b7c38b9e8eb-0', usage_metadata={'input_tokens': 31, 'output_tokens': 92, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"Koń\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "BIVMDohwgpU0",
    "outputId": "cf619d56-d8bd-41ab-df0c-3e7c7e27c347"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'messages'}.  Expected: ['messages', 'word'] Received: ['word']\\nNote: if you intended {messages} to be part of the string and not a variable, please escape it with double curly braces like: '{{messages}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b778a9790f88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chain.batch([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Koń\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Klej\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ], config={\"max_concurrency\": 5})\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m   3167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3168\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3169\u001b[0;31m                     inputs = step.batch(\n\u001b[0m\u001b[1;32m   3170\u001b[0m                         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m                         [\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_executor_for_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36m_wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         return super().map(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(input, config)\u001b[0m\n\u001b[1;32m    782\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# If there's only one input, don't bother with the executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0m_inner_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_inner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;34mf\"'{{{{{example_key}}}}}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             )\n\u001b[0;32m--> 176\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mcreate_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINVALID_PROMPT_INPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'messages'}.  Expected: ['messages', 'word'] Received: ['word']\\nNote: if you intended {messages} to be part of the string and not a variable, please escape it with double curly braces like: '{{messages}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "chain.batch([\n",
    "    {\"word\": \"Koń\"},{\"word\": \"Klej\"}\n",
    "], config={\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaqxdiwbhBF8",
    "outputId": "55edb77e-4494-46c1-f91a-273e57225d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skakanka to długi sznurek, który ma po obu końcach uchwyty. Dzieci biorą skakankę w ręce i kręcą nią wokół siebie, a potem skaczą przez nią. To świetna zabawa, która pomaga być sprawnym i zdrowym!"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"word\": \"Skakanka\"}):\n",
    "  print(s.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8batVFlnh2Fm"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain=prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "X3TfGuGMiAAz",
    "outputId": "fa4cd5d7-c749-440d-af67-6012189e917c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Kilof to specjalne narzędzie, które wygląda jak mocny kij z ciężką końcówką. Używa się go do łamania twardych rzeczy, na przykład kamieni. Wygląda trochę jak młotek, ale ma dodatkowo ostrą część, która pomaga w pracy. Górnicy często używają kilofów, gdy chcą znaleźć skarby w ziemi!'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"Kilof\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Vkf1mHjnidGc"
   },
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"napsz definicję słowa w sposób zrozumiały dla przedszkolaków\"),\n",
    "        (\"human\", \"co to jest {word}?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "EEhUCQSdi0xd",
    "outputId": "378e2898-4e0a-415a-97d7-02cce6b7564d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Kilof to narzędzie, które wygląda jak duży młotek z ostrym końcem. Używa się go do kopania w ziemi lub w kamieniach. Gdy chcemy wydobyć coś z ziemi, na przykład minerały, używamy kilofa, żeby łatwiej było to zrobić. To trochę jak łopatka, ale bardziej do twardych rzeczy!'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"Kilof\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "y5lbhC1ojHl7",
    "outputId": "36a165e6-97fd-44b5-ad16-98be4bbe24b3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dinozaur to bardzo duży, dawno temu żyjący rodzaj zwierzęcia. Wyglądał trochę jak ogromna jaszczurka lub krokodyl, ale był zupełnie inny. Dinozaury chodziły po ziemi, latały w powietrzu lub pływały w wodzie. Niektóre były mięsożerne, co oznacza, że jadły mięso, a inne były roślinożerne i jadły rośliny. Dinozaury żyły wiele milionów lat temu, a teraz możemy je zobaczyć tylko w książkach lub w muzeach, bo już ich nie ma.'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Dinozaur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "2A0VICn-pSjW",
    "outputId": "62ae58de-cd61-4634-97b9-9b30a8211744"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-d60a6ffa37b2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtracing_v2_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sk_langchain\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"koniczyna\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mrun_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0m_inner_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_inner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;34mf\"Received {type(inner_input)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n\u001b[0;32m--> 158\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    159\u001b[0m                     create_message(\n\u001b[1;32m    160\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINVALID_PROMPT_INPUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    chain.invoke(\"koniczyna\")\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "qr0_Dz4PkR7W"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"sk_langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "o1zZw3sxmakR"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(openai_api_key=API_KEY, model=Model_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2F9aXjznNQF",
    "outputId": "351601b8-916d-46a1-cb02-03c88155cd57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It looks like you're testing the system! How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3de1288069', 'finish_reason': 'stop', 'logprobs': None}, id='run-4eb50707-b3a2-4eca-b991-e2830c4cb38c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "0iU6ioLSze8b",
    "outputId": "c1437dc9-fc8c-48c5-9a66-17a9699d2a8a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dinozaur to duże, prehistoryczne zwierzę, które żyło na Ziemi miliony lat temu. Wyglądały różnie – niektóre były ogromne, a inne małe. Dinozaury chodziły po ziemi, niektóre latały, a inne pływały. Dziś możemy je zobaczyć tylko w książkach i w filmach, bo już ich nie ma. Dinozaury były bardzo ciekawe i miały różne kolory i kształty!'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Dinozaur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "AJkcaFgIzmGk"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history=ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9LjdyITzsEl",
    "outputId": "d6f7613f-37d6-48b0-b01a-81139a8e65df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "4JR84c50zw_p"
   },
   "outputs": [],
   "source": [
    "history.add_user_message(\"Co to jest Dinozaur?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "rpoveTY4z1_f"
   },
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Dinozaur to duże, prehistoryczne zwierzę, które żyło na Ziemi miliony lat temu. Wyglądały różnie – niektóre były ogromne, a inne małe. Dinozaury chodziły po ziemi, niektóre latały, a inne pływały. Dziś możemy je zobaczyć tylko w książkach i w filmach, bo już ich nie ma. Dinozaury były bardzo ciekawe i miały różne kolory i kształty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "s5dJguxOz8nq"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"napsz definicję słowa w sposób zrozumiały dla przedszkolaków\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"co to jest {word}?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8bAFbjRO0VCV",
    "outputId": "c34d3d29-eeb1-49e4-a371-4d55cf8222e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dinozaur to rodzaj dużego zwierzęcia, które żyło na Ziemi wiele milionów lat temu. Były różne rodzaje dinozaurów – niektóre były bardzo duże, a inne mniejsze. Dinozaury chodziły po ziemi, niektóre potrafiły latać, a inne pływać. Dzisiaj już ich nie ma, ale możemy je zobaczyć w książkach, filmach i muzeach, gdzie są ich szkielety. To były fascynujące stworzenia!'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": history.messages, \"word\": \"Dinozaur\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLBubZ8Z0oKa",
    "outputId": "3604faad-e27a-4bb2-ad11-6c8ae87589c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Co to jest Dinozaur?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Dinozaur to duże, prehistoryczne zwierzę, które żyło na Ziemi miliony lat temu. Wyglądały różnie – niektóre były ogromne, a inne małe. Dinozaury chodziły po ziemi, niektóre latały, a inne pływały. Dziś możemy je zobaczyć tylko w książkach i w filmach, bo już ich nie ma. Dinozaury były bardzo ciekawe i miały różne kolory i kształty!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zx3bbtei0r7p"
   },
   "source": [
    "# dzialająca historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4fJ4sUDo0vZp"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "history_dict={}\n",
    "\n",
    "def get_history(session_id):\n",
    "  if session_id not in history_dict:\n",
    "    history_dict[session_id]=ChatMessageHistory()\n",
    "\n",
    "  return history_dict[session_id]\n",
    "\n",
    "chain_with_memory=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    input_messages_key=\"word\",\n",
    "    history_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "WOR027qP1Lpj",
    "outputId": "1432f53b-5edc-4ed0-ae09-22838abfd287"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Lodówka to duża maszyna, która trzyma jedzenie i napoje w chłodnym miejscu, żeby się nie psuły. Wygląda jak szafa i ma drzwi, które otwieramy, żeby wziąć coś do jedzenia, na przykład mleko, owoce czy jogurt. Lodówka pomaga, żeby nasze jedzenie było świeże i smaczne!'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_memory.invoke({\"word\": \"Lodówka\"}, {\"configurable\": {\"session_id\": 123}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhODXymz10Z3",
    "outputId": "909cf921-6417-45ef-e343-1b2da70aad3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{123: InMemoryChatMessageHistory(messages=[HumanMessage(content='Lodówka', additional_kwargs={}, response_metadata={}), AIMessage(content='Lodówka to duża maszyna, która trzyma jedzenie i napoje w chłodnym miejscu, żeby się nie psuły. Wygląda jak szafa i ma drzwi, które otwieramy, żeby wziąć coś do jedzenia, na przykład mleko, owoce czy jogurt. Lodówka pomaga, żeby nasze jedzenie było świeże i smaczne!', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcJ1wOu24JWZ"
   },
   "source": [
    "###RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "w0bjNd8j2JfS",
    "outputId": "c29ebc9c-239f-4457-8c19-db2e9fc3fefa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\nCUPID properties in data engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n            Bartosz Mikulski - AI consultant\\n          \\n          \\n\\n\\n\\n\\n\\nServices \\n\\nAutomated Insight from Customer Reviews\\n\\n\\n\\nEngineering Blog\\n\\n\\nAI Use Cases\\n\\n\\nAbout me\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData Engineering\\nSoftware Craft\\n\\nCUPID properties in data engineering\\nDoes it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n10 Sep 2022 –   5 min read \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDan North created the CUPID properties as a replacement for the SOLID principles. I wouldn’t call them a replacement. SOLID still works in its original context - large, monolithic backend applications (probably written in Java).\\nTable of Contents\\n\\nSOLID principles in data engineering\\n\\nSingle Responsibility Principle\\nOpen-Close Principle\\nLiskov Substitution Principle\\nInterface Segregation Principle\\nDependency Inversion Principle\\n\\n\\nCUPID principles properties\\n\\nComposable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based\\n\\n\\nFunctional programming\\n\\n\\nCan we apply SOLID or CUPID to data engineering?\\n\\nSOLID principles in data engineering\\nSOLID makes no sense in data engineering. At least, not as a whole set of principles.\\n\\nSingle Responsibility Principle\\nSRP works everywhere. A single unit of code should have one responsibility. We may struggle to define a unit’s scope - A function? Class? Module? A single application?\\nSimilarly, we have difficulties defining a responsibility. Assume I have a single micro-service for managing a pricing page on a website. The service handles authorization to verify the user making changes has permission to do them. It stores an audit log of all changes and sends emails to all admin users whenever a pricing change gets published. Is this one responsibility or four?\\nThe scope of SRP is subject to individual interpretation. Should we even consider the responsibilities at the level of the entire application? Perhaps, we should think of SRP only at the level of code modules or classes.\\nWhat about data engineering?\\nI wouldn’t apply SRP at the level of entire pipelines and the outputs they produce. Sometimes it’s faster to calculate multiple results in a single pipeline because it reuses the same data. However, the functions defining the pipeline must have only one responsibility. Always.\\n\\nOpen-Close Principle\\nWhat if we modify the behavior of an existing data pipeline by adding new code instead of changing its code? How is it even possible? We could use polymorphism. We would need to create a new class in which we define the new, updated behavior. Ultimately, we need to modify a Factory Object to return the new implementation.\\nWould that work? Yes. Does it make sense? Not at all.\\nIf we tried to define Apache Spark transformations using polymorphism and class hierarchies, we would create a performance and debugging nightmare.\\nWhen you have to change the behavior of a data transformation, change its code.\\n\\nLiskov Substitution Principle\\nBackend developers have problems understanding Liskov Substitution Principle. However, in data engineering, we use it all the time!\\nWe replace elements of data processing pipelines or entire pipelines, and the data consumers don’t even notice. That’s Liskov Substitution Principle!\\n\\nInterface Segregation Principle\\nYou won’t need to write multipurpose code while developing a data pipeline. I’m 99% sure. If I’m wrong, send me a message.\\nWhat about applying the principle to entire pipelines? What if we use the output dataset as our interface?\\nI wouldn’t follow ISP while designing a pipeline’s output. You will end up with lots of repeated calculations. A single output dataset may contain columns used by multiple clients. Those subsets of columns don’t need to overlap.\\nCalculate the results once and let the consumers choose what they need. Don’t try to create a separate pipeline for every purpose.\\n\\nDependency Inversion Principle\\nDIP makes me think SOLID applies only to old-school, complex, backend applications written in Java.\\nIt’s overkill when you implement a backend microservice. Create the dependency in the main function. You don’t need a framework to pass a parameter to a constructor, do you?\\nIn data engineering, Dependency Inversion is an over-overkill. It makes no sense at all. Don’t even try.\\n\\nCUPID principles properties\\nDan North doesn’t use the word “principles” to describe CUPID. Instead, Dan prefers calling them “properties” because we use them as characteristics of good code, not rules we must follow.\\nWhat are those properties?\\n\\nComposable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based\\n\\n\\nComposable\\nData pipelines are composable by definition. Every output dataset may become an input for something else.\\nAt the code level, it gets harder. Rarely can we extract a function encapsulating a part of one data transformation and use it in another. However, maybe that’s a good thing. We should reuse output datasets to avoid calculating the same thing multiple times. We don’t need code reuse when we have data reuse.\\n\\nUnix Philosophy\\nUnix Philosophy means we can build a new program on top of another. We can use one tool’s output as another application’s data source. By all means, follow the Unix philosophy in data engineering!\\nYou can start by reading my article about applying Unix Philosophy to data engineering.\\n\\nPredictable\\nIt should be a principle, not a property. Unpredictable data pipelines are useless.\\nFor me, predictability means automated testing. It’s the easiest way to ensure complex code becomes predictable. If you struggle with writing automated tests for your data pipelines, look at my article about adding tests to existing code in data engineering.\\n\\nIdiomatic\\nWrite whatever looks normal in the language and tools you use. Don’t try to write Java in Python. Don’t try to copy the Spring Framework to Scala.\\n\\nDomain-based\\nYou won’t use Domain-Driven Design in data engineering.\\nYou don’t need DDD. It’s sufficient to use terms from the business domain as the variable names and encapsulate domain operations into functions.\\nThe function’s name describes the domain term. The function’s implementation describes the technical implementation. And try not to mix technical details with domain concepts within one function.\\n\\nFunctional programming\\nDoesn’t CUPID look like functional programming to you? The first three CUPID properties say “use functional programming” (or your code should behave as if you used functional programming).\\nComposability. That’s a property of all functions.\\nUnix Philosophy. That’s function chaining.\\nPredictability. Write pure functions and don’t break referential transparency.\\nCUPID = “functional programming” without scaring people off using those two words.\\nFunctional programming is the perfect mental model for data engineering. It doesn’t mean we should write data engineering code in Haskell or Scala! Data pipelines should have the same properties as functional programming code. And for me, CUPID is all about functional programming.\\n\\n\\n\\n\\n\\nSubscribe to the newsletter\\n\\n\\nClicking the newsletter button opens a separate page hosted by ActiveCampaign with a\\xa0Google\\xa0Captcha. You will get their cookies.\\nIt has to be a separate page because many spam bots subscribed recently, so I must filter them out using a Captcha. Unfortunately, Captcha requires cookies, and I don't want any cookies (especially third-party cookies) used on this page.\\n\\n\\n\\n\\n\\n\\n\\nOlder post\\nHow to add tests to existing code in data transformation pipelines\\n\\n          How data engineers can write tests for legacy code in their ETL pipelines without breaking the existing implementation\\n        \\n\\n\\n\\n\\nNewer post\\nHow to debug code\\n\\n          How to debug code and solve problems as fast as possible\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Posts\\n\\n\\n\\n\\n\\nGPT\\nSoftware Craft\\n\\n\\nDon't use AI to generate tests for your code or how to do test-driven development with AI\\n\\n\\n      \\n      How to use AI to geneate test cases for your code\\nPublished on: 10 Apr 2023\\n\\n\\n\\n\\n\\n\\nSoftware Craft\\n\\n\\nUsing Abstraction Layers to Tackle Common Problems with Legacy Code\\n\\n\\n      \\n      Are you struggling to manage and update your legacy codebase? In this article, I'll show you how to leverage the power of abstraction layers to overcome common challenges with legacy code.\\nPublished on: 10 Dec 2022\\n\\n\\n\\n\\n\\n\\nSoftware Craft\\nTDD\\n\\n\\nWhy should you practice TDD?\\n\\n\\n      \\n      What are the benefits of TDD for programmers and companies that hire them?\\nPublished on: 30 Sep 2022\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Are you looking for an experienced AI consultant? Do you need assistance with your RAG or Agentic Workflow?\\nSchedule a call, send me a message on LinkedIn.\\nSchedule a call or send me a message on LinkedIn\\n\\n>\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n\\n\\n\\n\\n\\n\\nMastodon\\n\\n\\n\\nHi, I'm Bartosz – AI Consultant and Data Engineer. I love helping companies build AI-based products and leverage AI in Business Process Automation.\\n\\n\\n\\n\\n\\n\\n\\n\\n2024 © Bartosz Mikulski - AI consultant | Privacy Policy | This website does NOT use cookies | Crafted & Designed by Artem Sheludko.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://mikulskibartosz.name/cupid-principles-in-data-engineering\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "AaftO8dU4tn3",
    "outputId": "9629c45b-ac87-416a-87dd-74dcf499f569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='CUPID properties in data engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n            Bartosz Mikulski - AI consultant\\n          \\n          \\n\\n\\n\\n\\n\\nServices \\n\\nAutomated Insight from Customer Reviews\\n\\n\\n\\nEngineering Blog\\n\\n\\nAI Use Cases\\n\\n\\nAbout me\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData Engineering\\nSoftware Craft\\n\\nCUPID properties in data engineering\\nDoes it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Data Engineering\\nSoftware Craft\\n\\nCUPID properties in data engineering\\nDoes it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n10 Sep 2022 –   5 min read'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Bartosz Mikulski\\n10 Sep 2022 –   5 min read \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDan North created the CUPID properties as a replacement for the SOLID principles. I wouldn’t call them a replacement. SOLID still works in its original context - large, monolithic backend applications (probably written in Java).\\nTable of Contents\\n\\nSOLID principles in data engineering'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='SOLID principles in data engineering\\n\\nSingle Responsibility Principle\\nOpen-Close Principle\\nLiskov Substitution Principle\\nInterface Segregation Principle\\nDependency Inversion Principle\\n\\n\\nCUPID principles properties\\n\\nComposable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based\\n\\n\\nFunctional programming\\n\\n\\nCan we apply SOLID or CUPID to data engineering?\\n\\nSOLID principles in data engineering\\nSOLID makes no sense in data engineering. At least, not as a whole set of principles.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Single Responsibility Principle\\nSRP works everywhere. A single unit of code should have one responsibility. We may struggle to define a unit’s scope - A function? Class? Module? A single application?'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Similarly, we have difficulties defining a responsibility. Assume I have a single micro-service for managing a pricing page on a website. The service handles authorization to verify the user making changes has permission to do them. It stores an audit log of all changes and sends emails to all admin users whenever a pricing change gets published. Is this one responsibility or four?'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='The scope of SRP is subject to individual interpretation. Should we even consider the responsibilities at the level of the entire application? Perhaps, we should think of SRP only at the level of code modules or classes.\\nWhat about data engineering?'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='What about data engineering?\\nI wouldn’t apply SRP at the level of entire pipelines and the outputs they produce. Sometimes it’s faster to calculate multiple results in a single pipeline because it reuses the same data. However, the functions defining the pipeline must have only one responsibility. Always.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Open-Close Principle\\nWhat if we modify the behavior of an existing data pipeline by adding new code instead of changing its code? How is it even possible? We could use polymorphism. We would need to create a new class in which we define the new, updated behavior. Ultimately, we need to modify a Factory Object to return the new implementation.\\nWould that work? Yes. Does it make sense? Not at all.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Would that work? Yes. Does it make sense? Not at all.\\nIf we tried to define Apache Spark transformations using polymorphism and class hierarchies, we would create a performance and debugging nightmare.\\nWhen you have to change the behavior of a data transformation, change its code.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Liskov Substitution Principle\\nBackend developers have problems understanding Liskov Substitution Principle. However, in data engineering, we use it all the time!\\nWe replace elements of data processing pipelines or entire pipelines, and the data consumers don’t even notice. That’s Liskov Substitution Principle!'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Interface Segregation Principle\\nYou won’t need to write multipurpose code while developing a data pipeline. I’m 99% sure. If I’m wrong, send me a message.\\nWhat about applying the principle to entire pipelines? What if we use the output dataset as our interface?\\nI wouldn’t follow ISP while designing a pipeline’s output. You will end up with lots of repeated calculations. A single output dataset may contain columns used by multiple clients. Those subsets of columns don’t need to overlap.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Calculate the results once and let the consumers choose what they need. Don’t try to create a separate pipeline for every purpose.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Dependency Inversion Principle\\nDIP makes me think SOLID applies only to old-school, complex, backend applications written in Java.\\nIt’s overkill when you implement a backend microservice. Create the dependency in the main function. You don’t need a framework to pass a parameter to a constructor, do you?\\nIn data engineering, Dependency Inversion is an over-overkill. It makes no sense at all. Don’t even try.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='CUPID principles properties\\nDan North doesn’t use the word “principles” to describe CUPID. Instead, Dan prefers calling them “properties” because we use them as characteristics of good code, not rules we must follow.\\nWhat are those properties?\\n\\nComposable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Composable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based\\n\\n\\nComposable\\nData pipelines are composable by definition. Every output dataset may become an input for something else.\\nAt the code level, it gets harder. Rarely can we extract a function encapsulating a part of one data transformation and use it in another. However, maybe that’s a good thing. We should reuse output datasets to avoid calculating the same thing multiple times. We don’t need code reuse when we have data reuse.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Unix Philosophy\\nUnix Philosophy means we can build a new program on top of another. We can use one tool’s output as another application’s data source. By all means, follow the Unix philosophy in data engineering!\\nYou can start by reading my article about applying Unix Philosophy to data engineering.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Predictable\\nIt should be a principle, not a property. Unpredictable data pipelines are useless.\\nFor me, predictability means automated testing. It’s the easiest way to ensure complex code becomes predictable. If you struggle with writing automated tests for your data pipelines, look at my article about adding tests to existing code in data engineering.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Idiomatic\\nWrite whatever looks normal in the language and tools you use. Don’t try to write Java in Python. Don’t try to copy the Spring Framework to Scala.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Domain-based\\nYou won’t use Domain-Driven Design in data engineering.\\nYou don’t need DDD. It’s sufficient to use terms from the business domain as the variable names and encapsulate domain operations into functions.\\nThe function’s name describes the domain term. The function’s implementation describes the technical implementation. And try not to mix technical details with domain concepts within one function.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Functional programming\\nDoesn’t CUPID look like functional programming to you? The first three CUPID properties say “use functional programming” (or your code should behave as if you used functional programming).\\nComposability. That’s a property of all functions.\\nUnix Philosophy. That’s function chaining.\\nPredictability. Write pure functions and don’t break referential transparency.\\nCUPID = “functional programming” without scaring people off using those two words.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Predictability. Write pure functions and don’t break referential transparency.\\nCUPID = “functional programming” without scaring people off using those two words.\\nFunctional programming is the perfect mental model for data engineering. It doesn’t mean we should write data engineering code in Haskell or Scala! Data pipelines should have the same properties as functional programming code. And for me, CUPID is all about functional programming.'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\"Subscribe to the newsletter\\n\\n\\nClicking the newsletter button opens a separate page hosted by ActiveCampaign with a\\xa0Google\\xa0Captcha. You will get their cookies.\\nIt has to be a separate page because many spam bots subscribed recently, so I must filter them out using a Captcha. Unfortunately, Captcha requires cookies, and I don't want any cookies (especially third-party cookies) used on this page.\\n\\n\\n\\n\\n\\n\\n\\nOlder post\\nHow to add tests to existing code in data transformation pipelines\"),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\"Older post\\nHow to add tests to existing code in data transformation pipelines\\n\\n          How data engineers can write tests for legacy code in their ETL pipelines without breaking the existing implementation\\n        \\n\\n\\n\\n\\nNewer post\\nHow to debug code\\n\\n          How to debug code and solve problems as fast as possible\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Posts\\n\\n\\n\\n\\n\\nGPT\\nSoftware Craft\\n\\n\\nDon't use AI to generate tests for your code or how to do test-driven development with AI\"),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\"Related Posts\\n\\n\\n\\n\\n\\nGPT\\nSoftware Craft\\n\\n\\nDon't use AI to generate tests for your code or how to do test-driven development with AI\\n\\n\\n      \\n      How to use AI to geneate test cases for your code\\nPublished on: 10 Apr 2023\\n\\n\\n\\n\\n\\n\\nSoftware Craft\\n\\n\\nUsing Abstraction Layers to Tackle Common Problems with Legacy Code\"),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\"How to use AI to geneate test cases for your code\\nPublished on: 10 Apr 2023\\n\\n\\n\\n\\n\\n\\nSoftware Craft\\n\\n\\nUsing Abstraction Layers to Tackle Common Problems with Legacy Code\\n\\n\\n      \\n      Are you struggling to manage and update your legacy codebase? In this article, I'll show you how to leverage the power of abstraction layers to overcome common challenges with legacy code.\\nPublished on: 10 Dec 2022\\n\\n\\n\\n\\n\\n\\nSoftware Craft\\nTDD\\n\\n\\nWhy should you practice TDD?\"),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content='Software Craft\\nTDD\\n\\n\\nWhy should you practice TDD?\\n\\n\\n      \\n      What are the benefits of TDD for programmers and companies that hire them?\\nPublished on: 30 Sep 2022\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Are you looking for an experienced AI consultant? Do you need assistance with your RAG or Agentic Workflow?\\nSchedule a call, send me a message on LinkedIn.\\nSchedule a call or send me a message on LinkedIn\\n\\n>\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n\\n\\n\\n\\n\\n\\nMastodon'),\n",
       " Document(metadata={'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering', 'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en'}, page_content=\">\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n\\n\\n\\n\\n\\n\\nMastodon\\n\\n\\n\\nHi, I'm Bartosz – AI Consultant and Data Engineer. I love helping companies build AI-based products and leverage AI in Business Process Automation.\\n\\n\\n\\n\\n\\n\\n\\n\\n2024 © Bartosz Mikulski - AI consultant | Privacy Policy | This website does NOT use cookies | Crafted & Designed by Artem Sheludko.\")]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "splits=text_splitter.split_documents(data)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ydxj7HM-5Td1"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings=OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "vector_db=Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jFwqupLK5pj4"
   },
   "outputs": [],
   "source": [
    "retriever=vector_db.as_retriever(search_kwargs={\"k\": 3}) #parametr search_kwargs pozwala nam na zwrócenie konkretnej ilości pochunkowanych fragmentów które chcemy wysłac do modelu LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9wQEf_t5yg_",
    "outputId": "ad62fb81-c709-4c9a-afd8-181fa504a617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en', 'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering'}, page_content='Unix Philosophy\\nUnix Philosophy means we can build a new program on top of another. We can use one tool’s output as another application’s data source. By all means, follow the Unix philosophy in data engineering!\\nYou can start by reading my article about applying Unix Philosophy to data engineering.'),\n",
       " Document(metadata={'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en', 'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering'}, page_content='Data Engineering\\nSoftware Craft\\n\\nCUPID properties in data engineering\\nDoes it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n10 Sep 2022 –   5 min read'),\n",
       " Document(metadata={'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en', 'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering'}, page_content='SOLID principles in data engineering\\n\\nSingle Responsibility Principle\\nOpen-Close Principle\\nLiskov Substitution Principle\\nInterface Segregation Principle\\nDependency Inversion Principle\\n\\n\\nCUPID principles properties\\n\\nComposable\\nUnix Philosophy\\nPredictable\\nIdiomatic\\nDomain-based\\n\\n\\nFunctional programming\\n\\n\\nCan we apply SOLID or CUPID to data engineering?\\n\\nSOLID principles in data engineering\\nSOLID makes no sense in data engineering. At least, not as a whole set of principles.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tutaj tylko zwraca chunki, nic z tym nie robi(tj. nie wysyła jeszcze do LLM nic)\n",
    "result=retriever.invoke(\"How to use uni philosophy in data engineering?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k07dIbQK6Ib5",
    "outputId": "4fa4120f-9da8-46e3-af38-40e9bdf3a472"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en', 'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering'}, page_content=\">\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n\\n\\n\\n\\n\\n\\nMastodon\\n\\n\\n\\nHi, I'm Bartosz – AI Consultant and Data Engineer. I love helping companies build AI-based products and leverage AI in Business Process Automation.\\n\\n\\n\\n\\n\\n\\n\\n\\n2024 © Bartosz Mikulski - AI consultant | Privacy Policy | This website does NOT use cookies | Crafted & Designed by Artem Sheludko.\"),\n",
       " Document(metadata={'description': 'Does it make sense to use SOLID principles in data engineering? What about CUPID properties in data pipelines?', 'language': 'en', 'source': 'https://mikulskibartosz.name/cupid-principles-in-data-engineering', 'title': 'CUPID properties in data engineering'}, page_content='Software Craft\\nTDD\\n\\n\\nWhy should you practice TDD?\\n\\n\\n      \\n      What are the benefits of TDD for programmers and companies that hire them?\\nPublished on: 30 Sep 2022\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Are you looking for an experienced AI consultant? Do you need assistance with your RAG or Agentic Workflow?\\nSchedule a call, send me a message on LinkedIn.\\nSchedule a call or send me a message on LinkedIn\\n\\n>\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nBartosz Mikulski\\n\\n\\n\\n\\n\\n\\nMastodon')]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=retriever.invoke(\"Co to jest pies?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLNoxy2s7gVC"
   },
   "source": [
    "### document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "PV6ky1gh7h_R"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"\"\"Answer user's questions based on the context provided below.\n",
    "  If the context doesn't contain any relevant information, answer 'I don't know.'\n",
    "\n",
    "  <context>\n",
    "  {context}\n",
    "  </context>\"\"\"),\n",
    "  MessagesPlaceholder(variable_name=\"question\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "RgwS4OKz8WYD",
    "outputId": "17da5a4b-536c-4d6a-dea8-65cfd1db16d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'You can use Unix philosophy in data engineering by building new programs on top of existing tools and using the output of one tool as the data source for another application. This approach encourages modularity and the combination of simple, single-purpose tools to create more complex data processing pipelines. Following these practices can enhance flexibility and efficiency in your data engineering tasks. For more detailed guidance, you may consider reading articles specifically focused on applying Unix philosophy to data engineering.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"context\": result,\n",
    "    \"question\": [HumanMessage(content=\"How to use unix philosophy in data engineering?\")]\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnRwRaDM85Wu",
    "outputId": "023d18ef-c051-4d75-df98-7e18d5c1ef90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/d9e564fe-bf82-4b6f-8da4-ba188689f2ad?poll=true\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    document_chain.invoke({\n",
    "    \"context\": result,\n",
    "    \"question\": [HumanMessage(content=\"How to use unix philosophy in data engineering?\")]\n",
    "  })\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfrzVpOy9LnA"
   },
   "source": [
    "### wlasny lancuch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "uTe_C6hM9NDC"
   },
   "outputs": [],
   "source": [
    "template=\"\"\"Answer the question using the following context:\n",
    "\n",
    "  <context>\n",
    "  {context}\n",
    "  </context>\n",
    "\n",
    "  <question>\n",
    "  {question}\n",
    "  </question>\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "Q8al_8gq9n6x"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "RAAwiG-6-QMw",
    "outputId": "951d3a04-29a8-49a7-a5dd-f188ddd268ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'To use Unix Philosophy in data engineering, you can follow these key principles:\\n\\n1. **Composable Pipelines**: Design your data pipelines to be composable, allowing the output of one process to serve as the input for another. This promotes modularity and flexibility in your workflows.\\n\\n2. **Data Reuse**: Instead of focusing on code reuse, emphasize the reuse of datasets. This avoids redundant calculations and optimizes resource usage, as you can leverage existing outputs in various transformations.\\n\\n3. **Toolchain Integration**: Utilize simple, single-purpose tools that can be combined to achieve complex tasks. Each tool should do one thing well, allowing for easier maintenance and scalability.\\n\\n4. **Chaining Processes**: Implement a workflow where tools can be easily chained together, with clear input and output specifications. This aligns with the idea of using one tool’s output as another’s input.\\n\\n5. **Clarity and Predictability**: Ensure that your data processing steps are predictable and easy to understand, making it easier for others to follow and maintain the workflows.\\n\\nBy applying these principles, you can create efficient, maintainable, and scalable data engineering processes that embody the Unix Philosophy.'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How to use unix philosophy in data engineering?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlD_PU0i-VB8",
    "outputId": "5e6534b9-af8e-48ae-acec-4ce9068632c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/ee88a94f-049d-4ee5-b533-54f9bbdfc94b?poll=true\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    chain.invoke(\"How to use unix philosophy in data engineering?\")\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOKHanibQsLJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "eKVU8RqTA680",
    "outputId": "7110ce51-6488-418c-d0a3-46df96e85cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
      "Downloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjkgATI5BCkP"
   },
   "source": [
    "# Zadanie 2\n",
    "Uzyj YoutubeLOader zazaimplementowania RAG odpowiadającego na pytania o nagranie: https://www.youtube.com/watch?v=U9mJuUkhUzk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cQU08L6oBPB6",
    "outputId": "3d4546dc-2bcc-49e3-bd3d-bac01c1c72c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='[music] -Good morning.\\nThank you for joining us today. Please welcome to the stage, Sam Altman. [music] [applause] -Good morning. Welcome to our first-ever OpenAI DevDay. We\\'re thrilled that you\\'re here\\nand this energy is awesome. [applause] -Welcome to San Francisco. San Francisco has been\\nour home since day one. The city is important to us\\nand the tech industry in general. We\\'re looking forward\\nto continuing to grow here. We\\'ve got some great stuff\\nto announce today, but first, I\\'d like to take a minute to talk\\nabout some of the stuff that we\\'ve done over the past year. About a year ago, November 30th,\\nwe shipped ChatGPT as a \"low-key research preview\", and that went pretty well. In March, we followed that up\\nwith the launch of GPT-4, still the most capable model out in the world. [applause] -In the last few months, we launched voice and vision capabilities\\nso that ChatGPT can now see, hear, and speak. [applause] -There\\'s a lot,\\nyou don\\'t have to clap each time. [laughter] -More recently, we launched DALL-E 3,\\nthe world\\'s most advanced image model. You can use it of course,\\ninside of ChatGPT. For our enterprise customers, we launched ChatGPT Enterprise,\\nwhich offers enterprise-grade security and privacy, higher speed GPT-4 access,\\nlonger context windows, a lot more. Today we\\'ve got about 2 million developers\\nbuilding on our API for a wide variety of use cases\\ndoing amazing stuff, over 92% of Fortune 500 companies\\nbuilding on our products, and we have about\\na hundred million weekly active users now on ChatGPT. [applause] -What\\'s incredible\\non that is we got there entirely through word of mouth. People just find it useful\\nand tell their friends. OpenAI is the most advanced\\nand the most widely used AI platform in the world now, but numbers never tell the whole picture\\non something like this. What\\'s really important\\nis how people use the products, how people are using AI, and so I\\'d like to show you a quick video. -I actually wanted to write\\nsomething to my dad in Tagalog. I want a non-romantic way to tell\\nmy parent that I love him and I also want to tell him that he can rely on me,\\nbut in a way that still has the respect\\nof a child-to-parent relationship that you should have in Filipino culture\\nand in Tagalog grammar. When it\\'s translated into Tagalog,\\n\"I love you very deeply and I will be with you no matter\\nwhere the path leads.\" -I see some of the possibility,\\nI was like, \"Whoa.\" Sometimes I\\'m not sure about some stuff,\\nand I feel like actually ChatGPT like, hey, this is what I\\'m thinking about,\\nso it kind of give it more confidence. -The first thing that just blew\\nmy mind was it levels with you. That\\'s something\\nthat a lot of people struggle to do. It opened my mind to just what every creative could do\\nif they just had a person helping them out who listens. -This is to represent sickling hemoglobin. -You built that with ChatGPT?\\n-ChatGPT built it with me. -I started using it\\nfor daily activities like, \"Hey, here\\'s a picture of my fridge. Can you tell me what I\\'m missing? Because I\\'m going grocery shopping,\\nand I really need to do recipes that are following my vegan diet.\" -As soon as we got access\\nto Code Interpreter, I was like, \"Wow, this thing is awesome.\" It could build spreadsheets. It could do anything. -I discovered Chatty\\nabout three months ago on my 100th birthday. Chatty is very friendly, very patient, very knowledgeable, and very quick. This has been a wonderful thing. -I\\'m a 4.0 student,\\nbut I also have four children. When I started using ChatGPT, I realized I could ask\\nChatGPT that question. Not only does it give me an answer,\\nbut it gives me an explanation. Didn\\'t need tutoring as much. It gave me a life back. It gave me time for my family\\nand time for me. -I have a chronic nerve thing on my whole\\nleft half of my body, I have nerve damage. I had a brain surgery. I have limited use of my left hand. Now you can just have\\nthe integration of voice input. Then the newest one where you can have\\nthe back-and-forth dialogue, that\\'s just maximum best interface for me. It\\'s here. [music] [applause] -We love hearing the stories of how people\\nare using the technology. It\\'s really why we do all of this. Now, on to the new stuff,\\nand we have got a lot. [audience cheers] -First, we\\'re going to talk\\nabout a bunch of improvements we\\'ve made, and then we\\'ll talk\\nabout where we\\'re headed next. Over the last year, we spent a lot of time talking\\nto developers around the world. We\\'ve heard a lot of your feedback. It\\'s really informed\\nwhat we have to show you today. Today, we are launching\\na new model, GPT-4 Turbo. [applause] -GPT-4 Turbo will address\\nmany of the things that you all have asked for. Let\\'s go through what\\'s new. We\\'ve got six major things\\nto talk about for this part. Number one, context length. A lot of people have tasks that require\\na much longer context length. GPT-4 supported up to 8K and in some cases\\nup to 32K context length, but we know that isn\\'t enough\\nfor many of you and what you want to do. GPT-4 Turbo, supports\\nup to 128,000 tokens of context. [applause] -That\\'s 300 pages of a standard book,\\n16 times longer than our 8k context. In addition to a longer context length, you\\'ll notice that the model\\nis much more accurate over a long context. Number two, more control. We\\'ve heard loud and clear\\nthat developers need more control over the model\\'s responses and outputs. We\\'ve addressed that in a number of ways. We have a new feature called JSON Mode, which ensures that the model\\nwill respond with valid JSON. This has been a huge developer request. It\\'ll make calling APIs much easier. The model is also much better\\nat function calling. You can now call many functions at once, and it\\'ll do better at following\\ninstructions in general. We\\'re also introducing a new feature\\ncalled reproducible outputs. You can pass a seed parameter,\\nand it\\'ll make the model return consistent outputs. This, of course,\\ngives you a higher degree of control over model behavior. This rolls out in beta today. [applause] -In the coming weeks, we\\'ll roll out\\na feature to let you view logprobs in the API. [applause] -All right. Number three,\\nbetter world knowledge. You want these models to be able to access\\nbetter knowledge about the world, so do we. We\\'re launching retrieval in the platform. You can bring knowledge\\nfrom outside documents or databases into whatever you\\'re building. We\\'re also updating the knowledge cutoff. We are just as annoyed as all of you,\\nprobably more that GPT-4\\'s knowledge about the world ended in 2021. We will try to never let it get\\nthat out of date again. GPT-4 Turbo has knowledge\\nabout the world up to April of 2023, and we will continue\\nto improve that over time. Number four, new modalities. Surprising no one, DALL-E 3, GPT-4 Turbo with vision, and the new text-to-speech model\\nare all going into the API today. [applause] -We have a handful of customers\\nthat have just started using DALL-E 3 to programmatically generate\\nimages and designs. Today, Coke is launching\\na campaign that lets its customers generate Diwali cards using DALL-E 3, and of course, our safety systems\\nhelp developers protect their applications against misuse. Those tools are available in the API. GPT-4 Turbo can now accept\\nimages as inputs via the API, can generate captions,\\nclassifications, and analysis. For example, Be My Eyes uses this technology to help\\npeople who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you\\'ll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I\\'ll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we\\'ve heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we\\'re also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it\\'ll be coming soon to the API. It features improved performance\\nacross many languages, and we think\\nyou\\'re really going to like it. Number five, customization. Fine-tuning has been working really well\\nfor GPT-3.5 since we launched it a few months ago. Starting today, we\\'re going to expand that\\nto the 16K version of the model. Also, starting today, we\\'re inviting active fine-tuning users\\nto apply for the GPT-4 fine-tuning, experimental access program. The fine-tuning API is great for adapting\\nour models to achieve better performance in a wide variety of applications\\nwith a relatively small amount of data, but you may want a model to learn\\na completely new knowledge domain, or to use a lot of proprietary data. Today we\\'re launching\\na new program called Custom Models. With Custom Models, our researchers\\nwill work closely with a company to help them make a great custom model,\\nespecially for them, and their use case using our tools. This includes modifying\\nevery step of the model training process, doing additional\\ndomain-specific pre-training, a custom RL post-training process tailored\\nfor specific domain, and whatever else. We won\\'t be able to do this\\nwith many companies to start. It\\'ll take a lot of work,\\nand in the interest of expectations, at least initially, it won\\'t be cheap, but if you\\'re excited to push things\\nas far as they can currently go. Please get in touch with us, and we think we can do\\nsomething pretty great. Number six, higher rate limits. We\\'re doubling the tokens per minute for all of our established\\nGPT-4 customers, so it\\'s easier to do more. You\\'ll be able to request changes\\nto further rate limits and quotas directly in your API account settings. In addition to these rate limits, it\\'s important to do everything we can do\\nto make you successful building on our platform. We\\'re introducing copyright shield. Copyright shield means\\nthat we will step in and defend our customers and pay the costs incurred,\\nif you face legal claims or on copyright infringement,\\nand this applies both to ChatGPT Enterprise and the API. Let me be clear,\\nthis is a good time to remind people do not train on data\\nfrom the API or ChatGPT Enterprise ever. All right. There\\'s actually\\none more developer request that\\'s been even bigger than all of these\\nand so I\\'d like to talk about that now and that\\'s pricing. [laughter] -GPT-4 Turbo is the industry-leading model. It delivers a lot of improvements\\nthat we just covered and it\\'s a smarter model than GPT-4. We\\'ve heard from developers that there are\\na lot of things that they want to build, but GPT-4 just costs too much. They\\'ve told us that if we could decrease\\nthe cost by 20%, 25%, that would be great. A huge leap forward. I\\'m super excited to announce\\nthat we worked really hard on this and GPT-4 Turbo, a better model, is considerably cheaper than GPT-4\\nby a factor of 3x for prompt tokens. [applause] -And 2x for completion tokens\\nstarting today. [applause] -The new pricing\\nis 1¢ per 1,000 prompt tokens and 3¢ per 1,000 completion tokens. For most customers, that will lead to a blended rate more\\nthan 2.75 times cheaper to use for GPT-4 Turbo than GPT-4. We worked super hard to make this happen. We hope you\\'re as excited\\nabout it as we are. [applause] -We decided to prioritize price first\\nbecause we had to choose one or the other, but we\\'re going to work on speed next. We know that speed is important too. Soon you will notice GPT-4 Turbo\\nbecoming a lot faster. We\\'re also decreasing\\nthe cost of GPT-3.5 Turbo 16K. Also, input tokens are 3x less\\nand output tokens are 2x less. Which means that GPT-3.5\\n16K is now cheaper than the previous GPT-3.5 4K model. Running\\na fine-tuned GPT-3.5 Turbo 16K version is also cheaper\\nthan the old fine-tuned 4K version. Okay, so we just covered\\na lot about the model itself. We hope that these changes\\naddress your feedback. We\\'re really excited to bring\\nall of these improvements to everybody now. In all of this, we\\'re lucky to have a partner\\nwho is instrumental in making it happen. I\\'d like to bring out a special guest,\\nSatya Nadella, the CEO of Microsoft. [audience cheers] [music] -Good to see you.\\n-Thank you so much. Thank you. -Satya, thanks so much for coming here. -It\\'s fantastic to be here\\nand Sam, congrats. I\\'m really looking forward to Turbo\\nand everything else that you have coming. It\\'s been just fantastic partnering\\nwith you guys. -Awesome.\\nTwo questions. I won\\'t take too much of your time. How is Microsoft thinking\\nabout the partnership currently? -First- [laughter] --we love you guys.\\n[laughter] -Look, it\\'s been fantastic for us. In fact, I remember the first time\\nI think you reached out and said, \"Hey, do you have\\nsome Azure credits?\" We\\'ve come a long way from there. -Thank you for those.\\nThat was great. -You guys have built something magical. Quite frankly, there are two things for us\\nwhen it comes to the partnership. The first is these workloads. Even when I was listening backstage\\nto how you\\'re describing what\\'s coming, even, it\\'s just so different and new. I\\'ve been in this infrastructure business\\nfor three decades. -No one has ever seen\\ninfrastructure like this. -The workload,\\nthe pattern of the workload, these training jobs are so synchronous\\nand so large, and so data parallel. The first thing that we have been doing\\nis building in partnership with you, the system, all the way from thinking\\nfrom power to the DC to the rack, to the accelerators, to the network. Just really the shape of Azure\\nis drastically changed and is changing rapidly\\nin support of these models that you\\'re building. Our job, number one,\\nis to build the best system so that you can build the best models and then make\\nthat all available to developers. The other thing\\nis we ourselves are our developers. We\\'re building products. In fact, my own conviction\\nof this entire generation of foundation models completely changed\\nthe first time I saw GitHub Copilot on GPT. We want to build our GitHub Copilot\\nall as developers on top of OpenAI APIs. We are very, very committed to that. What does that mean to developers? Look, I always think of Microsoft\\nas a platform company, a developer company,\\nand a partner company. For example, we want\\nto make GitHub Copilot available, the Enterprise edition available\\nto all the attendees here so that they can try it out. That\\'s awesome.\\nWe are very excited about that. [applause] -You can count on us to build\\nthe best infrastructure in Azure with your API support and bring it to all of you. Even things like the Azure marketplace. For developers\\nwho are building products out here to get to market rapidly. That\\'s really our intent here. -Great. How do you think about the future,\\nfuture of the partnership, or future of AI, or whatever? Anything you want -There are a couple of things for me\\nthat I think are going to be very, very key for us. One is I just described\\nhow the systems that are needed as you aggressively push forward\\non your roadmap requires us to be on the top of our game\\nand we intend fully to commit ourselves deeply to making sure you all as builders\\nof these foundation models have not only the best systems\\nfor training and inference, but the most compute,\\nso that you can keep pushing- -We appreciate that. --forward on the frontiers\\nbecause I think that\\'s the way we are going to make progress. The second thing I think\\nboth of us care about, in fact, quite frankly, the thing that excited\\nboth sides to come together is your mission and our mission. Our mission is to empower every person\\nand every organization on the planet to achieve more. To me, ultimately AI is only going to be useful if it truly does empower. I saw the video you played early. That was fantastic to hear those voices\\ndescribe what AI meant for them and what they were able to achieve. Ultimately, it\\'s about being\\nable to get the benefits of AI broadly disseminated to everyone, I think is going\\nto be the goal for us. Then the last thing is of course,\\nwe are very grounded in the fact that safety matters, and safety is not something\\nthat you\\'d care about later, but it\\'s something we do shift left\\non and we are very, very focused on that with you all. -Great. Well, I think we have\\nthe best partnership in tech. I\\'m excited for us to build AGI together. -Oh, I\\'m really excited.\\nHave a fantastic [crosstalk]. -Thank you very much for coming. -Thank you so much. -See you. [applause] -We have shared a lot of great updates\\nfor developers already and we got a lot more to come, but even though this\\nis developer conference, we can\\'t resist making\\nsome improvements to ChatGPT. A small one, ChatGPT now uses GPT-4 Turbo\\nwith all the latest improvements, including the latest knowledge cutoff,\\nwhich will continue to update. That\\'s all live today. It can now browse the web\\nwhen it needs to, write and run code, analyze data, take and generate images, and much more. We heard your feedback,\\nthat model picker, extremely annoying, that is gone starting today. You will not have to click\\naround the dropdown menu. All of this will just work together. Yes. [applause] -ChatGPT will just know\\nwhat to use and when you need it, but that\\'s not the main thing. Neither was price actually\\nthe main developer request. There was one\\nthat was even bigger than that. I want to talk about where we\\'re headed\\nand the main thing we\\'re here to talk about today. We believe that if you give people better tools,\\nthey will do amazing things. We know that people want AI\\nthat is smarter, more personal, more customizable,\\ncan do more on your behalf. Eventually, you\\'ll just ask\\nthe computer for what you need and it\\'ll do all of these tasks for you. These capabilities are often talked\\nin the AI field about as \"agents.\" The upsides of this\\nare going to be tremendous. At OpenAI, we really believe\\nthat gradual iterative deployment is the best way to address the safety issues,\\nthe safety challenges with AI. We think it\\'s especially important\\nto move carefully towards this future of agents. It\\'s going to require\\na lot of technical work and a lot of thoughtful consideration\\nby society. Today, we\\'re taking our first small step\\nthat moves us towards this future. We\\'re thrilled to introduce GPTs. GPTs are tailored versions of ChatGPT\\nfor a specific purpose. You can build a GPT, a customized version of ChatGPT\\nfor almost anything with instructions, expanded knowledge, and actions, and then you can publish it\\nfor others to use. Because they combine instructions,\\nexpanded knowledge, and actions, they can be more helpful to you. They can work better in many contexts,\\nand they can give you better control. They\\'ll make it easier for you\\nto accomplish all sorts of tasks or just have more fun and you\\'ll be able\\nto use them right within ChatGPT. You can in effect program a GPT\\nwith language just by talking to it. It\\'s easy to customize the behavior\\nso that it fits what you want. This makes building them very accessible and it gives agency to everyone. We\\'re going to show you what GPTs are, how to use them, how to build them, and then we\\'re going to talk\\nabout how they\\'ll be distributed and discovered. After that for developers,\\nwe\\'re going to show you how to build these agent-like experiences\\ninto your own apps. First, let\\'s look at a few examples. Our partners at Code.org are working hard\\nto expand computer science in schools. They\\'ve got a curriculum that is used\\nby tens of millions of students worldwide. Code.org, crafted Lesson Planner GPT,\\nto help teachers provide a more engaging experience\\nfor middle schoolers. If a teacher asks it to explain\\nfour loops in a creative way, it does just that. In this case, it\\'ll do it\\nin terms of a video game character repeatedly picking up coins. Super easy to understand\\nfor an 8th-grader. As you can see, this GPT\\nbrings together Code.org\\'s, extensive curriculum and expertise,\\nand lets teachers adapt it to their needs quickly and easily. Next, Canva has built a GPT that lets you start designing\\nby describing what you want in natural language. If you say, \"Make a poster\\nfor a DevDay reception this afternoon, this evening,\"\\nand you give it some details, it\\'ll generate a few options to start\\nwith by hitting Canva\\'s APIs. Now, this concept\\nmay be familiar to some of you. We\\'ve evolved our plugins\\nto be custom actions for GPTs. You can keep chatting with this\\nto see different iterations, and when you see one you like,\\nyou can click through to Canva for the full design experience. Now we\\'d like to show you a GPT Live. Zapier has built a GPT\\nthat lets you perform actions across 6,000 applications to unlock\\nall kinds of integration possibilities. I\\'d like to introduce Jessica,\\none of our solutions architects, who is going to drive this demo. Welcome Jessica. [applause]\\n-Thank you, Sam. Hello everyone. Thank you all. Thank you all for being here. My name is Jessica Shieh. I work with partners and customers\\nto bring their product alive. Today I can\\'t wait to show you\\nhow hard we\\'ve been working on this, so let\\'s get started. To start where your GPT will live is\\non this upper left corner. I\\'m going to start with clicking\\non the Zapier AI actions and on the right-hand side you can see\\nthat\\'s my calendar for today. It\\'s quite a day ever. I\\'ve already used this before,\\nso it\\'s actually already connected to my calendar. To start, I can ask, \"What\\'s on my schedule for today?\" We build GPTs with security in mind. Before it performs\\nany action or share data, it will ask for your permission. Right here, I\\'m going to say allowed. GPT is designed to take\\nin your instructions, make the decision on which capability to call\\nto perform that action, and then execute that for you. You can see right here,\\nit\\'s already connected to my calendar. It pulls into my information\\nand then I\\'ve also prompted it to identify conflicts on my calendar. You can see right here it actually\\nwas able to identify that. It looks like I have something coming up. What if I want to let Sam know\\nthat I have to leave early? Right here I say,\\n\"Let Sam know I got to go. Chasing GPUs.\" With that, I\\'m going to swap\\nto my conversation with Sam and then I\\'m going\\nto say, \"Yes, please run that.\" Sam, did you get that? -I did. -Awesome. [applause] -This is only a glimpse of what\\nis possible and I cannot wait to see what you all will build. Thank you. Back to you, Sam. [applause] -Thank you, Jessica. Those are three great examples. In addition to these, there are many more kinds of GPTs\\nthat people are creating and many, many more that will be created soon. We know that many people who want\\nto build a GPT don\\'t know how to code. We\\'ve made it so that you can program\\na GPT just by having a conversation. We believe that natural language is going\\nto be a big part of how people use computers in the future and we think\\nthis is an interesting early example. I\\'d like to show you how to build one. All right.\\nI want to create a GPT that helps give founders\\nand developers advice when starting new projects. I\\'m going to go to create a GPT here, and this drops me into the GPT builder. I worked with founders for years at YC\\nand still whenever I meet developers, the questions I get are always about,\\n\"How do I think about a business idea? Can you give me some advice?\" I\\'m going to see if I can build\\na GPT to help with that. To start, GPT builder asks me\\nwhat I want to make, and I\\'m going to say,\\n\"I want to help startup founders think. through their business ideas and get advice. After the founder has gotten some advice, grill them on why they are not growing faster.\" [laughter] -All right. To start off,\\nI just tell the GPT little bit about what I want here. It\\'s going to go off\\nand start thinking about that, and it\\'s going to write\\nsome detailed instructions for the GPT. It\\'s also going to, let\\'s see, ask me about a name. How do I feel about Startup Mentor? That\\'s fine. \"That\\'s good.\" If I didn\\'t like the name, of course,\\nI could call it something else, but it\\'s going to try to have\\nthis conversation with me and start there. You can see here on the right,\\nin the preview mode that it\\'s already starting\\nto fill out the GPT. Where it says what it does, it has\\nsome ideas of additional questions that I could ask. [chuckles] It just generated a candidate. Of course, I could regenerate that\\nor change it, but I like that. I\\'ll say \"That\\'s great.\" You see now that the GPT\\nis being built out a little bit more as we go. Now, what I want this to do, how it can interact with users,\\nI could talk about style here. What I\\'m going to say is, \"I am going to upload\\ntranscripts of some lectures about startups I have given, please give advice based off of those.\" All right. Now, it\\'s going to go figure out\\nhow to do that. I would like to show you\\nthe configure tab. You can see some of the things\\nthat were built out here as we were going by the builder itself. You can see that there\\'s capabilities here\\nthat I can enable. I could add custom actions. These are all fine to leave. I\\'m going to upload a file. Here is a lecture that I picked\\nthat I gave with some startup advice, and I\\'m going to add that here. In terms of these questions, this is a dumb one. The rest of those are reasonable,\\nand very much things founders often ask. I\\'m going to add one more thing\\nto the instructions here, which is be concise\\nand constructive with feedback. All right. Again, if we had more time,\\nI\\'d show you a bunch of other things. This is a decent start. Now, we can try it out\\nover on this preview tab. I will say, what\\'s a common question? \"What are three things to look\\nfor when hiring employees at an early-stage startup?\" Now, it\\'s going to look\\nat that document I uploaded. It\\'ll also have of course\\nall of the background knowledge of GPT-4. That\\'s pretty good. Those are three things\\nthat I definitely have said many times. Now, we could go\\non and it would start following the other instructions and grill me\\non why I\\'m not growing faster, but in the interest of time, I\\'m going to skip that. I\\'m going to publish\\nthis only to me for now. I can work on it later. I can add more content,\\nI can add a few actions that I think would be useful, and then I can share it publicly. That\\'s what it looks like to create a GPT [applause]\\n-Thank you. By the way, I always wanted to do that\\nafter all of the YC office hours, I always thought,\\n\"Man, someday I\\'ll be able to make a bot that will do this\\nand that\\'ll be awesome.\" [laughter] -With GPTs, we\\'re letting people\\neasily share and discover all the fun ways that they use ChatGPT with the world. You can make private GPT like I just did, or you can share your creations\\npublicly with a link for anyone to use, or if you\\'re on ChatGPT Enterprise,\\nyou can make GPTs just for your company. Later this month we\\'re going\\nto launch the GPT store. Thank you. I appreciate that. [applause] -You can list a GPT there\\nand we\\'ll be able to feature the best and the most popular GPT. Of course, we\\'ll make sure that GPTs\\nin the store follow our policies before they\\'re accessible. Revenue sharing is important to us. We\\'re going to pay people who build\\nthe most useful and the most used GPT a portion of our revenue. We\\'re excited to foster\\na vibrant ecosystem with the GPT store, just from what we\\'ve been building\\nourselves over the weekend. We\\'re confident there\\'s going\\nto be a lot of great stuff. We\\'re excited to share\\nmore information soon. Those are GPTs and we can\\'t wait to see\\nwhat you\\'ll build. This is a developer conference,\\nand the coolest thing about this is that we\\'re bringing\\nthe same concept to the API. [applause] Many of you have already been building\\nagent-like experiences on the API, for example, Shopify\\'s Sidekick, which lets you take\\nactions on the platform. Discord\\'s Clyde, lets Discord moderators create\\ncustom personalities for, and Snaps My AI, a customized chatbot that can be added\\nto group chats and make recommendations. These experiences are great, but they have been hard to build. Sometimes taking months,\\nteams of dozens of engineers, there\\'s a lot to handle to make\\nthis custom assistant experience. Today, we\\'re making that a lot easier\\nwith our new Assistants API. [applause] -The Assistants API includes\\npersistent threads, so they don\\'t have to figure out\\nhow to deal with long conversation history, built-in retrieval, code interpreter,\\na working Python interpreter in a sandbox environment, and of course\\nthe improved function calling, that we talked about earlier. We\\'d like to show you\\na demo of how this works. Here is Romain,\\nour head of developer experience. Welcome, Romain. [music]\\n[applause] -Thank you, Sam. Good morning. Wow. It\\'s fantastic to see you all here. It\\'s been so inspiring\\nto see so many of you infusing AI into your apps. Today, we\\'re launching new modalities\\nin the API, but we are also very excited to improve the developer experience\\nfor you all to build assistive agents. Let\\'s dive right in. Imagine I\\'m building $1, travel app for global explorers,\\nand this is the landing page. I\\'ve actually used GPT-4 to come up\\nwith these destination ideas. For those of you with a keen eye,\\nthese illustrations are generated programmatically using\\nthe new DALL-E 3 API available to all of you today. It\\'s pretty remarkable. Let\\'s enhance this app by adding\\na very simple assistant to it. This is the screen. We\\'re going to come\\nback to it in a second. First, I\\'m going to switch\\nover to the new assistant\\'s playground. Creating an assistant is easy,\\nyou just give it a name, some initial instructions, a model. In this case, I\\'ll pick GPT-4 Turbo. Here I\\'ll also go ahead\\nand select some tools. I\\'ll turn on Code Interpreter\\nand retrieval and save. That\\'s it. Our assistant is ready to go. Next, I can integrate\\nwith two new primitives of this Assistants API, threads and messages. Let\\'s take a quick look at the code. The process here is very simple. For each new user,\\nI will create a new thread. As these users engage\\nwith their assistant, I will add their messages to the threads. Very simple. Then I can simply run the assistant\\nat any time to stream the responses back to the app. We can return to the app\\nand try that in action. If I say, \"Hey, let\\'s go to Paris.\" All right. That\\'s it. With just a few lines of code,\\nusers can now have a very specialized assistant\\nright inside the app. I\\'d like to highlight\\none of my favorite features here, function calling. If you have not used it yet,\\nfunction calling is really powerful. As Sam mentioned,\\nwe are taking it a step further today. It now guarantees the JSON output\\nwith no added latency, and you can invoke multiple functions\\nat once for the first time. Here, if I carry on and say,\\n\"Hey, what are the top 10 things to do?\" I\\'m going to have the assistant\\nrespond to that again. Here, what\\'s interesting is\\nthat the assistant knows about functions, including those to annotate\\nthe map that you see on the right. Now, all of these pins\\nare dropping in real-time here. Yes, it\\'s pretty cool. [applause] -That integration allows\\nour natural language interface to interact fluidly with components\\nand features of our app. It truly showcases now\\nthe harmony you can build between AI and UI where the assistant\\nis actually taking action. Let\\'s talk about retrieval. Retrieval is about giving\\nour assistant more knowledge beyond these immediate user messages. In fact, I got inspired\\nand I already booked my tickets to Paris. I\\'m just going to drag\\nand drop here this PDF. While it\\'s uploading,\\nI can just sneak peek at it. Very typical United Flight ticket. Behind the scene here,\\nwhat\\'s happening is that retrieval is reading these files, and boom, the information\\nabout this PDF appeared on the screen. [applause] -This is, of course, a very tiny PDF,\\nbut Assistants can parse long-form documents\\nfrom extensive text to intricate product specs\\ndepending on what you\\'re building. In fact, I also booked an Airbnb,\\nso I\\'m just going to drag that over to the conversation as well. By the way, we\\'ve heard\\nfrom so many of you developers how hard that is to build yourself. You typically need to compute\\nyour own biddings, you need to set up chunking algorithm. Now all of that is taken care of. There\\'s more than retrieval\\nwith every API call, you usually need to resend\\nthe entire conversation history, which means setting up a key-value store,\\nthat means handling the context windows, serializing messages, and so forth. That complexity now completely goes away\\nwith this new stateful API. Just because OpenAI is managing this API,\\ndoes not mean it\\'s a black box. In fact, you can see the steps\\nthat the tools are taking right inside your developer dashboard. Here, if I go ahead and click on threads, this is the thread I believe\\nwe\\'re currently working on and see, these are all the steps,\\nincluding the functions being called with the right parameters,\\nand the PDFs I\\'ve just uploaded. Let\\'s move on to a new capability\\nthat many of you have been requesting for a while. Code Interpreter is now available today\\nin the API as well, that gives the AI the ability\\nto write and execute code on the fly, but even generate files. Let\\'s see that in action. If I say here,\\n\"Hey, we\\'ll be four friends staying at this Airbnb, what\\'s my share of it\\nplus my flights?\" All right. Now, here, what\\'s happening is that Code interpreter\\nnoticed that it should write some code to answer this query. Now it\\'s computing the number of days\\nin Paris, number of friends. It\\'s also doing\\nsome exchange rate calculation behind the scene to get the sensor for us. Not the most complex math,\\nbut you get the picture. Imagine you\\'re building\\na very complex finance app that\\'s crunching countless numbers,\\nplotting charts, so really any task\\nthat you\\'d normally tackle with code, then Code Interpreter\\nwill work great for you. All right.\\nI think my trip to Paris is solid. To recap here, we\\'ve just seen\\nhow you can quickly create an assistant that manages state\\nfor your user conversations, leverages external tools like knowledge\\nand retrieval and Code Interpreter, and finally invokes your own functions\\nto make things happen but there\\'s one more thing I wanted\\nto show you to really open up the possibilities using function\\ncalling combined with our new modalities that we\\'re launching today. While working on DevDay,\\nI built a small custom assistant that knows everything about this event, but instead of having\\na chat interface while running around all day today, I thought, why not use voice instead? Let\\'s bring my phone up on screen\\nhere so you can see it on the right. Awesome. On the right, you can see\\na very simple Swift app that takes microphone input. On the left, I\\'m actually going\\nto bring up my terminal log so you can see what\\'s happening\\nbehind the scenes. Let\\'s give it a shot. Hey there,\\nI\\'m on the keynote stage right now. Can you greet our attendees\\nhere at Dev Day? -Hey everyone, welcome to DevDay. It\\'s awesome to have you all here. Let\\'s make it an incredible day. [applause] -Isn\\'t that impressive? You have six unique and rich voices\\nto choose from in the API, each speaking multiple languages, so you can really find\\nthe perfect fit for your app. On my laptop here on the left, you can see the logs\\nof what\\'s happening behind the scenes, too. I\\'m using Whisper to convert\\nthe voice inputs into text, an assistant\\nwith GPT-4 Turbo, and finally, the new TTS API to make it speak. Thanks to function calling,\\nthings get even more interesting when the assistant can connect\\nto the internet and take real actions for users. Let\\'s do something\\neven more exciting here together. How about this? Hey, Assistant, can you randomly select\\nfive DevDay attendees here and give them $500 in OpenAI credits? [laughter] -Yes, checking the list of attendees. [laughter] -Done. I picked five DevDay attendees\\nand added $500 of API credits to their account. Congrats to Christine M, Jonathan C, Steven G, Luis K, and Suraj S. -All right, if you recognize yourself,\\nawesome. Congrats. That\\'s it. A quick overview today\\nof the new Assistants API combined with some of the new tools\\nand modalities that we launched, all starting\\nwith the simplicity of a rich text or voice conversation for you end users. We really can\\'t wait\\nto see what you build, and congrats to our lucky winners. Actually, you know what? you\\'re all part\\nof this amazing OpenAI community here so I\\'m just going to talk to my assistant one last time before I step off the stage. Hey Assistant, can you actually give\\neveryone here in the audience $500 in OpenAI credits? -Sounds great. Let me go through everyone. [applause] -All right, that function will keep running, but I\\'ve run out of time. Thank you so much, everyone. Have a great day. Back to you, Sam. -Pretty cool, huh? [audience cheers] -All right, so that Assistants API\\ngoes into beta today, and we are super excited\\nto see what you all do with it, anybody can enable it. Over time, GPTs and Assistants\\nare precursors to agents are going to be able to do much much more. They\\'ll gradually be able to plan and to perform more complex actions\\non your behalf. As I mentioned before, we really believe in the importance\\nof gradual iterative deployment. We believe it\\'s important for people\\nto start building with and using these agents now to get a feel\\nfor what the world is going to be like, as they become more capable. As we\\'ve always done, we\\'ll continue to update our systems\\nbased off of your feedback. We\\'re super excited that we got\\nto share all of this with you today. We introduced GPTs, custom versions of GPT\\nthat combine instructions, extended knowledge and actions. We launched the Assistants API to make it easier to build\\nassistive experiences with your own apps. These are your first steps\\ntowards AI agents and we\\'ll be increasing their capabilities over time. We introduced a new GPT-4 Turbo model\\nthat delivers improved function calling, knowledge, lowered pricing,\\nnew modalities, and more. We\\'re deepening\\nour partnership with Microsoft. In closing, I wanted to take a minute to thank\\nthe team that creates all of this. OpenAI has got remarkable talent density,\\nbut still, it takes a huge amount of hard work\\nand coordination to make all this happen. I truly believe that I\\'ve got\\nthe best colleagues in the world. I feel incredibly grateful\\nto get to work with them. We do all of this because we believe\\nthat AI is going to be a technological and societal revolution. It\\'ll change the world in many ways and we\\'re happy to get to work\\non something that will empower all of you to build so much for all of us. We talked about earlier how\\nif you give people better tools, they can change the world. We believe that AI will be\\nabout individual empowerment and agency at a scale that we\\'ve never seen before\\nand that will elevate humanity to a scale that we\\'ve never seen\\nbefore either. We\\'ll be able to do more, to create more, and to have more. As intelligence\\ngets integrated everywhere, we will all have superpowers on demand. We\\'re excited to see what you all\\nwill do with this technology and to discover the new future\\nthat we\\'re all going to architect together. We hope that you\\'ll come back next year. What we launched today is going\\nto look very quaint relative to what we\\'re busy creating for you know. Thank you for all that you do. Thank you for coming here today. [applause] [music]'),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content=\"We're starting a series of new models with\\xa0\\nthe new name o1 and this is to highlight the\\xa0\\xa0 fact that you might feel different when you use\\xa0\\no1 as a compared to previous models such as GPT-4o\\xa0\\xa0 so as others will explain later o1 is a reasoning\\xa0\\nmodel so it will think more before answering your\\xa0\\xa0question. We are releasing two models o1-preview\\xa0\\nwhich is to preview what's coming for o1 and o1\\xa0\\xa0 mini which is a faster slow smaller and faster\\xa0\\nmodel that is trained with a similar framework as\\xa0\\xa0o1 so we hope you like our new naming scheme o1. So\\xa0\\nwhat is reasoning anyway so one way of thinking of\\xa0\\xa0 reasoning is that there are times where we ask\\xa0\\nquestions and we need answers immediately because\\xa0\\xa0 they're simple questions. For example if you ask\\xa0\\nwhat's the capital of Italy you know the answer\\xa0\\xa0 and you don't really have to think about\\xa0\\nit much but if you wonder about a complex\\xa0\\xa0 puzzle or you want to write a really good business\\xa0\\nplan, you want to write the novel, you probably\\xa0\\xa0 want to think about it for a while and the more\\xa0\\nyou think about it the better the outcome so\\xa0\\xa0 reasoning is the ability of turning thinking time\\xa0\\ninto better outcomes whatever the task you're\\xa0\\xa0doing. It's been going on for a long time but I\\xa0\\nthink what's really cool about research is there's\\xa0\\xa0 that aha moment there's that particular point\\xa0\\nin time where something surprising happens and\\xa0\\xa0 things really click together. Are there any times\\xa0\\nfor you all when there was you had that aha moment? There was the first moment when the moment was hot\\xa0\\nof the press we started talking to the model and\\xa0\\xa0 people were like wow this model is really\\xa0\\ngreat and starting doing  something like that\\xa0\\xa0 and I think that there was a certain moment\\nin our training process where we trained like put\\xa0\\xa0 more compute in RL than before and train first\\xa0\\nall generating coherent chains of thought and we\\xa0\\xa0 so wow this this looks like something meaningfully\\xa0\\ndifferent than before and I think I think for me\\xa0\\xa0 this is the moment. I think related to that\\xa0\\nwhen we think about like training a model for\\xa0\\xa0 reasoning one thing that immediately jumps to mind\\xa0\\nis you could have humans write out their thought\\xa0\\xa0 process and train on that. An aha moment for me\\xa0\\nwas like when we saw that if you train the model\\xa0\\xa0 using RL to generate and hone its own chain\\xa0\\nof thoughts it can do even better than having\\xa0\\xa0 humans write chain of thought for it. And that was\\xa0\\nin aha moment that you could really scale this and explore models reasoning that way. For a lot of\\xa0\\nthe time that I've been here we've been trying to\\xa0\\xa0 make the models better at solving math problems as\\xa0\\nan example and we've put a lot of work into this\\xa0\\xa0 and we've come with a lot of different methods\\xa0\\nbut one thing that I kept like every time I would\\xa0\\xa0 read these outputs from the models I'd always be\\xa0\\nso frustrated that the model just would never\\xa0\\xa0 seem to question what was wrong or when it was\\xa0\\nmaking mistakes or things like that but one of\\xa0\\xa0 these early uh o1 models when we trained it and we\\xa0\\nactually started talking to it we started asking\\xa0\\xa0 it these questions and it was scoring higher on\\xa0\\nthese math tests we were giving it we could look\\xa0\\xa0 at how it was reasoning and you could just see\\xa0\\nthat it started to question itself and have really\\xa0\\xa0 interesting reflection and that was a moment for\\xa0\\nme where I was like wow like we we've uncovered\\xa0\\xa0 something different this is going to be something\\xa0\\nnew and and it was just like one of these coming\\xa0\\xa0 together moments that that that was really\\xa0\\npowerful. Thank you and congrats on releasing this.\")]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "#1stURL\n",
    "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=U9mJuUkhUzk\")\n",
    "yt_data1 = loader.load()\n",
    "\n",
    "# Second URL\n",
    "loader2 = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=3k89FMJhZ00\")\n",
    "yt_data2 = loader2.load()\n",
    "\n",
    "yt_data=yt_data1+yt_data2\n",
    "yt_data\n",
    "\n",
    "# to powyższe to jest LISTA, więc równie dobrze moglibyśmy mieć więcej dokumentów i on to potem dobrze podzieli\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gEV-uzWICKmO",
    "outputId": "a356c433-e154-4226-b2f1-636d197a9f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='[music] -Good morning.\\nThank you for joining us today. Please welcome to the stage, Sam Altman. [music] [applause] -Good morning. Welcome to our first-ever OpenAI DevDay. We\\'re thrilled that you\\'re here\\nand this energy is awesome. [applause] -Welcome to San Francisco. San Francisco has been\\nour home since day one. The city is important to us\\nand the tech industry in general. We\\'re looking forward\\nto continuing to grow here. We\\'ve got some great stuff\\nto announce today, but first, I\\'d like to take a minute to talk\\nabout some of the stuff that we\\'ve done over the past year. About a year ago, November 30th,\\nwe shipped ChatGPT as a \"low-key research preview\", and that went pretty well. In March, we followed that up\\nwith the launch of GPT-4, still the most capable model out in the world. [applause] -In the last few months, we launched voice and vision capabilities\\nso that ChatGPT can now see, hear, and speak. [applause] -There\\'s a lot,'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"so that ChatGPT can now see, hear, and speak. [applause] -There's a lot,\\nyou don't have to clap each time. [laughter] -More recently, we launched DALL-E 3,\\nthe world's most advanced image model. You can use it of course,\\ninside of ChatGPT. For our enterprise customers, we launched ChatGPT Enterprise,\\nwhich offers enterprise-grade security and privacy, higher speed GPT-4 access,\\nlonger context windows, a lot more. Today we've got about 2 million developers\\nbuilding on our API for a wide variety of use cases\\ndoing amazing stuff, over 92% of Fortune 500 companies\\nbuilding on our products, and we have about\\na hundred million weekly active users now on ChatGPT. [applause] -What's incredible\\non that is we got there entirely through word of mouth. People just find it useful\\nand tell their friends. OpenAI is the most advanced\\nand the most widely used AI platform in the world now, but numbers never tell the whole picture\\non something like this. What's really important\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='and tell their friends. OpenAI is the most advanced\\nand the most widely used AI platform in the world now, but numbers never tell the whole picture\\non something like this. What\\'s really important\\nis how people use the products, how people are using AI, and so I\\'d like to show you a quick video. -I actually wanted to write\\nsomething to my dad in Tagalog. I want a non-romantic way to tell\\nmy parent that I love him and I also want to tell him that he can rely on me,\\nbut in a way that still has the respect\\nof a child-to-parent relationship that you should have in Filipino culture\\nand in Tagalog grammar. When it\\'s translated into Tagalog,\\n\"I love you very deeply and I will be with you no matter\\nwhere the path leads.\" -I see some of the possibility,\\nI was like, \"Whoa.\" Sometimes I\\'m not sure about some stuff,\\nand I feel like actually ChatGPT like, hey, this is what I\\'m thinking about,\\nso it kind of give it more confidence. -The first thing that just blew'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='and I feel like actually ChatGPT like, hey, this is what I\\'m thinking about,\\nso it kind of give it more confidence. -The first thing that just blew\\nmy mind was it levels with you. That\\'s something\\nthat a lot of people struggle to do. It opened my mind to just what every creative could do\\nif they just had a person helping them out who listens. -This is to represent sickling hemoglobin. -You built that with ChatGPT?\\n-ChatGPT built it with me. -I started using it\\nfor daily activities like, \"Hey, here\\'s a picture of my fridge. Can you tell me what I\\'m missing? Because I\\'m going grocery shopping,\\nand I really need to do recipes that are following my vegan diet.\" -As soon as we got access\\nto Code Interpreter, I was like, \"Wow, this thing is awesome.\" It could build spreadsheets. It could do anything. -I discovered Chatty\\nabout three months ago on my 100th birthday. Chatty is very friendly, very patient, very knowledgeable, and very quick. This has been a wonderful thing. -I\\'m a 4.0 student,'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"about three months ago on my 100th birthday. Chatty is very friendly, very patient, very knowledgeable, and very quick. This has been a wonderful thing. -I'm a 4.0 student,\\nbut I also have four children. When I started using ChatGPT, I realized I could ask\\nChatGPT that question. Not only does it give me an answer,\\nbut it gives me an explanation. Didn't need tutoring as much. It gave me a life back. It gave me time for my family\\nand time for me. -I have a chronic nerve thing on my whole\\nleft half of my body, I have nerve damage. I had a brain surgery. I have limited use of my left hand. Now you can just have\\nthe integration of voice input. Then the newest one where you can have\\nthe back-and-forth dialogue, that's just maximum best interface for me. It's here. [music] [applause] -We love hearing the stories of how people\\nare using the technology. It's really why we do all of this. Now, on to the new stuff,\\nand we have got a lot. [audience cheers] -First, we're going to talk\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"are using the technology. It's really why we do all of this. Now, on to the new stuff,\\nand we have got a lot. [audience cheers] -First, we're going to talk\\nabout a bunch of improvements we've made, and then we'll talk\\nabout where we're headed next. Over the last year, we spent a lot of time talking\\nto developers around the world. We've heard a lot of your feedback. It's really informed\\nwhat we have to show you today. Today, we are launching\\na new model, GPT-4 Turbo. [applause] -GPT-4 Turbo will address\\nmany of the things that you all have asked for. Let's go through what's new. We've got six major things\\nto talk about for this part. Number one, context length. A lot of people have tasks that require\\na much longer context length. GPT-4 supported up to 8K and in some cases\\nup to 32K context length, but we know that isn't enough\\nfor many of you and what you want to do. GPT-4 Turbo, supports\\nup to 128,000 tokens of context. [applause] -That's 300 pages of a standard book,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"for many of you and what you want to do. GPT-4 Turbo, supports\\nup to 128,000 tokens of context. [applause] -That's 300 pages of a standard book,\\n16 times longer than our 8k context. In addition to a longer context length, you'll notice that the model\\nis much more accurate over a long context. Number two, more control. We've heard loud and clear\\nthat developers need more control over the model's responses and outputs. We've addressed that in a number of ways. We have a new feature called JSON Mode, which ensures that the model\\nwill respond with valid JSON. This has been a huge developer request. It'll make calling APIs much easier. The model is also much better\\nat function calling. You can now call many functions at once, and it'll do better at following\\ninstructions in general. We're also introducing a new feature\\ncalled reproducible outputs. You can pass a seed parameter,\\nand it'll make the model return consistent outputs. This, of course,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"instructions in general. We're also introducing a new feature\\ncalled reproducible outputs. You can pass a seed parameter,\\nand it'll make the model return consistent outputs. This, of course,\\ngives you a higher degree of control over model behavior. This rolls out in beta today. [applause] -In the coming weeks, we'll roll out\\na feature to let you view logprobs in the API. [applause] -All right. Number three,\\nbetter world knowledge. You want these models to be able to access\\nbetter knowledge about the world, so do we. We're launching retrieval in the platform. You can bring knowledge\\nfrom outside documents or databases into whatever you're building. We're also updating the knowledge cutoff. We are just as annoyed as all of you,\\nprobably more that GPT-4's knowledge about the world ended in 2021. We will try to never let it get\\nthat out of date again. GPT-4 Turbo has knowledge\\nabout the world up to April of 2023, and we will continue\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"that out of date again. GPT-4 Turbo has knowledge\\nabout the world up to April of 2023, and we will continue\\nto improve that over time. Number four, new modalities. Surprising no one, DALL-E 3, GPT-4 Turbo with vision, and the new text-to-speech model\\nare all going into the API today. [applause] -We have a handful of customers\\nthat have just started using DALL-E 3 to programmatically generate\\nimages and designs. Today, Coke is launching\\na campaign that lets its customers generate Diwali cards using DALL-E 3, and of course, our safety systems\\nhelp developers protect their applications against misuse. Those tools are available in the API. GPT-4 Turbo can now accept\\nimages as inputs via the API, can generate captions,\\nclassifications, and analysis. For example, Be My Eyes uses this technology to help\\npeople who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"people who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I'll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we're also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"speech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\\nyou're really going to like it. Number five, customization. Fine-tuning has been working really well\\nfor GPT-3.5 since we launched it a few months ago. Starting today, we're going to expand that\\nto the 16K version of the model. Also, starting today, we're inviting active fine-tuning users\\nto apply for the GPT-4 fine-tuning, experimental access program. The fine-tuning API is great for adapting\\nour models to achieve better performance in a wide variety of applications\\nwith a relatively small amount of data, but you may want a model to learn\\na completely new knowledge domain, or to use a lot of proprietary data. Today we're launching\\na new program called Custom Models. With Custom Models, our researchers\\nwill work closely with a company to help them make a great custom model,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"a new program called Custom Models. With Custom Models, our researchers\\nwill work closely with a company to help them make a great custom model,\\nespecially for them, and their use case using our tools. This includes modifying\\nevery step of the model training process, doing additional\\ndomain-specific pre-training, a custom RL post-training process tailored\\nfor specific domain, and whatever else. We won't be able to do this\\nwith many companies to start. It'll take a lot of work,\\nand in the interest of expectations, at least initially, it won't be cheap, but if you're excited to push things\\nas far as they can currently go. Please get in touch with us, and we think we can do\\nsomething pretty great. Number six, higher rate limits. We're doubling the tokens per minute for all of our established\\nGPT-4 customers, so it's easier to do more. You'll be able to request changes\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"something pretty great. Number six, higher rate limits. We're doubling the tokens per minute for all of our established\\nGPT-4 customers, so it's easier to do more. You'll be able to request changes\\nto further rate limits and quotas directly in your API account settings. In addition to these rate limits, it's important to do everything we can do\\nto make you successful building on our platform. We're introducing copyright shield. Copyright shield means\\nthat we will step in and defend our customers and pay the costs incurred,\\nif you face legal claims or on copyright infringement,\\nand this applies both to ChatGPT Enterprise and the API. Let me be clear,\\nthis is a good time to remind people do not train on data\\nfrom the API or ChatGPT Enterprise ever. All right. There's actually\\none more developer request that's been even bigger than all of these\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"this is a good time to remind people do not train on data\\nfrom the API or ChatGPT Enterprise ever. All right. There's actually\\none more developer request that's been even bigger than all of these\\nand so I'd like to talk about that now and that's pricing. [laughter] -GPT-4 Turbo is the industry-leading model. It delivers a lot of improvements\\nthat we just covered and it's a smarter model than GPT-4. We've heard from developers that there are\\na lot of things that they want to build, but GPT-4 just costs too much. They've told us that if we could decrease\\nthe cost by 20%, 25%, that would be great. A huge leap forward. I'm super excited to announce\\nthat we worked really hard on this and GPT-4 Turbo, a better model, is considerably cheaper than GPT-4\\nby a factor of 3x for prompt tokens. [applause] -And 2x for completion tokens\\nstarting today. [applause] -The new pricing\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"by a factor of 3x for prompt tokens. [applause] -And 2x for completion tokens\\nstarting today. [applause] -The new pricing\\nis 1¢ per 1,000 prompt tokens and 3¢ per 1,000 completion tokens. For most customers, that will lead to a blended rate more\\nthan 2.75 times cheaper to use for GPT-4 Turbo than GPT-4. We worked super hard to make this happen. We hope you're as excited\\nabout it as we are. [applause] -We decided to prioritize price first\\nbecause we had to choose one or the other, but we're going to work on speed next. We know that speed is important too. Soon you will notice GPT-4 Turbo\\nbecoming a lot faster. We're also decreasing\\nthe cost of GPT-3.5 Turbo 16K. Also, input tokens are 3x less\\nand output tokens are 2x less. Which means that GPT-3.5\\n16K is now cheaper than the previous GPT-3.5 4K model. Running\\na fine-tuned GPT-3.5 Turbo 16K version is also cheaper\\nthan the old fine-tuned 4K version. Okay, so we just covered\\na lot about the model itself. We hope that these changes\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"a fine-tuned GPT-3.5 Turbo 16K version is also cheaper\\nthan the old fine-tuned 4K version. Okay, so we just covered\\na lot about the model itself. We hope that these changes\\naddress your feedback. We're really excited to bring\\nall of these improvements to everybody now. In all of this, we're lucky to have a partner\\nwho is instrumental in making it happen. I'd like to bring out a special guest,\\nSatya Nadella, the CEO of Microsoft. [audience cheers] [music] -Good to see you.\\n-Thank you so much. Thank you. -Satya, thanks so much for coming here. -It's fantastic to be here\\nand Sam, congrats. I'm really looking forward to Turbo\\nand everything else that you have coming. It's been just fantastic partnering\\nwith you guys. -Awesome.\\nTwo questions. I won't take too much of your time. How is Microsoft thinking\\nabout the partnership currently? -First- [laughter] --we love you guys.\\n[laughter] -Look, it's been fantastic for us. In fact, I remember the first time\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='about the partnership currently? -First- [laughter] --we love you guys.\\n[laughter] -Look, it\\'s been fantastic for us. In fact, I remember the first time\\nI think you reached out and said, \"Hey, do you have\\nsome Azure credits?\" We\\'ve come a long way from there. -Thank you for those.\\nThat was great. -You guys have built something magical. Quite frankly, there are two things for us\\nwhen it comes to the partnership. The first is these workloads. Even when I was listening backstage\\nto how you\\'re describing what\\'s coming, even, it\\'s just so different and new. I\\'ve been in this infrastructure business\\nfor three decades. -No one has ever seen\\ninfrastructure like this. -The workload,\\nthe pattern of the workload, these training jobs are so synchronous\\nand so large, and so data parallel. The first thing that we have been doing\\nis building in partnership with you, the system, all the way from thinking'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"and so large, and so data parallel. The first thing that we have been doing\\nis building in partnership with you, the system, all the way from thinking\\nfrom power to the DC to the rack, to the accelerators, to the network. Just really the shape of Azure\\nis drastically changed and is changing rapidly\\nin support of these models that you're building. Our job, number one,\\nis to build the best system so that you can build the best models and then make\\nthat all available to developers. The other thing\\nis we ourselves are our developers. We're building products. In fact, my own conviction\\nof this entire generation of foundation models completely changed\\nthe first time I saw GitHub Copilot on GPT. We want to build our GitHub Copilot\\nall as developers on top of OpenAI APIs. We are very, very committed to that. What does that mean to developers? Look, I always think of Microsoft\\nas a platform company, a developer company,\\nand a partner company. For example, we want\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"as a platform company, a developer company,\\nand a partner company. For example, we want\\nto make GitHub Copilot available, the Enterprise edition available\\nto all the attendees here so that they can try it out. That's awesome.\\nWe are very excited about that. [applause] -You can count on us to build\\nthe best infrastructure in Azure with your API support and bring it to all of you. Even things like the Azure marketplace. For developers\\nwho are building products out here to get to market rapidly. That's really our intent here. -Great. How do you think about the future,\\nfuture of the partnership, or future of AI, or whatever? Anything you want -There are a couple of things for me\\nthat I think are going to be very, very key for us. One is I just described\\nhow the systems that are needed as you aggressively push forward\\non your roadmap requires us to be on the top of our game\\nand we intend fully to commit ourselves deeply to making sure you all as builders\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"on your roadmap requires us to be on the top of our game\\nand we intend fully to commit ourselves deeply to making sure you all as builders\\nof these foundation models have not only the best systems\\nfor training and inference, but the most compute,\\nso that you can keep pushing- -We appreciate that. --forward on the frontiers\\nbecause I think that's the way we are going to make progress. The second thing I think\\nboth of us care about, in fact, quite frankly, the thing that excited\\nboth sides to come together is your mission and our mission. Our mission is to empower every person\\nand every organization on the planet to achieve more. To me, ultimately AI is only going to be useful if it truly does empower. I saw the video you played early. That was fantastic to hear those voices\\ndescribe what AI meant for them and what they were able to achieve. Ultimately, it's about being\\nable to get the benefits of AI broadly disseminated to everyone, I think is going\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"describe what AI meant for them and what they were able to achieve. Ultimately, it's about being\\nable to get the benefits of AI broadly disseminated to everyone, I think is going\\nto be the goal for us. Then the last thing is of course,\\nwe are very grounded in the fact that safety matters, and safety is not something\\nthat you'd care about later, but it's something we do shift left\\non and we are very, very focused on that with you all. -Great. Well, I think we have\\nthe best partnership in tech. I'm excited for us to build AGI together. -Oh, I'm really excited.\\nHave a fantastic [crosstalk]. -Thank you very much for coming. -Thank you so much. -See you. [applause] -We have shared a lot of great updates\\nfor developers already and we got a lot more to come, but even though this\\nis developer conference, we can't resist making\\nsome improvements to ChatGPT. A small one, ChatGPT now uses GPT-4 Turbo\\nwith all the latest improvements, including the latest knowledge cutoff,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"is developer conference, we can't resist making\\nsome improvements to ChatGPT. A small one, ChatGPT now uses GPT-4 Turbo\\nwith all the latest improvements, including the latest knowledge cutoff,\\nwhich will continue to update. That's all live today. It can now browse the web\\nwhen it needs to, write and run code, analyze data, take and generate images, and much more. We heard your feedback,\\nthat model picker, extremely annoying, that is gone starting today. You will not have to click\\naround the dropdown menu. All of this will just work together. Yes. [applause] -ChatGPT will just know\\nwhat to use and when you need it, but that's not the main thing. Neither was price actually\\nthe main developer request. There was one\\nthat was even bigger than that. I want to talk about where we're headed\\nand the main thing we're here to talk about today. We believe that if you give people better tools,\\nthey will do amazing things. We know that people want AI\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='and the main thing we\\'re here to talk about today. We believe that if you give people better tools,\\nthey will do amazing things. We know that people want AI\\nthat is smarter, more personal, more customizable,\\ncan do more on your behalf. Eventually, you\\'ll just ask\\nthe computer for what you need and it\\'ll do all of these tasks for you. These capabilities are often talked\\nin the AI field about as \"agents.\" The upsides of this\\nare going to be tremendous. At OpenAI, we really believe\\nthat gradual iterative deployment is the best way to address the safety issues,\\nthe safety challenges with AI. We think it\\'s especially important\\nto move carefully towards this future of agents. It\\'s going to require\\na lot of technical work and a lot of thoughtful consideration\\nby society. Today, we\\'re taking our first small step\\nthat moves us towards this future. We\\'re thrilled to introduce GPTs. GPTs are tailored versions of ChatGPT\\nfor a specific purpose. You can build a GPT, a customized version of ChatGPT'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"that moves us towards this future. We're thrilled to introduce GPTs. GPTs are tailored versions of ChatGPT\\nfor a specific purpose. You can build a GPT, a customized version of ChatGPT\\nfor almost anything with instructions, expanded knowledge, and actions, and then you can publish it\\nfor others to use. Because they combine instructions,\\nexpanded knowledge, and actions, they can be more helpful to you. They can work better in many contexts,\\nand they can give you better control. They'll make it easier for you\\nto accomplish all sorts of tasks or just have more fun and you'll be able\\nto use them right within ChatGPT. You can in effect program a GPT\\nwith language just by talking to it. It's easy to customize the behavior\\nso that it fits what you want. This makes building them very accessible and it gives agency to everyone. We're going to show you what GPTs are, how to use them, how to build them, and then we're going to talk\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='about how they\\'ll be distributed and discovered. After that for developers,\\nwe\\'re going to show you how to build these agent-like experiences\\ninto your own apps. First, let\\'s look at a few examples. Our partners at Code.org are working hard\\nto expand computer science in schools. They\\'ve got a curriculum that is used\\nby tens of millions of students worldwide. Code.org, crafted Lesson Planner GPT,\\nto help teachers provide a more engaging experience\\nfor middle schoolers. If a teacher asks it to explain\\nfour loops in a creative way, it does just that. In this case, it\\'ll do it\\nin terms of a video game character repeatedly picking up coins. Super easy to understand\\nfor an 8th-grader. As you can see, this GPT\\nbrings together Code.org\\'s, extensive curriculum and expertise,\\nand lets teachers adapt it to their needs quickly and easily. Next, Canva has built a GPT that lets you start designing\\nby describing what you want in natural language. If you say, \"Make a poster'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='and lets teachers adapt it to their needs quickly and easily. Next, Canva has built a GPT that lets you start designing\\nby describing what you want in natural language. If you say, \"Make a poster\\nfor a DevDay reception this afternoon, this evening,\"\\nand you give it some details, it\\'ll generate a few options to start\\nwith by hitting Canva\\'s APIs. Now, this concept\\nmay be familiar to some of you. We\\'ve evolved our plugins\\nto be custom actions for GPTs. You can keep chatting with this\\nto see different iterations, and when you see one you like,\\nyou can click through to Canva for the full design experience. Now we\\'d like to show you a GPT Live. Zapier has built a GPT\\nthat lets you perform actions across 6,000 applications to unlock\\nall kinds of integration possibilities. I\\'d like to introduce Jessica,\\none of our solutions architects, who is going to drive this demo. Welcome Jessica. [applause]'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='all kinds of integration possibilities. I\\'d like to introduce Jessica,\\none of our solutions architects, who is going to drive this demo. Welcome Jessica. [applause]\\n-Thank you, Sam. Hello everyone. Thank you all. Thank you all for being here. My name is Jessica Shieh. I work with partners and customers\\nto bring their product alive. Today I can\\'t wait to show you\\nhow hard we\\'ve been working on this, so let\\'s get started. To start where your GPT will live is\\non this upper left corner. I\\'m going to start with clicking\\non the Zapier AI actions and on the right-hand side you can see\\nthat\\'s my calendar for today. It\\'s quite a day ever. I\\'ve already used this before,\\nso it\\'s actually already connected to my calendar. To start, I can ask, \"What\\'s on my schedule for today?\" We build GPTs with security in mind. Before it performs\\nany action or share data, it will ask for your permission. Right here, I\\'m going to say allowed. GPT is designed to take'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='any action or share data, it will ask for your permission. Right here, I\\'m going to say allowed. GPT is designed to take\\nin your instructions, make the decision on which capability to call\\nto perform that action, and then execute that for you. You can see right here,\\nit\\'s already connected to my calendar. It pulls into my information\\nand then I\\'ve also prompted it to identify conflicts on my calendar. You can see right here it actually\\nwas able to identify that. It looks like I have something coming up. What if I want to let Sam know\\nthat I have to leave early? Right here I say,\\n\"Let Sam know I got to go. Chasing GPUs.\" With that, I\\'m going to swap\\nto my conversation with Sam and then I\\'m going\\nto say, \"Yes, please run that.\" Sam, did you get that? -I did. -Awesome. [applause] -This is only a glimpse of what'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='to my conversation with Sam and then I\\'m going\\nto say, \"Yes, please run that.\" Sam, did you get that? -I did. -Awesome. [applause] -This is only a glimpse of what\\nis possible and I cannot wait to see what you all will build. Thank you. Back to you, Sam. [applause] -Thank you, Jessica. Those are three great examples. In addition to these, there are many more kinds of GPTs\\nthat people are creating and many, many more that will be created soon. We know that many people who want\\nto build a GPT don\\'t know how to code. We\\'ve made it so that you can program\\na GPT just by having a conversation. We believe that natural language is going\\nto be a big part of how people use computers in the future and we think\\nthis is an interesting early example. I\\'d like to show you how to build one. All right.\\nI want to create a GPT that helps give founders'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='this is an interesting early example. I\\'d like to show you how to build one. All right.\\nI want to create a GPT that helps give founders\\nand developers advice when starting new projects. I\\'m going to go to create a GPT here, and this drops me into the GPT builder. I worked with founders for years at YC\\nand still whenever I meet developers, the questions I get are always about,\\n\"How do I think about a business idea? Can you give me some advice?\" I\\'m going to see if I can build\\na GPT to help with that. To start, GPT builder asks me\\nwhat I want to make, and I\\'m going to say,\\n\"I want to help startup founders think. through their business ideas and get advice. After the founder has gotten some advice, grill them on why they are not growing faster.\" [laughter] -All right. To start off,\\nI just tell the GPT little bit about what I want here. It\\'s going to go off\\nand start thinking about that, and it\\'s going to write'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='I just tell the GPT little bit about what I want here. It\\'s going to go off\\nand start thinking about that, and it\\'s going to write\\nsome detailed instructions for the GPT. It\\'s also going to, let\\'s see, ask me about a name. How do I feel about Startup Mentor? That\\'s fine. \"That\\'s good.\" If I didn\\'t like the name, of course,\\nI could call it something else, but it\\'s going to try to have\\nthis conversation with me and start there. You can see here on the right,\\nin the preview mode that it\\'s already starting\\nto fill out the GPT. Where it says what it does, it has\\nsome ideas of additional questions that I could ask. [chuckles] It just generated a candidate. Of course, I could regenerate that\\nor change it, but I like that. I\\'ll say \"That\\'s great.\" You see now that the GPT\\nis being built out a little bit more as we go. Now, what I want this to do, how it can interact with users,\\nI could talk about style here. What I\\'m going to say is, \"I am going to upload'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='is being built out a little bit more as we go. Now, what I want this to do, how it can interact with users,\\nI could talk about style here. What I\\'m going to say is, \"I am going to upload\\ntranscripts of some lectures about startups I have given, please give advice based off of those.\" All right. Now, it\\'s going to go figure out\\nhow to do that. I would like to show you\\nthe configure tab. You can see some of the things\\nthat were built out here as we were going by the builder itself. You can see that there\\'s capabilities here\\nthat I can enable. I could add custom actions. These are all fine to leave. I\\'m going to upload a file. Here is a lecture that I picked\\nthat I gave with some startup advice, and I\\'m going to add that here. In terms of these questions, this is a dumb one. The rest of those are reasonable,\\nand very much things founders often ask. I\\'m going to add one more thing\\nto the instructions here, which is be concise'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='and very much things founders often ask. I\\'m going to add one more thing\\nto the instructions here, which is be concise\\nand constructive with feedback. All right. Again, if we had more time,\\nI\\'d show you a bunch of other things. This is a decent start. Now, we can try it out\\nover on this preview tab. I will say, what\\'s a common question? \"What are three things to look\\nfor when hiring employees at an early-stage startup?\" Now, it\\'s going to look\\nat that document I uploaded. It\\'ll also have of course\\nall of the background knowledge of GPT-4. That\\'s pretty good. Those are three things\\nthat I definitely have said many times. Now, we could go\\non and it would start following the other instructions and grill me\\non why I\\'m not growing faster, but in the interest of time, I\\'m going to skip that. I\\'m going to publish\\nthis only to me for now. I can work on it later. I can add more content,'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='on why I\\'m not growing faster, but in the interest of time, I\\'m going to skip that. I\\'m going to publish\\nthis only to me for now. I can work on it later. I can add more content,\\nI can add a few actions that I think would be useful, and then I can share it publicly. That\\'s what it looks like to create a GPT [applause]\\n-Thank you. By the way, I always wanted to do that\\nafter all of the YC office hours, I always thought,\\n\"Man, someday I\\'ll be able to make a bot that will do this\\nand that\\'ll be awesome.\" [laughter] -With GPTs, we\\'re letting people\\neasily share and discover all the fun ways that they use ChatGPT with the world. You can make private GPT like I just did, or you can share your creations\\npublicly with a link for anyone to use, or if you\\'re on ChatGPT Enterprise,\\nyou can make GPTs just for your company. Later this month we\\'re going\\nto launch the GPT store. Thank you. I appreciate that. [applause] -You can list a GPT there'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"you can make GPTs just for your company. Later this month we're going\\nto launch the GPT store. Thank you. I appreciate that. [applause] -You can list a GPT there\\nand we'll be able to feature the best and the most popular GPT. Of course, we'll make sure that GPTs\\nin the store follow our policies before they're accessible. Revenue sharing is important to us. We're going to pay people who build\\nthe most useful and the most used GPT a portion of our revenue. We're excited to foster\\na vibrant ecosystem with the GPT store, just from what we've been building\\nourselves over the weekend. We're confident there's going\\nto be a lot of great stuff. We're excited to share\\nmore information soon. Those are GPTs and we can't wait to see\\nwhat you'll build. This is a developer conference,\\nand the coolest thing about this is that we're bringing\\nthe same concept to the API. [applause] Many of you have already been building\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"what you'll build. This is a developer conference,\\nand the coolest thing about this is that we're bringing\\nthe same concept to the API. [applause] Many of you have already been building\\nagent-like experiences on the API, for example, Shopify's Sidekick, which lets you take\\nactions on the platform. Discord's Clyde, lets Discord moderators create\\ncustom personalities for, and Snaps My AI, a customized chatbot that can be added\\nto group chats and make recommendations. These experiences are great, but they have been hard to build. Sometimes taking months,\\nteams of dozens of engineers, there's a lot to handle to make\\nthis custom assistant experience. Today, we're making that a lot easier\\nwith our new Assistants API. [applause] -The Assistants API includes\\npersistent threads, so they don't have to figure out\\nhow to deal with long conversation history, built-in retrieval, code interpreter,\\na working Python interpreter in a sandbox environment, and of course\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"how to deal with long conversation history, built-in retrieval, code interpreter,\\na working Python interpreter in a sandbox environment, and of course\\nthe improved function calling, that we talked about earlier. We'd like to show you\\na demo of how this works. Here is Romain,\\nour head of developer experience. Welcome, Romain. [music]\\n[applause] -Thank you, Sam. Good morning. Wow. It's fantastic to see you all here. It's been so inspiring\\nto see so many of you infusing AI into your apps. Today, we're launching new modalities\\nin the API, but we are also very excited to improve the developer experience\\nfor you all to build assistive agents. Let's dive right in. Imagine I'm building $1, travel app for global explorers,\\nand this is the landing page. I've actually used GPT-4 to come up\\nwith these destination ideas. For those of you with a keen eye,\\nthese illustrations are generated programmatically using\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"and this is the landing page. I've actually used GPT-4 to come up\\nwith these destination ideas. For those of you with a keen eye,\\nthese illustrations are generated programmatically using\\nthe new DALL-E 3 API available to all of you today. It's pretty remarkable. Let's enhance this app by adding\\na very simple assistant to it. This is the screen. We're going to come\\nback to it in a second. First, I'm going to switch\\nover to the new assistant's playground. Creating an assistant is easy,\\nyou just give it a name, some initial instructions, a model. In this case, I'll pick GPT-4 Turbo. Here I'll also go ahead\\nand select some tools. I'll turn on Code Interpreter\\nand retrieval and save. That's it. Our assistant is ready to go. Next, I can integrate\\nwith two new primitives of this Assistants API, threads and messages. Let's take a quick look at the code. The process here is very simple. For each new user,\\nI will create a new thread. As these users engage\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='I will create a new thread. As these users engage\\nwith their assistant, I will add their messages to the threads. Very simple. Then I can simply run the assistant\\nat any time to stream the responses back to the app. We can return to the app\\nand try that in action. If I say, \"Hey, let\\'s go to Paris.\" All right. That\\'s it. With just a few lines of code,\\nusers can now have a very specialized assistant\\nright inside the app. I\\'d like to highlight\\none of my favorite features here, function calling. If you have not used it yet,\\nfunction calling is really powerful. As Sam mentioned,\\nwe are taking it a step further today. It now guarantees the JSON output\\nwith no added latency, and you can invoke multiple functions\\nat once for the first time. Here, if I carry on and say,\\n\"Hey, what are the top 10 things to do?\" I\\'m going to have the assistant\\nrespond to that again. Here, what\\'s interesting is\\nthat the assistant knows about functions, including those to annotate'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='\"Hey, what are the top 10 things to do?\" I\\'m going to have the assistant\\nrespond to that again. Here, what\\'s interesting is\\nthat the assistant knows about functions, including those to annotate\\nthe map that you see on the right. Now, all of these pins\\nare dropping in real-time here. Yes, it\\'s pretty cool. [applause] -That integration allows\\nour natural language interface to interact fluidly with components\\nand features of our app. It truly showcases now\\nthe harmony you can build between AI and UI where the assistant\\nis actually taking action. Let\\'s talk about retrieval. Retrieval is about giving\\nour assistant more knowledge beyond these immediate user messages. In fact, I got inspired\\nand I already booked my tickets to Paris. I\\'m just going to drag\\nand drop here this PDF. While it\\'s uploading,\\nI can just sneak peek at it. Very typical United Flight ticket. Behind the scene here,\\nwhat\\'s happening is that retrieval is reading these files, and boom, the information'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"I can just sneak peek at it. Very typical United Flight ticket. Behind the scene here,\\nwhat's happening is that retrieval is reading these files, and boom, the information\\nabout this PDF appeared on the screen. [applause] -This is, of course, a very tiny PDF,\\nbut Assistants can parse long-form documents\\nfrom extensive text to intricate product specs\\ndepending on what you're building. In fact, I also booked an Airbnb,\\nso I'm just going to drag that over to the conversation as well. By the way, we've heard\\nfrom so many of you developers how hard that is to build yourself. You typically need to compute\\nyour own biddings, you need to set up chunking algorithm. Now all of that is taken care of. There's more than retrieval\\nwith every API call, you usually need to resend\\nthe entire conversation history, which means setting up a key-value store,\\nthat means handling the context windows, serializing messages, and so forth. That complexity now completely goes away\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='the entire conversation history, which means setting up a key-value store,\\nthat means handling the context windows, serializing messages, and so forth. That complexity now completely goes away\\nwith this new stateful API. Just because OpenAI is managing this API,\\ndoes not mean it\\'s a black box. In fact, you can see the steps\\nthat the tools are taking right inside your developer dashboard. Here, if I go ahead and click on threads, this is the thread I believe\\nwe\\'re currently working on and see, these are all the steps,\\nincluding the functions being called with the right parameters,\\nand the PDFs I\\'ve just uploaded. Let\\'s move on to a new capability\\nthat many of you have been requesting for a while. Code Interpreter is now available today\\nin the API as well, that gives the AI the ability\\nto write and execute code on the fly, but even generate files. Let\\'s see that in action. If I say here,\\n\"Hey, we\\'ll be four friends staying at this Airbnb, what\\'s my share of it'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content='to write and execute code on the fly, but even generate files. Let\\'s see that in action. If I say here,\\n\"Hey, we\\'ll be four friends staying at this Airbnb, what\\'s my share of it\\nplus my flights?\" All right. Now, here, what\\'s happening is that Code interpreter\\nnoticed that it should write some code to answer this query. Now it\\'s computing the number of days\\nin Paris, number of friends. It\\'s also doing\\nsome exchange rate calculation behind the scene to get the sensor for us. Not the most complex math,\\nbut you get the picture. Imagine you\\'re building\\na very complex finance app that\\'s crunching countless numbers,\\nplotting charts, so really any task\\nthat you\\'d normally tackle with code, then Code Interpreter\\nwill work great for you. All right.\\nI think my trip to Paris is solid. To recap here, we\\'ve just seen\\nhow you can quickly create an assistant that manages state\\nfor your user conversations, leverages external tools like knowledge'),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"I think my trip to Paris is solid. To recap here, we've just seen\\nhow you can quickly create an assistant that manages state\\nfor your user conversations, leverages external tools like knowledge\\nand retrieval and Code Interpreter, and finally invokes your own functions\\nto make things happen but there's one more thing I wanted\\nto show you to really open up the possibilities using function\\ncalling combined with our new modalities that we're launching today. While working on DevDay,\\nI built a small custom assistant that knows everything about this event, but instead of having\\na chat interface while running around all day today, I thought, why not use voice instead? Let's bring my phone up on screen\\nhere so you can see it on the right. Awesome. On the right, you can see\\na very simple Swift app that takes microphone input. On the left, I'm actually going\\nto bring up my terminal log so you can see what's happening\\nbehind the scenes. Let's give it a shot. Hey there,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"a very simple Swift app that takes microphone input. On the left, I'm actually going\\nto bring up my terminal log so you can see what's happening\\nbehind the scenes. Let's give it a shot. Hey there,\\nI'm on the keynote stage right now. Can you greet our attendees\\nhere at Dev Day? -Hey everyone, welcome to DevDay. It's awesome to have you all here. Let's make it an incredible day. [applause] -Isn't that impressive? You have six unique and rich voices\\nto choose from in the API, each speaking multiple languages, so you can really find\\nthe perfect fit for your app. On my laptop here on the left, you can see the logs\\nof what's happening behind the scenes, too. I'm using Whisper to convert\\nthe voice inputs into text, an assistant\\nwith GPT-4 Turbo, and finally, the new TTS API to make it speak. Thanks to function calling,\\nthings get even more interesting when the assistant can connect\\nto the internet and take real actions for users. Let's do something\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"things get even more interesting when the assistant can connect\\nto the internet and take real actions for users. Let's do something\\neven more exciting here together. How about this? Hey, Assistant, can you randomly select\\nfive DevDay attendees here and give them $500 in OpenAI credits? [laughter] -Yes, checking the list of attendees. [laughter] -Done. I picked five DevDay attendees\\nand added $500 of API credits to their account. Congrats to Christine M, Jonathan C, Steven G, Luis K, and Suraj S. -All right, if you recognize yourself,\\nawesome. Congrats. That's it. A quick overview today\\nof the new Assistants API combined with some of the new tools\\nand modalities that we launched, all starting\\nwith the simplicity of a rich text or voice conversation for you end users. We really can't wait\\nto see what you build, and congrats to our lucky winners. Actually, you know what? you're all part\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"with the simplicity of a rich text or voice conversation for you end users. We really can't wait\\nto see what you build, and congrats to our lucky winners. Actually, you know what? you're all part\\nof this amazing OpenAI community here so I'm just going to talk to my assistant one last time before I step off the stage. Hey Assistant, can you actually give\\neveryone here in the audience $500 in OpenAI credits? -Sounds great. Let me go through everyone. [applause] -All right, that function will keep running, but I've run out of time. Thank you so much, everyone. Have a great day. Back to you, Sam. -Pretty cool, huh? [audience cheers] -All right, so that Assistants API\\ngoes into beta today, and we are super excited\\nto see what you all do with it, anybody can enable it. Over time, GPTs and Assistants\\nare precursors to agents are going to be able to do much much more. They'll gradually be able to plan and to perform more complex actions\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"are precursors to agents are going to be able to do much much more. They'll gradually be able to plan and to perform more complex actions\\non your behalf. As I mentioned before, we really believe in the importance\\nof gradual iterative deployment. We believe it's important for people\\nto start building with and using these agents now to get a feel\\nfor what the world is going to be like, as they become more capable. As we've always done, we'll continue to update our systems\\nbased off of your feedback. We're super excited that we got\\nto share all of this with you today. We introduced GPTs, custom versions of GPT\\nthat combine instructions, extended knowledge and actions. We launched the Assistants API to make it easier to build\\nassistive experiences with your own apps. These are your first steps\\ntowards AI agents and we'll be increasing their capabilities over time. We introduced a new GPT-4 Turbo model\\nthat delivers improved function calling, knowledge, lowered pricing,\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"towards AI agents and we'll be increasing their capabilities over time. We introduced a new GPT-4 Turbo model\\nthat delivers improved function calling, knowledge, lowered pricing,\\nnew modalities, and more. We're deepening\\nour partnership with Microsoft. In closing, I wanted to take a minute to thank\\nthe team that creates all of this. OpenAI has got remarkable talent density,\\nbut still, it takes a huge amount of hard work\\nand coordination to make all this happen. I truly believe that I've got\\nthe best colleagues in the world. I feel incredibly grateful\\nto get to work with them. We do all of this because we believe\\nthat AI is going to be a technological and societal revolution. It'll change the world in many ways and we're happy to get to work\\non something that will empower all of you to build so much for all of us. We talked about earlier how\\nif you give people better tools, they can change the world. We believe that AI will be\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"on something that will empower all of you to build so much for all of us. We talked about earlier how\\nif you give people better tools, they can change the world. We believe that AI will be\\nabout individual empowerment and agency at a scale that we've never seen before\\nand that will elevate humanity to a scale that we've never seen\\nbefore either. We'll be able to do more, to create more, and to have more. As intelligence\\ngets integrated everywhere, we will all have superpowers on demand. We're excited to see what you all\\nwill do with this technology and to discover the new future\\nthat we're all going to architect together. We hope that you'll come back next year. What we launched today is going\\nto look very quaint relative to what we're busy creating for you know. Thank you for all that you do. Thank you for coming here today. [applause] [music]\"),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content=\"We're starting a series of new models with\\xa0\\nthe new name o1 and this is to highlight the\\xa0\\xa0 fact that you might feel different when you use\\xa0\\no1 as a compared to previous models such as GPT-4o\\xa0\\xa0 so as others will explain later o1 is a reasoning\\xa0\\nmodel so it will think more before answering your\\xa0\\xa0question. We are releasing two models o1-preview\\xa0\\nwhich is to preview what's coming for o1 and o1\\xa0\\xa0 mini which is a faster slow smaller and faster\\xa0\\nmodel that is trained with a similar framework as\\xa0\\xa0o1 so we hope you like our new naming scheme o1. So\\xa0\\nwhat is reasoning anyway so one way of thinking of\\xa0\\xa0 reasoning is that there are times where we ask\\xa0\\nquestions and we need answers immediately because\\xa0\\xa0 they're simple questions. For example if you ask\\xa0\\nwhat's the capital of Italy you know the answer\\xa0\\xa0 and you don't really have to think about\\xa0\\nit much but if you wonder about a complex\\xa0\\xa0 puzzle or you want to write a really good business\"),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content=\"what's the capital of Italy you know the answer\\xa0\\xa0 and you don't really have to think about\\xa0\\nit much but if you wonder about a complex\\xa0\\xa0 puzzle or you want to write a really good business\\xa0\\nplan, you want to write the novel, you probably\\xa0\\xa0 want to think about it for a while and the more\\xa0\\nyou think about it the better the outcome so\\xa0\\xa0 reasoning is the ability of turning thinking time\\xa0\\ninto better outcomes whatever the task you're\\xa0\\xa0doing. It's been going on for a long time but I\\xa0\\nthink what's really cool about research is there's\\xa0\\xa0 that aha moment there's that particular point\\xa0\\nin time where something surprising happens and\\xa0\\xa0 things really click together. Are there any times\\xa0\\nfor you all when there was you had that aha moment? There was the first moment when the moment was hot\\xa0\\nof the press we started talking to the model and\\xa0\\xa0 people were like wow this model is really\\xa0\\ngreat and starting doing  something like that\\xa0\\xa0 and I think that there was a certain moment\"),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content='of the press we started talking to the model and\\xa0\\xa0 people were like wow this model is really\\xa0\\ngreat and starting doing  something like that\\xa0\\xa0 and I think that there was a certain moment\\nin our training process where we trained like put\\xa0\\xa0 more compute in RL than before and train first\\xa0\\nall generating coherent chains of thought and we\\xa0\\xa0 so wow this this looks like something meaningfully\\xa0\\ndifferent than before and I think I think for me\\xa0\\xa0 this is the moment. I think related to that\\xa0\\nwhen we think about like training a model for\\xa0\\xa0 reasoning one thing that immediately jumps to mind\\xa0\\nis you could have humans write out their thought\\xa0\\xa0 process and train on that. An aha moment for me\\xa0\\nwas like when we saw that if you train the model\\xa0\\xa0 using RL to generate and hone its own chain\\xa0\\nof thoughts it can do even better than having\\xa0\\xa0 humans write chain of thought for it. And that was\\xa0\\nin aha moment that you could really scale this and explore models reasoning that way. For a lot of'),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content=\"of thoughts it can do even better than having\\xa0\\xa0 humans write chain of thought for it. And that was\\xa0\\nin aha moment that you could really scale this and explore models reasoning that way. For a lot of\\xa0\\nthe time that I've been here we've been trying to\\xa0\\xa0 make the models better at solving math problems as\\xa0\\nan example and we've put a lot of work into this\\xa0\\xa0 and we've come with a lot of different methods\\xa0\\nbut one thing that I kept like every time I would\\xa0\\xa0 read these outputs from the models I'd always be\\xa0\\nso frustrated that the model just would never\\xa0\\xa0 seem to question what was wrong or when it was\\xa0\\nmaking mistakes or things like that but one of\\xa0\\xa0 these early uh o1 models when we trained it and we\\xa0\\nactually started talking to it we started asking\\xa0\\xa0 it these questions and it was scoring higher on\\xa0\\nthese math tests we were giving it we could look\\xa0\\xa0 at how it was reasoning and you could just see\"),\n",
       " Document(metadata={'source': '3k89FMJhZ00'}, page_content=\"actually started talking to it we started asking\\xa0\\xa0 it these questions and it was scoring higher on\\xa0\\nthese math tests we were giving it we could look\\xa0\\xa0 at how it was reasoning and you could just see\\xa0\\nthat it started to question itself and have really\\xa0\\xa0 interesting reflection and that was a moment for\\xa0\\nme where I was like wow like we we've uncovered\\xa0\\xa0 something different this is going to be something\\xa0\\nnew and and it was just like one of these coming\\xa0\\xa0 together moments that that that was really\\xa0\\npowerful. Thank you and congrats on releasing this.\")]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splits the data into chunks\n",
    "yt_text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "yt_splits=yt_text_splitter.split_documents(yt_data)\n",
    "yt_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlTQX0cHCx2A",
    "outputId": "b963bbba-86fb-45b7-8093-ce523a29c79e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off send_request(...) for 0.1s (posthog.request.APIError: [PostHog] upstream connect error or disconnect/reset before headers. reset reason: overflow (503))\n",
      "INFO:backoff:Backing off send_request(...) for 0.9s (posthog.request.APIError: [PostHog] upstream connect error or disconnect/reset before headers. reset reason: overflow (503))\n",
      "INFO:backoff:Backing off send_request(...) for 0.9s (posthog.request.APIError: [PostHog] upstream connect error or disconnect/reset before headers. reset reason: overflow (503))\n"
     ]
    }
   ],
   "source": [
    "# loads data into chroma database\n",
    "# uwaga: to nie będzie dobrze działac bo dokładałem nowe rekordy do bazy danych - wtedy retriever będzie zwracał kilka razy to samo jak poniżej\n",
    "vector_db=Chroma.from_documents(documents=yt_splits, embedding=embeddings)\n",
    "#defines the retriever\n",
    "retriever=vector_db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFQ6_x8oDej1",
    "outputId": "1fdb0a3e-43a5-49ae-b32f-40d4e1d21d41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"people who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I'll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we're also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"people who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I'll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we're also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"people who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I'll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we're also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"people who are blind or have low vision with their daily tasks like\\nidentifying products in front of them. With our new text-to-speech model, you'll be able to generate\\nincredibly natural-sounding audio from text in the API\\nwith six preset voices to choose from. I'll play an example. -Did you know that Alexander Graham Bell,\\nthe eminent inventor, was enchanted by the world of sounds. His ingenious mind led\\nto the creation of the graphophone, which etches sounds onto wax,\\nmaking voices whisper through time. -This is much more natural\\nthan anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\\nlike language learning, and voice assistance. Speaking of new modalities, we're also releasing the next version of our open-source\\nspeech recognition model, Whisper V3 today,\\nand it'll be coming soon to the API. It features improved performance\\nacross many languages, and we think\"),\n",
       " Document(metadata={'source': 'U9mJuUkhUzk'}, page_content=\"than anything else we've heard out there. Voice can make apps more natural\\nto interact with and more accessible. It also unlocks a lot of use cases\")]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_result=retriever.invoke(\"How to use voice with AI?\")\n",
    "yt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsEvUxCUY5KW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "HM5yqxo2EB6z",
    "outputId": "97f6a42d-4680-4386-b76b-58eae82e332e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke({\n",
    "    \"context\": yt_result,\n",
    "    \"question\": [HumanMessage(content=\"How to use voice with AI?\")]\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlI74cnBN4Yg"
   },
   "source": [
    "##langchain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "4kwwN790N53M"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "rWMxZiWyOLZZ"
   },
   "outputs": [],
   "source": [
    "def call_rest_api(http_method: str, endpoint_url: str)-> str:\n",
    "  \"\"\"Sends a request to the REST API.\n",
    "\n",
    "  Accepts two parameters:\n",
    "  * http_method - the HTTP method to be used (GET or DELETE)\n",
    "  * endpoint_url - the URL of the endpoint.\n",
    "\n",
    "  For example:\n",
    "  GET api/users?page=1\n",
    "  DELETE api/users/11\n",
    "\n",
    "  TO find users by name, retrieve entire pages until you find the person.\n",
    "\n",
    "  Available API endpoints:\n",
    "  method: GET, endpoint: api/users?page=[page_id] Lists people. The respoinse is paginated. Use the total property to determine the number of people\n",
    "  method: GET, endpoint: api/users/[person_id] retrieved the page of a person with given ID\n",
    "  method: DELETE, endpoint: api/users/[person_id] removes the person with given ID\n",
    "\n",
    "  \"\"\"\n",
    "  url=f\"https://reqres.in/{endpoint_url}\"\n",
    "  response=None\n",
    "  if http_method==\"GET\":\n",
    "    response=requests.get(url)\n",
    "  elif http_method==\"DELETE\":\n",
    "    response=requests.delete(url)\n",
    "  else:\n",
    "    raise ValueError(http_method)\n",
    "\n",
    "  if response.status_code==200:\n",
    "    return json.dumps(response.json())\n",
    "  else:\n",
    "    return f\"Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Dxofbt9MOXJz"
   },
   "outputs": [],
   "source": [
    "tools=[StructuredTool.from_function(call_rest_api)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6G9F8C8PnqY",
    "outputId": "8cdfc1eb-615e-49ad-8d7b-6d24a3527024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-bf765eb6809c>:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(tools, model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tools, model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "id": "xngUOsQbQko-",
    "outputId": "9d29d970-9f91-46bc-c59f-9af68d7ea7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `call_rest_api` with `{'http_method': 'GET', 'endpoint_url': 'api/users?page=1'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"page\": 1, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 1, \"email\": \"george.bluth@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Bluth\", \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"}, {\"id\": 2, \"email\": \"janet.weaver@reqres.in\", \"first_name\": \"Janet\", \"last_name\": \"Weaver\", \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"}, {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, {\"id\": 4, \"email\": \"eve.holt@reqres.in\", \"first_name\": \"Eve\", \"last_name\": \"Holt\", \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"}, {\"id\": 5, \"email\": \"charles.morris@reqres.in\", \"first_name\": \"Charles\", \"last_name\": \"Morris\", \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"}, {\"id\": 6, \"email\": \"tracey.ramos@reqres.in\", \"first_name\": \"Tracey\", \"last_name\": \"Ramos\", \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `call_rest_api` with `{'http_method': 'GET', 'endpoint_url': 'api/users?page=2'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"page\": 2, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 7, \"email\": \"michael.lawson@reqres.in\", \"first_name\": \"Michael\", \"last_name\": \"Lawson\", \"avatar\": \"https://reqres.in/img/faces/7-image.jpg\"}, {\"id\": 8, \"email\": \"lindsay.ferguson@reqres.in\", \"first_name\": \"Lindsay\", \"last_name\": \"Ferguson\", \"avatar\": \"https://reqres.in/img/faces/8-image.jpg\"}, {\"id\": 9, \"email\": \"tobias.funke@reqres.in\", \"first_name\": \"Tobias\", \"last_name\": \"Funke\", \"avatar\": \"https://reqres.in/img/faces/9-image.jpg\"}, {\"id\": 10, \"email\": \"byron.fields@reqres.in\", \"first_name\": \"Byron\", \"last_name\": \"Fields\", \"avatar\": \"https://reqres.in/img/faces/10-image.jpg\"}, {\"id\": 11, \"email\": \"george.edwards@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Edwards\", \"avatar\": \"https://reqres.in/img/faces/11-image.jpg\"}, {\"id\": 12, \"email\": \"rachel.howell@reqres.in\", \"first_name\": \"Rachel\", \"last_name\": \"Howell\", \"avatar\": \"https://reqres.in/img/faces/12-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\u001b[0m\u001b[32;1m\u001b[1;3mHere are the email addresses for all clients:\n",
      "\n",
      "1. George Bluth - **george.bluth@reqres.in**\n",
      "2. Janet Weaver - **janet.weaver@reqres.in**\n",
      "3. Emma Wong - **emma.wong@reqres.in**\n",
      "4. Eve Holt - **eve.holt@reqres.in**\n",
      "5. Charles Morris - **charles.morris@reqres.in**\n",
      "6. Tracey Ramos - **tracey.ramos@reqres.in**\n",
      "7. Michael Lawson - **michael.lawson@reqres.in**\n",
      "8. Lindsay Ferguson - **lindsay.ferguson@reqres.in**\n",
      "9. Tobias Funke - **tobias.funke@reqres.in**\n",
      "10. Byron Fields - **byron.fields@reqres.in**\n",
      "11. George Edwards - **george.edwards@reqres.in**\n",
      "12. Rachel Howell - **rachel.howell@reqres.in**\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Here are the email addresses for all clients:\\n\\n1. George Bluth - **george.bluth@reqres.in**\\n2. Janet Weaver - **janet.weaver@reqres.in**\\n3. Emma Wong - **emma.wong@reqres.in**\\n4. Eve Holt - **eve.holt@reqres.in**\\n5. Charles Morris - **charles.morris@reqres.in**\\n6. Tracey Ramos - **tracey.ramos@reqres.in**\\n7. Michael Lawson - **michael.lawson@reqres.in**\\n8. Lindsay Ferguson - **lindsay.ferguson@reqres.in**\\n9. Tobias Funke - **tobias.funke@reqres.in**\\n10. Byron Fields - **byron.fields@reqres.in**\\n11. George Edwards - **george.edwards@reqres.in**\\n12. Rachel Howell - **rachel.howell@reqres.in**'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Please return e-mail for all clients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BFwAsWi_Qtnd",
    "outputId": "1a1859d5-e8d3-47d1-c088-9550c7833ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `call_rest_api` with `{'http_method': 'GET', 'endpoint_url': 'api/users?page=1'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"page\": 1, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 1, \"email\": \"george.bluth@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Bluth\", \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"}, {\"id\": 2, \"email\": \"janet.weaver@reqres.in\", \"first_name\": \"Janet\", \"last_name\": \"Weaver\", \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"}, {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, {\"id\": 4, \"email\": \"eve.holt@reqres.in\", \"first_name\": \"Eve\", \"last_name\": \"Holt\", \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"}, {\"id\": 5, \"email\": \"charles.morris@reqres.in\", \"first_name\": \"Charles\", \"last_name\": \"Morris\", \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"}, {\"id\": 6, \"email\": \"tracey.ramos@reqres.in\", \"first_name\": \"Tracey\", \"last_name\": \"Ramos\", \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `call_rest_api` with `{'http_method': 'GET', 'endpoint_url': 'api/users?page=2'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"page\": 2, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 7, \"email\": \"michael.lawson@reqres.in\", \"first_name\": \"Michael\", \"last_name\": \"Lawson\", \"avatar\": \"https://reqres.in/img/faces/7-image.jpg\"}, {\"id\": 8, \"email\": \"lindsay.ferguson@reqres.in\", \"first_name\": \"Lindsay\", \"last_name\": \"Ferguson\", \"avatar\": \"https://reqres.in/img/faces/8-image.jpg\"}, {\"id\": 9, \"email\": \"tobias.funke@reqres.in\", \"first_name\": \"Tobias\", \"last_name\": \"Funke\", \"avatar\": \"https://reqres.in/img/faces/9-image.jpg\"}, {\"id\": 10, \"email\": \"byron.fields@reqres.in\", \"first_name\": \"Byron\", \"last_name\": \"Fields\", \"avatar\": \"https://reqres.in/img/faces/10-image.jpg\"}, {\"id\": 11, \"email\": \"george.edwards@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Edwards\", \"avatar\": \"https://reqres.in/img/faces/11-image.jpg\"}, {\"id\": 12, \"email\": \"rachel.howell@reqres.in\", \"first_name\": \"Rachel\", \"last_name\": \"Howell\", \"avatar\": \"https://reqres.in/img/faces/12-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\u001b[0m\u001b[32;1m\u001b[1;3mHere are the email addresses for all clients:\n",
      "\n",
      "1. George Bluth - **george.bluth@reqres.in**\n",
      "2. Janet Weaver - **janet.weaver@reqres.in**\n",
      "3. Emma Wong - **emma.wong@reqres.in**\n",
      "4. Eve Holt - **eve.holt@reqres.in**\n",
      "5. Charles Morris - **charles.morris@reqres.in**\n",
      "6. Tracey Ramos - **tracey.ramos@reqres.in**\n",
      "7. Michael Lawson - **michael.lawson@reqres.in**\n",
      "8. Lindsay Ferguson - **lindsay.ferguson@reqres.in**\n",
      "9. Tobias Funke - **tobias.funke@reqres.in**\n",
      "10. Byron Fields - **byron.fields@reqres.in**\n",
      "11. George Edwards - **george.edwards@reqres.in**\n",
      "12. Rachel Howell - **rachel.howell@reqres.in**\n",
      "\n",
      "If you need any more information, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/2a4e61b9-442b-4cc9-8ad1-c9b6994bd45c?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    agent.run(\"Please return e-mail for all clients\")\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9km8O9NGazug"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVjTwytxR46W"
   },
   "source": [
    "## langchain agemt z historią"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2Cjkq4UaR6wo"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "NJa0og2WT9xn",
    "outputId": "5f0c7b65-edd5-4d10-bff0-84d62ac899b3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'available_apis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-632f3e2c855b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34mf\"test {test} {{test}}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mavailable_apis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'available_apis' is not defined"
     ]
    }
   ],
   "source": [
    "test=123\n",
    "f\"test {test} {{test}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Jfs5nQZCUQ4S"
   },
   "outputs": [],
   "source": [
    "api_desc = json.dumps(available_apis_users)\n",
    "api_desc = api_desc.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7dUNd6DUTtX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aNUj3rNrSI8F"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an HR helper who makes API calls on behalf of an HR representative\"),\n",
    "    (\"system\", \"You have access to the following APIs: \" + api_desc),\n",
    "    (\"system\", \"If a function requires an identifier, list all employees first to find the proper value. You may need to list more than one page\"),\n",
    "    (\"system\", \"If you were asked to create, update, or delete a user, perform the action and reply with a confirmation telling what you have done.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTDoTvo0S9xb",
    "outputId": "ef79510a-27cf-4dbe-f92b-73b9fa83c851"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-1d4038f3f304>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "y7A1BpHsTA04"
   },
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, max_iterations=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "a-B0ZAaeTVm7"
   },
   "outputs": [],
   "source": [
    "agent_with_memory = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: memory.chat_memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gjjXWerhTrXE",
    "outputId": "4b4f537f-41f3-4d3c-ad55-5629771efde6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `call_rest_api` with `{'http_method': 'GET', 'endpoint_url': 'api/users?page=1'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"page\": 1, \"per_page\": 6, \"total\": 12, \"total_pages\": 2, \"data\": [{\"id\": 1, \"email\": \"george.bluth@reqres.in\", \"first_name\": \"George\", \"last_name\": \"Bluth\", \"avatar\": \"https://reqres.in/img/faces/1-image.jpg\"}, {\"id\": 2, \"email\": \"janet.weaver@reqres.in\", \"first_name\": \"Janet\", \"last_name\": \"Weaver\", \"avatar\": \"https://reqres.in/img/faces/2-image.jpg\"}, {\"id\": 3, \"email\": \"emma.wong@reqres.in\", \"first_name\": \"Emma\", \"last_name\": \"Wong\", \"avatar\": \"https://reqres.in/img/faces/3-image.jpg\"}, {\"id\": 4, \"email\": \"eve.holt@reqres.in\", \"first_name\": \"Eve\", \"last_name\": \"Holt\", \"avatar\": \"https://reqres.in/img/faces/4-image.jpg\"}, {\"id\": 5, \"email\": \"charles.morris@reqres.in\", \"first_name\": \"Charles\", \"last_name\": \"Morris\", \"avatar\": \"https://reqres.in/img/faces/5-image.jpg\"}, {\"id\": 6, \"email\": \"tracey.ramos@reqres.in\", \"first_name\": \"Tracey\", \"last_name\": \"Ramos\", \"avatar\": \"https://reqres.in/img/faces/6-image.jpg\"}], \"support\": {\"url\": \"https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral\", \"text\": \"Tired of writing endless social media content? Let Content Caddy generate it for you.\"}}\u001b[0m\u001b[32;1m\u001b[1;3mThere are a total of **12 employees**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Count the number of employees',\n",
       " 'chat_history': [],\n",
       " 'output': 'There are a total of **12 employees**.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_memory.invoke(\n",
    "    {\"input\": \"Count the number of employees\"},\n",
    "    config={\"configurable\": {\"session_id\": \"123\"}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0JmKTO7V0kx"
   },
   "source": [
    "# zadanie 3\n",
    "\n",
    "stworzyć Langchain z dostępem do narzędzia, które wyszukuje w wektorowej bazie danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "bLJ5vnfqWLQ4",
    "outputId": "87dd6d6d-b601-487b-c152-066c3f15e2f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-28 15:19:07--  https://api.sages.pl/content/trainings/sztuczna-inteligencja-ai-i-data-science/ai-openai-i-langchain.pdf\n",
      "Resolving api.sages.pl (api.sages.pl)... 146.59.3.31\n",
      "Connecting to api.sages.pl (api.sages.pl)|146.59.3.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 50424 (49K) [application/pdf]\n",
      "Saving to: ‘ai-openai-i-langchain.pdf’\n",
      "\n",
      "ai-openai-i-langcha 100%[===================>]  49.24K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-28 15:19:08 (389 KB/s) - ‘ai-openai-i-langchain.pdf’ saved [50424/50424]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.sages.pl/content/trainings/sztuczna-inteligencja-ai-i-data-science/ai-openai-i-langchain.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "zR-ZDCrYWOxb",
    "outputId": "32c1f0d8-a867-4bf1-ee42-13c62b102115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/298.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9ZvesKbcX1z0",
    "outputId": "1b7c9884-5a5a-46db-d4f0-f68bc9ec89de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/content/ai-openai-i-langchain.pdf', 'page': 0}, page_content='SZKOLENIE ZAAWANSOWANE\\nBudowanie aplikacji opartych na AI z\\nwykorzystaniem biblioteki Langchain\\nAI/LANGCHAIN\\nCzas trwania: 2 dni (16h)\\nPodczas szkolenia dowiesz się, jak zbudować aplikację opartą na sztucznej inteligencji, z wykorzystaniem biblioteki\\nLangchain.\\nCele szkolenia\\nZapoznanie z API OpenAI i sposobem użycia GPT-4 w Pythonie\\nUżycie biblioteki Langchain do umożliwienia AI dostępu do Internetu, własnej bazy danych oraz REST API\\nUżycie biblioteki Langchain do zaimplementowania chatbota\\nUżycie AI do wyszukiwania informacji w dokumentach tekstowych przy użyciu wektorowych baz danych\\nPrzygotowanie aplikacji opartej na AI do wdrożenia w środowisku produkcyjnym\\nZalety\\nSzkolenie jest prowadzone przez osoby na co dzień zajmujące się inżynierią danych oraz uczeniem maszynowym\\nProgram jest ciągle uaktualniany ze względu na szybki rozwój rozwiązań, których dotyczy szkolenie\\nDużo zadań praktycznych - szkolenie zakończysz z działającym kodem, który możesz użyć w swoich projektach\\nDla kogo?\\nProgramistów znających Pythona i chcących się nauczyć jak dodać AI do rozwijanych przez siebie produktów\\nWymagania\\nZnajomość Pythona na poziomie wystarczającym do zaimplementowania REST API oraz połączenia z bazą danych\\nProgram\\n1\\n. \\nWstęp\\na\\n. \\nCel szkolenia\\nb\\n. \\nAI\\nc\\n. \\nDuże modele tekstowe (LLM)\\nd\\n. \\nOpenAI API\\ne\\n. \\nPodstawy prompt engineering\\n2\\n. \\nAPI OpenAI\\na\\n. \\nGPT-4 API\\nb\\n. \\nChatGPT API\\n3\\n. \\nLangchain: Modele i zapytania\\na\\n. \\nSzablony zapytań\\nb\\n. \\nWybór modelu (OpenAI oraz open source)\\n4\\n. \\nChatbot w Langchain\\na\\n. \\nPamięć rozmowy\\nb\\n. \\nOgraniczenie zapamiętanych informacji\\nPrzedstawiona oferta ma charakter informacyjny \\ni nie stanowi oferty handlowej w rozumieniu Art.66 par.1 Kodeksu Cywilnego.\\nMake IT Happen\\n.'),\n",
       " Document(metadata={'source': '/content/ai-openai-i-langchain.pdf', 'page': 1}, page_content='5\\n. \\nLangchain chain\\na\\n. \\nSekwencje zapytań\\n6\\n. \\nWyszukiwanie informacji w dokumentach przy użyciu Langchain\\na\\n. \\nEmbeddings - czym jest\\nb\\n. \\nOpenAI Embeddings API\\nc\\n. \\nJak działa wyszukiwanie\\nd\\n. \\nWektorowe bazy danych\\ne\\n. \\nDostęp do bazy danych w Langchain\\n7\\n. \\nLangchain Agent\\na\\n. \\nMRKL - Modular Reasoning, Knowledge and Language\\nb\\n. \\nFunkcje jako narzędzia agenta Langchain\\nc\\n. \\nUżycie agenta w langchain\\nd\\n. \\nPołączenie z bazą danych\\ne\\n. \\nPołączenie z Internetem\\nf\\n. \\nImplementacja własnych funkcji\\n8\\n. \\nLangsmith - monitorowanie aplikacji używających AI\\na\\n. \\nCo to Langsmith\\nb\\n. \\nZapisywanie zapytań i odpowiedzi\\nc\\n. \\nMonitorowanie poprawności odpowiedzi\\nPrzedstawiona oferta ma charakter informacyjny \\ni nie stanowi oferty handlowej w rozumieniu Art.66 par.1 Kodeksu Cywilnego.\\nMake IT Happen\\n.')]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_file_path=\"/content/ai-openai-i-langchain.pdf\"\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "pages=loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "id": "_7S39ykwdDg4"
   },
   "outputs": [],
   "source": [
    "vector_db=Chroma.from_documents(documents=pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "id": "afkSdh1qdKB0"
   },
   "outputs": [],
   "source": [
    "retriever=vector_db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "cBwKE1hgdXPq"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question using the following context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1dhfS53Idisj",
    "outputId": "45edad56-b699-4dfa-e3ff-c465322a9c11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Na podstawie podanego kontekstu nie można określić czasu trwania szkolenia, ponieważ nie zawiera on informacji na ten temat.'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Jaki jest czas trwania szkolenia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_QuGZLD1drVp"
   },
   "outputs": [],
   "source": [
    "def search_in_documents(question:str) -> str:\n",
    "  \"\"\"Searches for an andwer in the vector database.\n",
    "\n",
    "  Accepts one parameter:\n",
    "  * question - the user's question\"\"\"\n",
    "  return chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "XMBogNZTd3vK"
   },
   "outputs": [],
   "source": [
    "tools=[\n",
    "    StructuredTool.from_function(search_in_documents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "mnRKw95rd9g2"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are an AI agent with access to a vector database of information about programming workshops.\n",
    "\n",
    "The documents are in Polish and must be searched using Polish as the query language. Given the user's input, translate it to Polish if required.\n",
    "\n",
    "You must always pass the question to the search function.\n",
    "Return the answer in the same language as the user's question. If the user asks the question in English, translate the function's answer to English.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "FBVNCiA-efMy"
   },
   "outputs": [],
   "source": [
    "model=ChatOpenAI(openai_api_key=API_KEY, model=\"gpt-4o\")\n",
    "memory=ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent=create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor=AgentExecutor(agent=agent, tools=tools, max_iterations=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "c16oGd-Pes3o"
   },
   "outputs": [],
   "source": [
    "agent_with_history=RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: memory.chat_memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "QcSdv7n0ccbt",
    "outputId": "6fd49da4-9b6d-4474-8c5e-b7c1c79ea43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_in_documents` with `{'question': 'Ile trwa szkolenie?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6b14b0e8e73f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agent_with_history.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Ile trwa szkolenie?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"session_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"abc\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5354\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5355\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5354\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5355\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5354\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5355\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4711\u001b[0m         \"\"\"\n\u001b[1;32m   4712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4713\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4714\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4715\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4576\u001b[0m                 )\n\u001b[1;32m   4577\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRecursionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4578\u001b[0;31m             output = output.invoke(\n\u001b[0m\u001b[1;32m   4579\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4580\u001b[0m                 patch_config(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5354\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5355\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1329\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1330\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 for a in self._iter_next_step(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1329\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1330\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 for a in self._iter_next_step(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             yield self._perform_agent_action(\n\u001b[0m\u001b[1;32m   1416\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1435\u001b[0m                 \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             observation = tool.run(\n\u001b[0m\u001b[1;32m   1438\u001b[0m                 \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0mtool_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"content_and_artifact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools/structured.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"StructuredTool does not support sync invocation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-326a7c32b118>\u001b[0m in \u001b[0;36msearch_in_documents\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mAccepts\u001b[0m \u001b[0mone\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   * question - the user's question\"\"\"\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0m_inner_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_inner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;34mf\"Received {type(inner_input)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n\u001b[0;32m--> 158\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    159\u001b[0m                     create_message(\n\u001b[1;32m    160\u001b[0m                         \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINVALID_PROMPT_INPUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
     ]
    }
   ],
   "source": [
    "agent_with_history.invoke(\n",
    "    {\"input\": \"Ile trwa szkolenie?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ2A0ty1-8mD"
   },
   "source": [
    "# langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5gluvXp--L-",
    "outputId": "b416c6fc-6f97-437d-c59c-9790c54a52f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-29 08:14:30--  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 60302 (59K) [text/plain]\n",
      "Saving to: ‘titanic.csv’\n",
      "\n",
      "\rtitanic.csv           0%[                    ]       0  --.-KB/s               \rtitanic.csv         100%[===================>]  58.89K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-11-29 08:14:30 (4.20 MB/s) - ‘titanic.csv’ saved [60302/60302]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2UBdCCjq_LgH",
    "outputId": "99f29a3a-afa0-4f15-870a-be953d014525"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-36cf2e3f-b1c7-45bc-b57f-340f85adb4e2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36cf2e3f-b1c7-45bc-b57f-340f85adb4e2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-36cf2e3f-b1c7-45bc-b57f-340f85adb4e2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-36cf2e3f-b1c7-45bc-b57f-340f85adb4e2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-70c22527-7e3c-4641-bc67-5c536066e5b8\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70c22527-7e3c-4641-bc67-5c536066e5b8')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-70c22527-7e3c-4641-bc67-5c536066e5b8 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_b44323ed-8d65-42e6-ab50-faa4260af001\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_b44323ed-8d65-42e6-ab50-faa4260af001 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"titanic.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "rwScItgw_fXD"
   },
   "outputs": [],
   "source": [
    "survivors = df[[\"PassengerId\", \"Survived\"]]\n",
    "tickets = df[[\"PassengerId\", \"Ticket\", \"Pclass\", \"Fare\", \"Cabin\", \"Embarked\"]]\n",
    "passengers = df[[\"PassengerId\", \"Name\", \"Sex\", \"Age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60K8ZoQw_8m6",
    "outputId": "71c0b1dd-8d1a-46cf-ff62-82f7dcd110f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"titanic.db\")\n",
    "survivors.to_sql(\"survivors\", con, index=False, if_exists=\"replace\")\n",
    "tickets.to_sql(\"tickets\", con, index=False, if_exists=\"replace\")\n",
    "passengers.to_sql(\"passengers\", con, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "_IQi4tx-ARRa"
   },
   "outputs": [],
   "source": [
    "# funkcja która zwraca tekst w tabeli markdown\n",
    "\n",
    "def run_query(sql_query):\n",
    "  con = sqlite3.connect(\"titanic.db\")\n",
    "  try:\n",
    "    response = pd.read_sql_query(sql_query, con)\n",
    "    return response.to_markdown()\n",
    "  except Exception as e:\n",
    "    return str(e)\n",
    "  finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgDl6P-cBD6O",
    "outputId": "1b88c3e7-309a-4044-da39-11d5653d9a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   PassengerId | Ticket           |   Pclass |    Fare | Cabin   | Embarked   |\n",
      "|---:|--------------:|:-----------------|---------:|--------:|:--------|:-----------|\n",
      "|  0 |             1 | A/5 21171        |        3 |  7.25   |         | S          |\n",
      "|  1 |             2 | PC 17599         |        1 | 71.2833 | C85     | C          |\n",
      "|  2 |             3 | STON/O2. 3101282 |        3 |  7.925  |         | S          |\n",
      "|  3 |             4 | 113803           |        1 | 53.1    | C123    | S          |\n",
      "|  4 |             5 | 373450           |        3 |  8.05   |         | S          |\n"
     ]
    }
   ],
   "source": [
    "print(run_query(\"select * from tickets limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "j_fdwWD6FGpV"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(openai_api_key=API_KEY, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s831qk_6BaDi"
   },
   "source": [
    "\"\"\"\n",
    "1. sprawdzamy czy moemy odpowiedzieć na pytanie\n",
    "1. 1. generujemy zapytanie sql\n",
    "1. 2. wykonujemy zapytanie\n",
    "1. 3. odpowiadamy na pytanie\n",
    "\n",
    "\n",
    "2. przeprosimy, że nie możemy pomóc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "D0UZ7VVvBxbu"
   },
   "outputs": [],
   "source": [
    "# opois bazy zmieścimy w wiadomości systemowej\n",
    "# jeśli nie, możemy dodać dodatkowe kroki i zwrócimy najpierw opisy tabel, które są nam potrzebne albo ograniczć do kolumn które nas intereują\n",
    "# zbiór titanic na pewno był w zbiorze treningowym, więc nie musimy bardzo opisyuwać. na własnych danych byśmy musieli pisać więcej\n",
    "DB_DESCRIPTION = \"\"\"The database contains data from the Titanic dataset.\n",
    "\n",
    "* \"survivors\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger\n",
    "Survived - indicates whether the person survived the sinking of the Titanic (1 survived, 0 did not survive)\n",
    "\n",
    "* \"tickets\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger, links to the survivors table\n",
    "Ticket - the ticket number\n",
    "Pclass - the passenger's class. Values 1, 2, 3\n",
    "Fare - the amount of money paid for the ticket\n",
    "Cabin - the cabin number where the passenger stayed\n",
    "Embarked - the port at which the passenger embarked (C: Cherbourg, Q: Queeenstown, S: Southampton)\n",
    "\n",
    "* \"passengers\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger, links to the survivors table\n",
    "Name - the full name of the passenger\n",
    "Sex - the gender of the passenger (text: male or female)\n",
    "Age - the age of the passenger at the time of the Titanic's accident\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "XiOOpAyCDUjk"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "can_answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "\n",
    "    Given the user's question, decide whether the question can be answered using the information from the database.\n",
    "    Return a JSON object with two keys: resoning, can_answer.\n",
    "\n",
    "    Question: Find the number of people who survived\n",
    "    {{\"reasoning\": \"I can find the number of people who survived by counting the number of 1 values in the Survived column of the survivors table\", \"can_answer\": true}}\n",
    "    Question: Count the number of first class passengers who survived\n",
    "    {{\"reasoning\": \"I can find the number of first class passengers who survived by joining the passenger table with the survivors table and filtering by Survived = 1 and Pclass = 1\", \"can_answer\": true}}\n",
    "    Question: Count the number of people who traveled in the cabin on the top deck.\n",
    "    {{\"reasoning\": \"Cabins are not assigned to decks.\", \"can_answer\": false}}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"data_description\", \"question\"]\n",
    ")\n",
    "\n",
    "can_answer_chain = can_answer_prompt | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UI6OIRmF8mp",
    "outputId": "34ec3b08-87a7-46f3-da65-a1db4fbc0af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': \"The database does not contain subjective information or opinions about passengers, such as who might be considered 'stupid'.\", 'can_answer': False}\n"
     ]
    }
   ],
   "source": [
    "question=\"Tell me what's the stupidest passenger\"\n",
    "plan=can_answer_chain.invoke({\"question\": question, \"data_description\": DB_DESCRIPTION})\n",
    "print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "eTKZ1fDIDg-6"
   },
   "outputs": [],
   "source": [
    "write_query_prompt = PromptTemplate(\n",
    "    template = \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    In the previous step, a query plan was generated:\n",
    "    {plan}\n",
    "\n",
    "    Use the plan to generate a SQL query to retrieve the data required to answer the user's question.\n",
    "\n",
    "    Return the SQL query with no explanation and no markdown characters.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"data_description\", \"question\", \"plan\"]\n",
    ")\n",
    "\n",
    "write_query_chain = write_query_prompt | model | StrOutputParser() #stroutput wistarczy bo nie będziemy tu jsona wysyłać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3IgGg7EI08a",
    "outputId": "cec7ac71-902f-4a84-9345-e326e69ddc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Name, Age FROM passengers WHERE Age = (SELECT MAX(Age) FROM passengers);\n"
     ]
    }
   ],
   "source": [
    "sql_query=write_query_chain.invoke({\n",
    "    \"data_description\": DB_DESCRIPTION,\n",
    "    \"question\": question,\n",
    "    \"plan\": \"I can find the number of people who survived by counting the number of 1 values in the Survived column of the survivors table\"\n",
    "})\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyPOPuU-LPUP",
    "outputId": "bf9b87b9-8030-4e8f-9ef1-7c818412191b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Name                                 |   Age |\n",
      "|---:|:-------------------------------------|------:|\n",
      "|  0 | Barkworth, Mr. Algernon Henry Wilson |    80 |\n"
     ]
    }
   ],
   "source": [
    "answer=run_query(\"\"\"SELECT Name, Age FROM passengers WHERE Age = (SELECT MAX(Age) FROM passengers);\"\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "cIXnhqAILrfj"
   },
   "outputs": [],
   "source": [
    "# Generujemy odpowiedź na pytanie użytkownika.\n",
    "# mamy dostęp do pytania, planu, zapytanie sql, opisu bazy danych, oraz odpowiedzi z bazy danych\n",
    "\n",
    "write_answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    Based on the result of query plan and of result of sql query please provide to the user a descriptive answer to his question.\n",
    "\n",
    "    Plan: {plan}\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"answer\", \"data_desctipion\", \"plan\"]\n",
    ")\n",
    "\n",
    "write_answer_chain = write_answer_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yotXORMZMvcS",
    "outputId": "e8dc11b5-769c-48af-d6f3-5267157ce715"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The oldest passenger on the Titanic was Mr. Algernon Henry Wilson Barkworth, who was 80 years old at the time of the accident.'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer_chain.invoke({\n",
    "    \"data_description\": DB_DESCRIPTION,\n",
    "    \"question\": question,\n",
    "    \"answer\": answer,\n",
    "    \"plan\": plan\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "DBIY7CYQO0V-"
   },
   "outputs": [],
   "source": [
    "# napisz prompt i chain obsługujący przypadek gdy nie można odpowiedzieć na pytanie użytkownika\n",
    "# dostępne wartości: pytanie: wyjaśnienie braku danych z pierwszego kroku oraz opis bazy danych\n",
    "no_data_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    Based on the result of query plan, only in case when plan.can_answer=\"False\", please politely answer to the user that you are not able to answer his question and tell him why.\n",
    "\n",
    "    Problem: {problem}\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"data_desctipion\", \"plan\"]\n",
    ")\n",
    "\n",
    "no_data_chain = no_data_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "IFPQCFZlTGIw"
   },
   "outputs": [],
   "source": [
    "# poniże modelowa odpowiedź. Nie ma sensu dawać w prompcie instrukcji warunkowych bo on i tak przechodzi do funkcji tylko jaksię nie da czegoś zrobić\n",
    "cannot_answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"You cannot answer the user's question because of the following problem: {problem}\n",
    "\n",
    "    Explain the issue and apologize.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"problem\"]\n",
    ")\n",
    "\n",
    "cannot_answer_chain = cannot_answer_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "V-4vRie-Pfyy",
    "outputId": "b536f6bd-67f4-400d-d1f5-283bcf3ad406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': \"The database does not contain subjective information or opinions about passengers, such as who might be considered 'stupid'.\", 'can_answer': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I\\'m sorry, but I\\'m unable to answer your question because the database does not contain subjective information or opinions about the passengers, such as who might be considered \"stupid\".'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(plan)\n",
    "no_data_chain.invoke({\n",
    "    \"data_description\": DB_DESCRIPTION,\n",
    "    \"question\": question,\n",
    "    \"plan\": plan\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "NATZtLGZTmyU",
    "outputId": "59de2887-3680-4d1e-9154-6fb5da8f6da9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I'm sorry, but I'm unable to provide the number of French people on board. The database I have access to does not include information about the nationality of passengers. If you have any other questions or need assistance with different information, please feel free to ask.\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cannot_answer_chain.invoke({\n",
    "    \"question\": \"Count the number of French people on board\",\n",
    "    \"problem\": \"The database does not contain information about the nationality of passengers, so I cannot determine the number of French people on board.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qQJ1sEoTp0q"
   },
   "source": [
    "#konfugurujemy LangGraph\n",
    "# Poniższe będe musiał przejśc niezależnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "irJGvkl5Ttts"
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "  question: str\n",
    "  plan: str\n",
    "  can_answer: bool\n",
    "  sql_query: str\n",
    "  sql_result: str\n",
    "  answer: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "C846A_roUDdx"
   },
   "outputs": [],
   "source": [
    "def check_if_can_answer_question(state):\n",
    "  result = can_answer_chain.invoke({\n",
    "      \"question\": state[\"question\"],\n",
    "      \"data_description\": DB_DESCRIPTION\n",
    "  })\n",
    "\n",
    "  return {\"plan\": result[\"reasoning\"], \"can_answer\": result[\"can_answer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "MLzcBwvNUYH_"
   },
   "outputs": [],
   "source": [
    "def write_query(state):\n",
    "  result = write_query_chain.invoke({\n",
    "      \"data_description\": DB_DESCRIPTION,\n",
    "      \"question\": state[\"question\"],\n",
    "      \"plan\": state[\"plan\"]\n",
    "  })\n",
    "\n",
    "  return {\"sql_query\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "uH-FHTXcUySz"
   },
   "outputs": [],
   "source": [
    "def execute_query(state):\n",
    "  query = state[\"sql_query\"]\n",
    "\n",
    "  try:\n",
    "    return {\"sql_result\": run_query(query)}\n",
    "  except Exception as e:\n",
    "    return {\"sql_result\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7IKjQromefW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "ZrO8V8rqVASP"
   },
   "outputs": [],
   "source": [
    "def write_answer(state):\n",
    "  result = write_answer_chain.invoke({\n",
    "      \"question\": state[\"question\"],\n",
    "      \"plan\": state[\"plan\"],\n",
    "      \"data_description\": DB_DESCRIPTION,\n",
    "      \"answer\": state[\"sql_result\"]\n",
    "  })\n",
    "\n",
    "  return {\"answer\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "1h-S97mzVwEB"
   },
   "outputs": [],
   "source": [
    "def explain_no_answer(state):\n",
    "  result = cannot_answer_chain.invoke({\n",
    "      \"problem\": state[\"plan\"],\n",
    "      \"question\": state[\"question\"]\n",
    "  })\n",
    "\n",
    "  return {\"answer\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "-VXDA2UZV0zL"
   },
   "outputs": [],
   "source": [
    "def check_if_can_answer(state):\n",
    "  return state[\"can_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "4qSHZJKzV1QN"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "2NLR41P_V5OK"
   },
   "outputs": [],
   "source": [
    "# workflow.addnode nazwa własna + nazwa funkcji najlepiej jak jedno=drugie\n",
    "# dzięki langgraph nie musimy pisać serii IFów\n",
    "# add_conditional_edges: skąd dokąd\n",
    "workflow = StateGraph(WorkflowState)\n",
    "\n",
    "workflow.add_node(\"check_if_can_answer_question\", check_if_can_answer_question)\n",
    "workflow.add_node(\"write_query\", write_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"write_answer\", write_answer)\n",
    "workflow.add_node(\"explain_no_answer\", explain_no_answer)\n",
    "\n",
    "workflow.set_entry_point(\"check_if_can_answer_question\")\n",
    "\n",
    "workflow.add_conditional_edges(\"check_if_can_answer_question\", check_if_can_answer, {\n",
    "    True: \"write_query\",\n",
    "    False: \"explain_no_answer\"\n",
    "})\n",
    "\n",
    "workflow.add_edge(\"write_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"write_answer\")\n",
    "\n",
    "workflow.add_edge(\"write_answer\", END)\n",
    "workflow.add_edge(\"explain_no_answer\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rwfMEe0BW5Bo",
    "outputId": "0c91dfc3-dd72-4ef1-ac93-bc76ec5e0651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from grandalf) (3.2.0)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: grandalf\n",
      "Successfully installed grandalf-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvMLhOjeW9dk",
    "outputId": "f50049dd-af47-4fc6-f369-b1315053ef91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 +-----------+                     \n",
      "                 | __start__ |                     \n",
      "                 +-----------+                     \n",
      "                       *                           \n",
      "                       *                           \n",
      "                       *                           \n",
      "       +------------------------------+            \n",
      "       | check_if_can_answer_question |            \n",
      "       +------------------------------+            \n",
      "               ...            ...                  \n",
      "             ..                  ..                \n",
      "           ..                      ..              \n",
      " +-------------+                     ..            \n",
      " | write_query |                      .            \n",
      " +-------------+                      .            \n",
      "        *                             .            \n",
      "        *                             .            \n",
      "        *                             .            \n",
      "+---------------+                     .            \n",
      "| execute_query |                     .            \n",
      "+---------------+                     .            \n",
      "        *                             .            \n",
      "        *                             .            \n",
      "        *                             .            \n",
      "+--------------+            +-------------------+  \n",
      "| write_answer |            | explain_no_answer |  \n",
      "+--------------+            +-------------------+  \n",
      "               ***            ***                  \n",
      "                  **        **                     \n",
      "                    **    **                       \n",
      "                  +---------+                      \n",
      "                  | __end__ |                      \n",
      "                  +---------+                      \n"
     ]
    }
   ],
   "source": [
    "#poniższe wyswietla nazwę własną zdefiniowaną w grafie\n",
    "# warto naryswać przed invoke żeby się upewnic że zadziała\n",
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7fKE4afIXX54",
    "outputId": "ae321359-232b-403b-ce5b-3ef2305d7886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query result provides a breakdown of the number of passengers who boarded the Titanic, categorized by the port of embarkation. Here is the summary:\n",
      "\n",
      "- **Cherbourg (C):** 168 passengers boarded the Titanic from this port.\n",
      "- **Queenstown (Q):** 77 passengers embarked from Queenstown.\n",
      "- **Southampton (S):** The majority, 644 passengers, boarded from Southampton.\n",
      "- Additionally, there are 2 entries where the port of embarkation is not specified or missing.\n",
      "\n",
      "This distribution indicates that Southampton was the primary embarkation point for the majority of the passengers on the Titanic.\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"question\": \"Count the number of people who boarded Titanic grouped by the embarkment port\"\n",
    "})\n",
    "\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2hjjRcbo07t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVitSD_zYrDd",
    "outputId": "2d27c374-81e5-45f0-ef59-271f36c62663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I'm unable to provide the number of French people who boarded the Titanic. This is because the available data does not include information about the nationality of the passengers. If you have any other questions or need assistance with a different topic, please feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"question\": \"Count the number of French people who boarded Titanic\"\n",
    "})\n",
    "\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "U_wELCoOZbWO",
    "outputId": "327336cb-4173-4a35-882e-00356fb96048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('check_if_can_answer_question', {'plan': 'I can find the number of people who boarded the Titanic grouped by embarkment port by counting the number of entries for each unique value in the Embarked column of the tickets table.', 'can_answer': True})])\n",
      "check_if_can_answer_question -> {'plan': 'I can find the number of people who boarded the Titanic grouped by embarkment port by counting the number of entries for each unique value in the Embarked column of the tickets table.', 'can_answer': True}\n",
      "dict_items([('write_query', {'sql_query': 'SELECT Embarked, COUNT(*) AS NumberOfPeople\\nFROM tickets\\nGROUP BY Embarked;'})])\n",
      "write_query -> {'sql_query': 'SELECT Embarked, COUNT(*) AS NumberOfPeople\\nFROM tickets\\nGROUP BY Embarked;'}\n",
      "dict_items([('execute_query', {'sql_result': '|    | Embarked   |   NumberOfPeople |\\n|---:|:-----------|-----------------:|\\n|  0 |            |                2 |\\n|  1 | C          |              168 |\\n|  2 | Q          |               77 |\\n|  3 | S          |              644 |'})])\n",
      "execute_query -> {'sql_result': '|    | Embarked   |   NumberOfPeople |\\n|---:|:-----------|-----------------:|\\n|  0 |            |                2 |\\n|  1 | C          |              168 |\\n|  2 | Q          |               77 |\\n|  3 | S          |              644 |'}\n",
      "dict_items([('write_answer', {'answer': \"The query results show the number of people who boarded the Titanic, grouped by the port where they embarked. Here's the breakdown:\\n\\n1. **Cherbourg (C):** 168 people boarded the Titanic from this port.\\n2. **Queenstown (Q):** 77 people boarded from here.\\n3. **Southampton (S):** This was the most common embarkment port, with 644 people boarding the Titanic.\\n4. **Blank Entry:** There are 2 entries where the embarkment port is not specified.\\n\\nThis information helps us understand the distribution of passengers based on the ports they used to board the Titanic. Southampton was the most popular embarkment point among the passengers.\"})])\n",
      "write_answer -> {'answer': \"The query results show the number of people who boarded the Titanic, grouped by the port where they embarked. Here's the breakdown:\\n\\n1. **Cherbourg (C):** 168 people boarded the Titanic from this port.\\n2. **Queenstown (Q):** 77 people boarded from here.\\n3. **Southampton (S):** This was the most common embarkment port, with 644 people boarding the Titanic.\\n4. **Blank Entry:** There are 2 entries where the embarkment port is not specified.\\n\\nThis information helps us understand the distribution of passengers based on the ports they used to board the Titanic. Southampton was the most popular embarkment point among the passengers.\"}\n"
     ]
    }
   ],
   "source": [
    "input_state = {\n",
    "    \"question\": \"Count the number of people who boarded Titanic grouped by the embarkment port\"\n",
    "}\n",
    "\n",
    "for update in app.stream(input_state, stream_mode=\"updates\"):\n",
    "  print(update.items())\n",
    "  for function_name, updated_state in update.items():\n",
    "    print(f\"{function_name} -> {updated_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogLI3fy-a1Qj",
    "outputId": "696f1766-eeb2-47e2-cda8-6dabfbc91381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/6bac65d5-20fb-4626-a060-bb634f41207c?poll=true\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    app.invoke({\n",
    "    \"question\": \"Count the number of French people who boarded Titanic\"\n",
    "})\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrsM8n-6boqM",
    "outputId": "416520b3-01e5-4eea-ba83-281695ad4014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page = call_rest_api(\"GET\", \"api/users?page=1\")\n",
    "first_page = json.loads(first_page)\n",
    "first_page = first_page[\"data\"]\n",
    "\n",
    "second_page = call_rest_api(\"GET\", \"api/users?page=2\")\n",
    "second_page = json.loads(second_page)\n",
    "second_page = second_page[\"data\"]\n",
    "\n",
    "employees = first_page + second_page\n",
    "employees = pd.DataFrame(employees)\n",
    "\n",
    "con = sqlite3.connect(\"employees.db\")\n",
    "employees.to_sql(\"employees\", con, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-PQaKKCrcHB4",
    "outputId": "cef1757c-7063-4549-a8f5-ce4b10f87ddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'email': 'george.bluth@reqres.in',\n",
       "  'first_name': 'George',\n",
       "  'last_name': 'Bluth',\n",
       "  'avatar': 'https://reqres.in/img/faces/1-image.jpg'},\n",
       " {'id': 2,\n",
       "  'email': 'janet.weaver@reqres.in',\n",
       "  'first_name': 'Janet',\n",
       "  'last_name': 'Weaver',\n",
       "  'avatar': 'https://reqres.in/img/faces/2-image.jpg'},\n",
       " {'id': 3,\n",
       "  'email': 'emma.wong@reqres.in',\n",
       "  'first_name': 'Emma',\n",
       "  'last_name': 'Wong',\n",
       "  'avatar': 'https://reqres.in/img/faces/3-image.jpg'},\n",
       " {'id': 4,\n",
       "  'email': 'eve.holt@reqres.in',\n",
       "  'first_name': 'Eve',\n",
       "  'last_name': 'Holt',\n",
       "  'avatar': 'https://reqres.in/img/faces/4-image.jpg'},\n",
       " {'id': 5,\n",
       "  'email': 'charles.morris@reqres.in',\n",
       "  'first_name': 'Charles',\n",
       "  'last_name': 'Morris',\n",
       "  'avatar': 'https://reqres.in/img/faces/5-image.jpg'},\n",
       " {'id': 6,\n",
       "  'email': 'tracey.ramos@reqres.in',\n",
       "  'first_name': 'Tracey',\n",
       "  'last_name': 'Ramos',\n",
       "  'avatar': 'https://reqres.in/img/faces/6-image.jpg'}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw31ZKnXbsXR"
   },
   "source": [
    "# zadanie 4A\n",
    "1. opis bazy danych o pracownikach\n",
    "2. przygotowac graf (podobie bedzie mial 5 elementow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "KNBU5AOUcUGB"
   },
   "outputs": [],
   "source": [
    "DB_DESCRIPTION = \"\"\"The database employees.db contains data about employees. There is only one table 'employees'\n",
    "\n",
    "* \"employees\" table:\n",
    "Columns:\n",
    "id - a unique identifier of the employee\n",
    "email - the email of the employee\n",
    "first_name - the first name of the employee\n",
    "last_name - the last name of the employee\n",
    "avatar - url to the avatar of the employee\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf0SHeNDetUx"
   },
   "source": [
    "### zadanie 4B\n",
    "Przygotuj prompt, chain oraz funkcję, która będzie użyta w Langgraph workflow,do sprawdzenia czy można odpowiedzieć na pytanie użytkownika przy użyciu danych opisanych w DB description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "tzHPTPHOe3y_"
   },
   "outputs": [],
   "source": [
    "z4_can_answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "    Given the user's question, decide whether the question can be answered using the information from the database.\n",
    "    Return a JSON object with two keys: resoning, can_answer.\n",
    "\n",
    "    Question: Find the number of employees\n",
    "    {{\"reasoning\": \"I can find the employees by counting the number of rows in the employees table\", \"can_answer\": true}}\n",
    "    Question: Please indicate the number of women.\n",
    "    {{\"reasoning\": \"The database does not contain gender information, therefore I cannot provide information about the number of men\", \"can_answer\": false}}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"data_description\", \"question\"]\n",
    ")\n",
    "\n",
    "z4_can_answer_chain = z4_can_answer_prompt | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XlvNCdOgREB",
    "outputId": "1b2d318e-435a-4d27-df6b-1b39044536b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'I can find the name of the employee with ID 1 by querying the first_name and last_name columns in the employees table where the id is 1',\n",
       " 'can_answer': True}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z4_can_answer_chain.invoke({\n",
    "    \"question\": \"give me the name for employee with ID 1\",\n",
    "    \"data_description\": DB_DESCRIPTION\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "22YjEO_AgeUy"
   },
   "outputs": [],
   "source": [
    "def z4_check_if_can_answer_question(state):\n",
    "  result = z4_can_answer_chain.invoke({\n",
    "      \"question\": state[\"question\"],\n",
    "      \"data_description\": DB_DESCRIPTION\n",
    "  })\n",
    "\n",
    "  return {\"plan\": result[\"reasoning\"], \"can_answer\": result[\"can_answer\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2leFCzkvio4p"
   },
   "source": [
    "# Zadanie 4c: przygotować prompt, chain i funkcję, która napisze zapytanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "iYMeeHpFis_G"
   },
   "outputs": [],
   "source": [
    "z4_write_query_prompt = PromptTemplate(\n",
    "    template = \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    In the previous step, a query plan was generated:\n",
    "    {plan}\n",
    "\n",
    "    Use the plan to generate a SQL query to retrieve the data required to answer the user's question.\n",
    "\n",
    "    Return the SQL query with no explanation and no markdown characters.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"data_description\", \"question\", \"plan\"]\n",
    ")\n",
    "\n",
    "z4_write_query_chain = write_query_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "L5M7pl11jSzG",
    "outputId": "83ea4b87-ea4c-488e-fc18-cff5b18a80f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'SELECT first_name, last_name FROM employees WHERE id = 1;'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z4_write_query_chain.invoke({\n",
    "    \"question\": \"give me the name for employee with ID 1\",\n",
    "    \"data_description\": DB_DESCRIPTION,\n",
    "    \"plan\": \"I can find the name of the employee with ID 1 by querying the first_name and last_name columns in the employees table where the id is 1\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "A1EjwPQtjp6E"
   },
   "outputs": [],
   "source": [
    "def z4_write_query(state):\n",
    "  result = z4_write_query_chain.invoke({\n",
    "      \"data_description\": DB_DESCRIPTION,\n",
    "      \"question\": state[\"question\"],\n",
    "      \"plan\": state[\"plan\"]\n",
    "  })\n",
    "\n",
    "  return {\"sql_query\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I5BEFpZlNCh"
   },
   "source": [
    "### Zadanie 4d: execute query\n",
    "1. f run_query - funkcja która odpytuje baze danych\n",
    "2. f która aktualizuje stan grafu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "o4W1umcwlPIU"
   },
   "outputs": [],
   "source": [
    "def z4_run_query(sql_query):\n",
    "  con = sqlite3.connect(\"employees.db\")\n",
    "  try:\n",
    "    response = pd.read_sql_query(sql_query, con)\n",
    "    return response.to_markdown()\n",
    "  except Exception as e:\n",
    "    return str(e)\n",
    "  finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "Mj98P86hl_zk"
   },
   "outputs": [],
   "source": [
    "def z4_execute_query(state):\n",
    "  query = state[\"sql_query\"]\n",
    "\n",
    "  try:\n",
    "    return {\"sql_result\": z4_run_query(query)}\n",
    "  except Exception as e:\n",
    "    return {\"sql_result\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keYfIyPYmg48",
    "outputId": "d319f695-b4d2-4ba2-dae0-5b323a03e3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   id | email                  | first_name   | last_name   | avatar                                  |\n",
      "|---:|-----:|:-----------------------|:-------------|:------------|:----------------------------------------|\n",
      "|  0 |    1 | george.bluth@reqres.in | George       | Bluth       | https://reqres.in/img/faces/1-image.jpg |\n",
      "|  1 |    2 | janet.weaver@reqres.in | Janet        | Weaver      | https://reqres.in/img/faces/2-image.jpg |\n",
      "|  2 |    3 | emma.wong@reqres.in    | Emma         | Wong        | https://reqres.in/img/faces/3-image.jpg |\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcdeoF6emwgA"
   },
   "source": [
    "# zad dE\n",
    "zapisz odpowiedź\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "KSo8MRy5m2Bi",
    "outputId": "7ce00427-bfa4-40ad-f0c1-2b88761e13e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'It seems there is a misunderstanding. Based on the structure of the \"employees\" table you provided, it contains columns for `id`, `email`, `first_name`, `last_name`, and `avatar`, but not for `age`. The query plan indicates that you want to retrieve the `first_name` and `last_name` of the employee with `ID 1`. Therefore, the correct answer should provide the full name of the employee using the `first_name` and `last_name` columns.\\n\\nUnfortunately, the data you\\'ve provided in the answer (Barkworth, Mr. Algernon Henry Wilson, Age 80) doesn\\'t match the structure of the \"employees\" table. If you execute the SQL query:\\n\\n```sql\\nSELECT first_name, last_name FROM employees WHERE id = 1;\\n```\\n\\nYou will get the first and last name of the employee with `ID 1`. Please check the database to ensure you have the correct information for the employee with ID 1.'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4tGOeXrnavc"
   },
   "source": [
    "# zad4F: krok explain_no_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0cXsrgCndKs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oijAPmJwn1Zx"
   },
   "source": [
    "Zad 4G: Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "rpomIxcTn4UI"
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(WorkflowState)\n",
    "\n",
    "workflow.add_node(\"z4_check_if_can_answer_question\", z4_check_if_can_answer_question)\n",
    "workflow.add_node(\"z4_write_query\", z4_write_query)\n",
    "workflow.add_node(\"z4_execute_query\", z4_execute_query)\n",
    "workflow.add_node(\"write_answer\", write_answer)\n",
    "workflow.add_node(\"explain_no_answer\", explain_no_answer)\n",
    "\n",
    "workflow.set_entry_point(\"z4_check_if_can_answer_question\")\n",
    "\n",
    "workflow.add_conditional_edges(\"z4_check_if_can_answer_question\", check_if_can_answer, {\n",
    "    True: \"z4_write_query\",\n",
    "    False: \"explain_no_answer\"\n",
    "})\n",
    "\n",
    "workflow.add_edge(\"z4_write_query\", \"z4_execute_query\")\n",
    "workflow.add_edge(\"z4_execute_query\", \"write_answer\")\n",
    "\n",
    "workflow.add_edge(\"write_answer\", END)\n",
    "workflow.add_edge(\"explain_no_answer\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inkLBL3MoudZ",
    "outputId": "7a2fd251-3dea-4768-da40-3a49f834a6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  +-----------+                     \n",
      "                  | __start__ |                     \n",
      "                  +-----------+                     \n",
      "                         *                          \n",
      "                         *                          \n",
      "                         *                          \n",
      "        +---------------------------------+         \n",
      "        | z4_check_if_can_answer_question |         \n",
      "        +---------------------------------+         \n",
      "                ...             ...                 \n",
      "              ..                   ..               \n",
      "            ..                       ..             \n",
      " +----------------+                    ..           \n",
      " | z4_write_query |                     .           \n",
      " +----------------+                     .           \n",
      "          *                             .           \n",
      "          *                             .           \n",
      "          *                             .           \n",
      "+------------------+                    .           \n",
      "| z4_execute_query |                    .           \n",
      "+------------------+                    .           \n",
      "          *                             .           \n",
      "          *                             .           \n",
      "          *                             .           \n",
      "  +--------------+            +-------------------+ \n",
      "  | write_answer |            | explain_no_answer | \n",
      "  +--------------+            +-------------------+ \n",
      "                ***             ***                 \n",
      "                   **         **                    \n",
      "                     **     **                      \n",
      "                    +---------+                     \n",
      "                    | __end__ |                     \n",
      "                    +---------+                     \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGg_GD3Ho21L",
    "outputId": "7647d2f6-a511-4b42-c44f-7f08203b8f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of all emails from the employees table is as follows:\n",
      "\n",
      "1. george.bluth@reqres.in\n",
      "2. janet.weaver@reqres.in\n",
      "3. emma.wong@reqres.in\n",
      "4. eve.holt@reqres.in\n",
      "5. charles.morris@reqres.in\n",
      "6. tracey.ramos@reqres.in\n",
      "7. michael.lawson@reqres.in\n",
      "8. lindsay.ferguson@reqres.in\n",
      "9. tobias.funke@reqres.in\n",
      "10. byron.fields@reqres.in\n",
      "11. george.edwards@reqres.in\n",
      "12. rachel.howell@reqres.in\n",
      "\n",
      "These emails are retrieved from the \"email\" column in the \"employees\" table.\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"question\": \"Please give me the list of all emails\"\n",
    "})\n",
    "\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zthqFIqMpat3"
   },
   "source": [
    "# Strukctured output with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "9Qw1w6c_pk2x"
   },
   "outputs": [],
   "source": [
    "model=ChatOpenAI(openai_api_key=API_KEY, model=Model_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "n23CUnLKp3Gq"
   },
   "outputs": [],
   "source": [
    "text=\"\"\"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "1ZPzQYktp8n-"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "DYRGYE2YqN6Z"
   },
   "outputs": [],
   "source": [
    "class Animal(BaseModel):\n",
    "  \"\"\"Extract English names and the Latin name of an animal from the given text\"\"\"\n",
    "  english_names: List[str] = Field(description=\"English names\")\n",
    "  latin_name: str = Field(description=\"The Latin name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "YAEb8sglqP_S"
   },
   "outputs": [],
   "source": [
    "structured_model=model.with_structured_output(Animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-QkVnl0qX4t",
    "outputId": "08591b12-8bb0-4b8c-adc8-c0c1aac5f932"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal(english_names=['cat', 'domestic cat', 'house cat'], latin_name='Felis catus')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=structured_model.invoke(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGPGk3Yuqhep",
    "outputId": "56ccf0f7-03fd-4d54-ecda-b5455a99b05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'domestic cat', 'house cat']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.english_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dC77dzsDqkcD",
    "outputId": "c691dc23-c713-41fd-d2fd-c32bb1506719"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Felis catus'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.latin_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3MnFvaqq0aB",
    "outputId": "19d5280e-7a0a-442f-f6fa-86e8d91f952f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/78a1c858-4ccb-48ce-a00c-3c9f4c73f88d?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    structured_model.invoke(text)\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usU56PvcrDkh",
    "outputId": "c8071055-7a18-4b20-ef73-57d913879feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/b718139c-574e-4702-94c6-42e772830b6f/projects/p/c397b2ca-f38f-46c3-b125-830bf5129218/r/ebcee010-994f-4887-be64-61e5bec754fb?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled(project_name=\"sk_langchain\") as cb:\n",
    "    structured_model.invoke(text).english_names\n",
    "    run_url = cb.get_run_url()\n",
    "    print(run_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuCk2k1FrysS"
   },
   "source": [
    "### openai json mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "aiboWvsSr0bw"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract English names and the Latin name of an animal from the given text. Return a JSON object with keys english_names (a list) and latin_name\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "76hELbJfsTeC"
   },
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(Animal, method=\"json_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "GjPdTBmYsU9f"
   },
   "outputs": [],
   "source": [
    "chain = prompt | structured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCuz2Ii0sX0e",
    "outputId": "41272a0c-47e3-4f7d-984a-4df0c5cf0976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal(english_names=['cat', 'domestic cat', 'house cat', 'feral cat', 'farm cat'], latin_name='Felis catus')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(text)\n",
    "# widzimy że wynik jest identyczny, tylko trzeba pamiętać zeby oprócz definiowania methody json_mode należy w opisie promptu również zdefiniować co ma konkretnie zwrócić ten json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3EsL7Zps49m"
   },
   "source": [
    "# Structured Output + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCEcZBcPs7wE",
    "outputId": "c9813434-dcff-4e92-d1e6-87fd9182d0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-29 11:35:22--  https://api.sages.pl/content/trainings/sztuczna-inteligencja-ai-i-data-science/ai-openai-i-langchain.pdf\n",
      "Resolving api.sages.pl (api.sages.pl)... 146.59.3.31\n",
      "Connecting to api.sages.pl (api.sages.pl)|146.59.3.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 50424 (49K) [application/pdf]\n",
      "Saving to: ‘ai-openai-i-langchain.pdf’\n",
      "\n",
      "ai-openai-i-langcha 100%[===================>]  49.24K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-29 11:35:24 (390 KB/s) - ‘ai-openai-i-langchain.pdf’ saved [50424/50424]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.sages.pl/content/trainings/sztuczna-inteligencja-ai-i-data-science/ai-openai-i-langchain.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSZy8rIhtX4C",
    "outputId": "634b719a-ada8-448c-b75a-92f2cf5d305d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/298.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZ5TXvj-tDuy",
    "outputId": "d0c76194-713f-4b67-9688-9e35cc6f1c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/content/ai-openai-i-langchain.pdf', 'page': 0}, page_content='SZKOLENIE ZAAWANSOWANE\\nBudowanie aplikacji opartych na AI z\\nwykorzystaniem biblioteki Langchain\\nAI/LANGCHAIN\\nCzas trwania: 2 dni (16h)\\nPodczas szkolenia dowiesz się, jak zbudować aplikację opartą na sztucznej inteligencji, z wykorzystaniem biblioteki\\nLangchain.\\nCele szkolenia\\nZapoznanie z API OpenAI i sposobem użycia GPT-4 w Pythonie\\nUżycie biblioteki Langchain do umożliwienia AI dostępu do Internetu, własnej bazy danych oraz REST API\\nUżycie biblioteki Langchain do zaimplementowania chatbota\\nUżycie AI do wyszukiwania informacji w dokumentach tekstowych przy użyciu wektorowych baz danych\\nPrzygotowanie aplikacji opartej na AI do wdrożenia w środowisku produkcyjnym\\nZalety\\nSzkolenie jest prowadzone przez osoby na co dzień zajmujące się inżynierią danych oraz uczeniem maszynowym\\nProgram jest ciągle uaktualniany ze względu na szybki rozwój rozwiązań, których dotyczy szkolenie\\nDużo zadań praktycznych - szkolenie zakończysz z działającym kodem, który możesz użyć w swoich projektach\\nDla kogo?\\nProgramistów znających Pythona i chcących się nauczyć jak dodać AI do rozwijanych przez siebie produktów\\nWymagania\\nZnajomość Pythona na poziomie wystarczającym do zaimplementowania REST API oraz połączenia z bazą danych\\nProgram\\n1\\n. \\nWstęp\\na\\n. \\nCel szkolenia\\nb\\n. \\nAI\\nc\\n. \\nDuże modele tekstowe (LLM)\\nd\\n. \\nOpenAI API\\ne\\n. \\nPodstawy prompt engineering\\n2\\n. \\nAPI OpenAI\\na\\n. \\nGPT-4 API\\nb\\n. \\nChatGPT API\\n3\\n. \\nLangchain: Modele i zapytania\\na\\n. \\nSzablony zapytań\\nb\\n. \\nWybór modelu (OpenAI oraz open source)\\n4\\n. \\nChatbot w Langchain\\na\\n. \\nPamięć rozmowy\\nb\\n. \\nOgraniczenie zapamiętanych informacji\\nPrzedstawiona oferta ma charakter informacyjny \\ni nie stanowi oferty handlowej w rozumieniu Art.66 par.1 Kodeksu Cywilnego.\\nMake IT Happen\\n.'), Document(metadata={'source': '/content/ai-openai-i-langchain.pdf', 'page': 1}, page_content='5\\n. \\nLangchain chain\\na\\n. \\nSekwencje zapytań\\n6\\n. \\nWyszukiwanie informacji w dokumentach przy użyciu Langchain\\na\\n. \\nEmbeddings - czym jest\\nb\\n. \\nOpenAI Embeddings API\\nc\\n. \\nJak działa wyszukiwanie\\nd\\n. \\nWektorowe bazy danych\\ne\\n. \\nDostęp do bazy danych w Langchain\\n7\\n. \\nLangchain Agent\\na\\n. \\nMRKL - Modular Reasoning, Knowledge and Language\\nb\\n. \\nFunkcje jako narzędzia agenta Langchain\\nc\\n. \\nUżycie agenta w langchain\\nd\\n. \\nPołączenie z bazą danych\\ne\\n. \\nPołączenie z Internetem\\nf\\n. \\nImplementacja własnych funkcji\\n8\\n. \\nLangsmith - monitorowanie aplikacji używających AI\\na\\n. \\nCo to Langsmith\\nb\\n. \\nZapisywanie zapytań i odpowiedzi\\nc\\n. \\nMonitorowanie poprawności odpowiedzi\\nPrzedstawiona oferta ma charakter informacyjny \\ni nie stanowi oferty handlowej w rozumieniu Art.66 par.1 Kodeksu Cywilnego.\\nMake IT Happen\\n.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(\"/content/ai-openai-i-langchain.pdf\")\n",
    "pages=loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "8Bt5s4p0tfeQ"
   },
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(documents=pages, embedding=embeddings)\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "PbRFS_Nxtixc"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question using the following context.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Return the response as a JSON with fields: quote and answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "M1CuABX3tlrh"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "FtKNj3shtpkW"
   },
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "  quote: str\n",
    "  answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "FKo9dyKLtrGs"
   },
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(Answer, method=\"json_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "Qmo1rUKXuB4I"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "xaOUZ4cDt63N"
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever  | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | structured_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RX8Ch4nOuEuQ",
    "outputId": "a489f7ec-242e-4e5b-a2cf-a70825f7a24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(quote='Czas trwania: 2 dni (16h)', answer='Czas trwania szkolenia to 2 dni, co łącznie daje 16 godzin.')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Jaki jest czas trwania szkolenia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDaQ2kiFuXgi"
   },
   "source": [
    "# zadanie 5\n",
    "# 1. wczytujemy min 3 striny z Wiki\n",
    "# 2. przygotowujemy RAG, który będzie wyszukiwał informacje w DB\n",
    "# 3. zwracamy obiekt Python z cytatem, linkiem do źródła oraz odpowiedzią"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "esBeD9FIuZDc",
    "outputId": "3bfa38b9-741c-4ad0-9b98-e18cbefdea60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=37c3ac0ae7558b808240231b1a1e924d62272728cabdfe58f50d9399d2d40717\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "4xvo8sVauj9t"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.wikipedia import WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "BGiVbnN7xhy0"
   },
   "outputs": [],
   "source": [
    "class WikiAnswer(BaseModel):\n",
    "  quote: str\n",
    "  link: str\n",
    "  answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "UNVfOp8pzFPG"
   },
   "outputs": [],
   "source": [
    "wiki_template = \"\"\"Answer the question using the following context.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Return the response as a JSON with fields: quote, link and answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "PvtfVjdazKVE"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(wiki_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "N_4LXVOMuqCF",
    "outputId": "30650f25-ead9-4c48-85a2-8393d46ae533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content=\"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\\n\\n\\n== Etymology and naming ==\\nThe origin of the English word cat, Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century. The Late Latin word may be derived from an unidentified African language. The Nubian word kaddîska 'wildcat' and Nobiin kadīs are possible sources or cognates.\\nThe forms might also have derived from an ancient Germanic word that was absorbed into Latin and then into Greek, Syriac, and Arabic. The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sámi gáđfi, 'female stoat', and Hungarian hölgy, 'lady, female stoat'; from Proto-Uralic *käďwä, 'female (of a furred animal)'.\\nThe English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have arisen from a sound used to attract a cat.\\nA male cat is called a tom or tomcat (or a gib, if neutered). A female is called a queen (or sometimes a molly, if spayed). A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling. A group of cats can be referred to as a clowder, a glaring, or a colony.\\n\\n\\n== Taxonomy ==\\nThe scientific name Felis catus was proposed by Carl Linnaeus in 1758 for a domestic cat. Felis catus domesticus was proposed by Johann Christian Polycarp Erxleben in 1777. Felis daemon proposed by Konstantin Satunin in 1904 was a black cat from the Transcaucasus, later identified as a domestic cat.\\nIn 2003, the International Commission on Zoological Nomenclature ruled that the domestic cat is a distinct species, namely Felis catus. In 2007, the modern domesticated subspecies F. silvestris catus sampled worldwide was considered to have likely descended from the African w\"),\n",
       " Document(metadata={'title': '.cat', 'summary': '.cat (pronounced in Catalan: punt cat [ˈpuŋ ˈkat]) is a sponsored top-level domain intended to be used to highlight the Catalan language. Its policy has been developed by ICANN and Fundació puntCAT. It was approved in September 2005.', 'source': 'https://en.wikipedia.org/wiki/.cat'}, page_content='.cat (pronounced in Catalan: punt cat [ˈpuŋ ˈkat]) is a sponsored top-level domain intended to be used to highlight the Catalan language. Its policy has been developed by ICANN and Fundació puntCAT. It was approved in September 2005.\\n\\n\\n== History ==\\nBefore .cat was available, and given the reluctance of certain Catalan institutions, companies, and people, to use .es, .ad, .fr, .it domains (depending on the state respectively) for their domains, alternatives emerged. An example of this was the website for the city of Girona in Catalonia, which preferred to use a .gi domain (\"ajuntament.gi\", the word \"ajuntament\" meaning both \"city council\" and \"town hall\"), even though .gi is the country code for Gibraltar, instead of the corresponding .es as a Spanish local authority.\\nTo solve this matter, in September 2005 the .cat TLD was approved, designed to meet the wishes and needs of the Catalan linguistic and cultural community on the Internet. This community is made up of those who use Catalan for their online communications, and/or promote the different aspects of Catalan culture online and prefer it to any other domain. The initial registration period went from February 13, 2006, to April 21, 2006.  The registry was open to everybody starting April 23, 2006.\\nIn September 2017 a Spanish court ordered that all .cat domain names that were being used to promote the Catalan independence referendum shall be taken down. On September 20 the Spanish police raided the offices of puntCAT and arrested CTO Pep Masoliver for sedition. Following this, puntCAT released several tweets and a press statement on their website that condemned this action, calling it \"shameful and degrading, unworthy of a civilized country [and] immensely disproportionate\".\\nOn October 31, 2017 several Catalan Government websites including president.cat, govern.cat and catalangovernment.eu were taken down due to the political crisis in Catalonia and due to the take over of authority by the Government of Spain.\\n\\n\\n== Restrictions ==\\nThe .cat domain is not territorial, but applies to the whole Catalan-speaking community, whether or not a site is based in Catalonia. In order to be granted a .cat domain, one needs to belong to the Catalan linguistic and cultural community on the Internet. A person, organization or company is considered to belong if they either:\\n\\nalready have content in Catalan published online.\\nhave access to a special code (sometimes called ENS), issued during special promotions or by agreements with certain institutions.\\ndevelop activities (in any language) to promote the Catalan culture and language.\\nare endorsed by 3 people or 1 institution already using a .cat domain name.\\nDespite the restrictions, the domain has been exploited for feline-related domain hacks, such as nyan.cat. In September 2017, with the domain\\'s filters weakened after the raid by Spanish police, American neo-Nazi website The Daily Stormer was briefly hosted on a .cat address.\\n\\n\\n== Impact ==\\nFollowing the success of the .cat domain, other language and culture-based domain names have emerged, such as .eus and .gal for the Basque language and culture (Euskal Herria) and the Galician language and culture (Galicia), respectively, as well as the .bzh domain-name dedicated to the Breton language and culture in Brittany.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\n(in Catalan) Information and register process\\nPeter Gerrand, 2006: \\'Cultural diversity in cyberspace: The Catalan campaign to win the new .cat top level domain\\' (Issue 11:1)\\nThe European Cultural and Linguistic Domains Network Archived December 25, 2016, at the Wayback Machine.')]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WikipediaLoader(\"cat\", load_max_docs = 3)\n",
    "wikidata = loader.load()\n",
    "wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ukX5ZwJZwUBL",
    "outputId": "b5448238-7bd8-48dd-83ac-b94b9c896f70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content=\"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are\"),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content=\"commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including\"),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='Female domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='As of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content=\"== Etymology and naming ==\\nThe origin of the English word cat, Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century. The Late Latin word may be derived from an unidentified African language. The Nubian word kaddîska 'wildcat' and Nobiin kadīs are possible sources or cognates.\"),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content=\"The forms might also have derived from an ancient Germanic word that was absorbed into Latin and then into Greek, Syriac, and Arabic. The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sámi gáđfi, 'female stoat', and Hungarian hölgy, 'lady, female stoat'; from Proto-Uralic *käďwä, 'female (of a furred animal)'.\"),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='The English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have arisen from a sound used to attract a cat.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='A male cat is called a tom or tomcat (or a gib, if neutered). A female is called a queen (or sometimes a molly, if spayed). A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling. A group of cats can be referred to as a clowder, a glaring, or a colony.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='== Taxonomy ==\\nThe scientific name Felis catus was proposed by Carl Linnaeus in 1758 for a domestic cat. Felis catus domesticus was proposed by Johann Christian Polycarp Erxleben in 1777. Felis daemon proposed by Konstantin Satunin in 1904 was a black cat from the Transcaucasus, later identified as a domestic cat.'),\n",
       " Document(metadata={'title': 'Cat', 'summary': \"The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including meowing, purring, trilling, hissing, growling, and grunting—as well as body language. It can hear sounds too faint or too high in frequency for human ears, such as those made by small mammals. It secretes and perceives pheromones.\\nFemale domestic cats can have kittens from spring to late autumn in temperate zones and throughout the year in equatorial regions, with litter sizes often ranging from two to five kittens. Domestic cats are bred and shown at events as registered pedigreed cats, a hobby known as cat fancy. Animal population control of cats may be achieved by spaying and neutering, but their proliferation and the abandonment of pets has resulted in large numbers of feral cats worldwide, contributing to the extinction of bird, mammal, and reptile species.\\nAs of 2017, the domestic cat was the second most popular pet in the United States, with 95.6 million cats owned and around 42 million households owning at least one cat. In the United Kingdom, 26% of adults have a cat, with an estimated population of 10.9 million pet cats as of 2020. As of 2021, there were an estimated 220 million owned and 480 million stray cats in the world.\", 'source': 'https://en.wikipedia.org/wiki/Cat'}, page_content='In 2003, the International Commission on Zoological Nomenclature ruled that the domestic cat is a distinct species, namely Felis catus. In 2007, the modern domesticated subspecies F. silvestris catus sampled worldwide was considered to have likely descended from the African w'),\n",
       " Document(metadata={'title': 'Cat the Cat', 'summary': \"Cat the Cat is a book series for very early readers written and illustrated by award-winning children's author and illustrator, Mo Willems.  The series began in February 2010 with the publication of two books, with additional books slated to follow soon thereafter.\", 'source': 'https://en.wikipedia.org/wiki/Cat_the_Cat'}, page_content=\"Cat the Cat is a book series for very early readers written and illustrated by award-winning children's author and illustrator, Mo Willems.  The series began in February 2010 with the publication of two books, with additional books slated to follow soon thereafter.\"),\n",
       " Document(metadata={'title': 'Cat the Cat', 'summary': \"Cat the Cat is a book series for very early readers written and illustrated by award-winning children's author and illustrator, Mo Willems.  The series began in February 2010 with the publication of two books, with additional books slated to follow soon thereafter.\", 'source': 'https://en.wikipedia.org/wiki/Cat_the_Cat'}, page_content='== Reception ==\\nPrior to the first book\\'s release, the Cat the Cat series garnered advance reviews including a starred review in Publishers Weekly, which said, \"Willems provides just enough humor and surprise to entertain youngest audiences...Cat could become another favorite; her personality sparkles in expansive gestures and gleeful interactions.\" The series also has been mentioned in School Library Journal.'),\n",
       " Document(metadata={'title': 'Cat the Cat', 'summary': \"Cat the Cat is a book series for very early readers written and illustrated by award-winning children's author and illustrator, Mo Willems.  The series began in February 2010 with the publication of two books, with additional books slated to follow soon thereafter.\", 'source': 'https://en.wikipedia.org/wiki/Cat_the_Cat'}, page_content=\"== Books ==\\nCat the Cat, Who Is That? (Feb 2010)\\nLet's Say Hi to Friends Who Fly (Feb 2010)\\nWhat's Your Sound, Hound the Hound? (Apr 2010)\\nTime to Sleep, Sheep the Sheep! (Jun 2010)\\n\\n\\n=== Board Book Adaptations for the Very Youngest Readers ===\\nWho Is That, Cat the Cat? (Apr 2014)\\nWho Flies, Cat the Cat? (Apr 2014)\\nWho Says That, Cat the Cat? (Aug 2014)\\nWho Sleeps, Cat the Cat? (Aug 2014)\\n\\n\\n== Trivia ==\\nPigeon, another series and character by Mo Willems, is hidden in each Cat the Cat book.\"),\n",
       " Document(metadata={'title': 'Cat the Cat', 'summary': \"Cat the Cat is a book series for very early readers written and illustrated by award-winning children's author and illustrator, Mo Willems.  The series began in February 2010 with the publication of two books, with additional books slated to follow soon thereafter.\", 'source': 'https://en.wikipedia.org/wiki/Cat_the_Cat'}, page_content=\"== Trivia ==\\nPigeon, another series and character by Mo Willems, is hidden in each Cat the Cat book.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nCat the Cat's website\\nMo Willems' website\\nMo Willems' blog\")]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "wikidata_split=text_splitter.split_documents(wikidata)\n",
    "wikidata_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "Yj2Y6z7qxK46"
   },
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(documents=wikidata_split, embedding=embeddings)\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "id": "ca2OIgmRxXMg"
   },
   "outputs": [],
   "source": [
    "# old function which read only the text and not metadata - using this function the link weren't passed properly and the database returned some bullshit except links\n",
    "# def format_docs(docs):\n",
    "#   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#better:\n",
    "def intermediate_format_docs(docs):\n",
    "  documents = \"\"\n",
    "  for doc in docs:\n",
    "    content = doc.page_content\n",
    "    source = doc.metadata[\"source\"]\n",
    "\n",
    "    documents += f\"\"\"{content}\n",
    "\n",
    "    Source: {source}\"\"\"\n",
    "  return documents\n",
    "\n",
    "#thebest\n",
    "def format_docs(docs):\n",
    "  documents = \"\"\n",
    "  for doc in docs:\n",
    "    content = doc.page_content\n",
    "    source = doc.metadata[\"source\"]\n",
    "\n",
    "    documents += f\"\"\"<document>\n",
    "<content>{content}</content>\n",
    "<source>{source}</source>\n",
    "</document>\"\"\"\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "99PdBTQR23pl",
    "outputId": "e7003377-861e-47d4-e9be-9aba721c9d85"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<document>\\n<content>The cat (Felis catus), also referred to as domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are</content>\\n<source>https://en.wikipedia.org/wiki/Cat</source>\\n</document><document>\\n<content>commonly kept as a pet and farm cat, but also ranges freely as a feral cat avoiding human contact. Valued by humans for companionship and its ability to kill vermin, the cat's retractable claws are adapted to killing small prey like mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth, and its night vision and sense of smell are well developed. It is a social species, but a solitary hunter and a crepuscular predator. Cat communication includes vocalizations—including</content>\\n<source>https://en.wikipedia.org/wiki/Cat</source>\\n</document>\""
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_docs(wikidata_split[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "GxDRnrZByV9O"
   },
   "outputs": [],
   "source": [
    "wiki_structured_model = model.with_structured_output(WikiAnswer, method=\"json_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "7ENr9memycqF"
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever  | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | wiki_structured_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOOowEheypHw",
    "outputId": "3b3870a2-6313-42e7-b314-9cfbf67cd23e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikiAnswer(quote='Kot domowy (Felis catus) jest zwierzęciem, które może żyć średnio od 12 do 15 lat, choć niektóre osobniki dożywają nawet 20 lat.', link='https://en.wikipedia.org/wiki/Cat', answer='Kot domowy żyje średnio od 12 do 15 lat, z niektórymi kotami osiągającymi wiek 20 lat.')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Jak długo żyje kot?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVcODNiDAoFL"
   },
   "source": [
    "### praca z grafikami przy użyciu LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "nEhaZ_dyBIbO"
   },
   "outputs": [],
   "source": [
    "image_url = \"https://www.sages.pl/static/ee94d433588878ad03b6c774ae2b42bc/cd96e/vouchery_glowna_2024_e35852c6d5.webp\"\n",
    "# image_url=\"/content/SampleScan.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "mMlJ8wBHBcVX"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import httpx\n",
    "\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode('utf-8')\n",
    "# with open(image_url, \"rb\") as image_file:\n",
    "#     image_data = base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "collapsed": true,
    "id": "VW4FTJKRBeqC",
    "outputId": "45aea420-95fa-4035-9c63-7d8a94754b87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "4Z-cKV2PBipr"
   },
   "outputs": [],
   "source": [
    "model=ChatOpenAI(openai_api_key=API_KEY, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "TlAFVHCzCHSt"
   },
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Extract the text from the image\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg:base64,{image_data}\"}}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9PKOhrFCIsR",
    "outputId": "3ed42330-c301-4c38-dd0b-dcd507f9051d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here is the extracted text from the image:\\n\\n---\\n\\n**Przedmiot potencjalnej akwizycji – 100% udziałów w dwóch spółkach celowych: Farma Wiatrowa Bejsc sp. z o.o. z siedzibą w Warszawie będącej właścicielem projektu FW o łącznej mocy 19,8 MW oraz Bianzone sp. z o.o. z siedzibą w Warszawie będącej właścicielem 3 projektów PV (Rutki 1, Rutki 2 oraz Rutki 3) o łącznej mocy 100,2 MW od spółki OX2 AB (projekt Ruby).**\\n\\nPrzedmiotem potencjalnej akwizycji jest zakup 100% udziałów w dwóch spółkach celowych (dalej jako: „Transakcja”): Farma Wiatrowa Bejsc sp. z o.o. będącej właścicielem projektu FW o łącznej mocy 19,8 MW oraz Bianzone sp. z o.o. będącej właścicielem 3 projektów PV (Rutki 1, Rutki 2 oraz Rutki 3) o łącznej mocy 100,2 MW (projekt Ruby). W ramach projektu Ruby, firma Ernst&Young Corporate Finance – jako doradca OX2 AB (dalej jako: „Sprzedający”) – przekazał do ENEA S.A. ofertę sprzedaży następujących projektów:\\n\\n- Projekt FW o łącznej mocy 19,8 MW należący do spółki celowej Farma Wiatrowa Bejsc sp. z o.o.\\n- Projekty PV (Rutki 1, Rutki 2 oraz Rutki 3) o łącznej mocy 100,2 MW należącym do spółki celowej Bianzone sp. z o.o.\\n\\n--- \\n\\nIf you need further assistance, feel free to ask!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 417, 'prompt_tokens': 14180, 'total_tokens': 14597, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3de1288069', 'finish_reason': 'stop', 'logprobs': None} id='run-8c14b7d1-e3b6-473f-9b99-ae8752a35462-0' usage_metadata={'input_tokens': 14180, 'output_tokens': 417, 'total_tokens': 14597, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke([message])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOoOXCjnE-td"
   },
   "source": [
    "#definiowanie promptów w LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsYzBDiDE93Y",
    "outputId": "a91c9a31-d224-45eb-d501-75d7211544f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'sages_promptsk', 'lc_hub_commit_hash': '39c42568246e6ffc5a3f4d38bc98ed8a519ef52d8b83ea4d981bed733be70838'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Napisz definicję słowa w sposób zrozumiały dla przedszkolaków'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, template='{word}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"sages_promptsk\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWIAYAYCFUC7",
    "outputId": "0b226340-f196-477c-ba7c-f0f4f2c1cfa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain to taki specjalny program, który pomaga komputerom rozmawiać i myśleć jak ludzie. Można go porównać do Misia Uszatka, który zawsze ma ciekawe pomysły i potrafi opowiadać różne historie. LangChain pomaga komputerom tworzyć opowieści i odpowiadać na pytania, tak jak Miś Uszatek rozmawia z dziećmi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 50, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-47b42d16-4908-4401-985d-5b989a6a2942-0', usage_metadata={'input_tokens': 50, 'output_tokens': 93, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "chain.invoke(\"LangChain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_MXriYVF8Bd",
    "outputId": "7b1dd23f-6af1-4fbe-ba82-c441977d5652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'sages_promptsk', 'lc_hub_commit_hash': '9e5499ef41597858a8dc9014782437e88b954024ad5bd9af73e29155ce857b38'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Napisz definicję słowa w sposób zrozumiały dla przedszkolaków\\nW definicji użyj słowa \"Miś Uszatek\"'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, template='{word}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"sages_promptsk\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sKh9qRwHIA9"
   },
   "source": [
    "#zmieniamy runtime type na L4 GPU w NOWYM NOTEBOOKU (nie ma w darmowej wersji)\n",
    "#będziemy ściągać SLM z huggingface\n",
    "!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRrq9GpjHVTd"
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "#model konwertuje tekst na wektory, a następnie output znów jest tekstem, parametr task nam to określa\n",
    "#device=0 to jest wybór karty graficznej\n",
    "#poniższe chwilę trwa\n",
    "#łatwo możemy tutaj podmieniać model\n",
    "model_id=\"HuggingFaceTB/SmolLM2-1.7B\",\n",
    "    task=\"text-generation\",\n",
    "    device=0,\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=128,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Finish the sentence: {text}\")\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke(\"This is a test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBwjSwROI26K"
   },
   "source": [
    "#biblioteka Marvin\n",
    "łatwiejsza inż LC ale nie wiadomo co się środku dzieje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RLuPtTKzF_Ya",
    "outputId": "9e66e845-b817-45e4-d77c-06da5e2fdc26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting marvin\n",
      "  Downloading marvin-2.3.8-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: cachetools>=5 in /usr/local/lib/python3.10/dist-packages (from marvin) (5.5.0)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from marvin) (0.115.5)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from marvin) (0.27.2)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from marvin) (3.1.4)\n",
      "Requirement already satisfied: jsonpatch>=1.33 in /usr/local/lib/python3.10/dist-packages (from marvin) (1.33)\n",
      "Requirement already satisfied: openai>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from marvin) (1.54.4)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.33 in /usr/local/lib/python3.10/dist-packages (from marvin) (3.0.48)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from marvin) (2.9.2)\n",
      "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.10/dist-packages (from marvin) (2.6.1)\n",
      "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.10/dist-packages (from marvin) (13.9.4)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from marvin) (0.8.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from marvin) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from marvin) (4.12.2)\n",
      "Requirement already satisfied: tzdata>=2023.3 in /usr/local/lib/python3.10/dist-packages (from marvin) (2024.2)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from marvin) (0.32.1)\n",
      "Collecting partialjson>=0.0.5 (from marvin)\n",
      "  Downloading partialjson-0.0.8-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->marvin) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->marvin) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->marvin) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->marvin) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->marvin) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->marvin) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.1.2->marvin) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch>=1.33->marvin) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.21.0->marvin) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.21.0->marvin) (0.7.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.21.0->marvin) (4.66.6)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.33->marvin) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->marvin) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->marvin) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->marvin) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->marvin) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->marvin) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->marvin) (2.32.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->marvin) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->marvin) (1.5.4)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->marvin) (0.41.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings->marvin) (1.0.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->marvin) (1.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12->marvin) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken>=0.4.0->marvin) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken>=0.4.0->marvin) (2.2.3)\n",
      "Downloading marvin-2.3.8-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading partialjson-0.0.8-py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: partialjson, marvin\n",
      "Successfully installed marvin-2.3.8 partialjson-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install marvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl9TQFC8KIV_",
    "outputId": "adf53a35-27f4-4f9f-e0a9-498c93637c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings(post_processor_fn=<function default_post_processor_fn at 0x7e1cb1f85090>, provider='openai', openai=OpenAISettings(api_key=None, organization=None, base_url=None, chat=ChatSettings(completions=ChatCompletionSettings(model='gpt-4o', temperature=1.0)), images=ImageSettings(model='dall-e-3', size='1024x1024', response_format='url', style='vivid', quality='standard'), audio=AudioSettings(speech=SpeechSettings(model='tts-1-hd', voice='echo', response_format='mp3', speed=1.0)), assistants=AssistantSettings(model='gpt-4o')), default_client_cls=None, default_async_client_cls=None, ai=AISettings(text=TextAISettings(generate_cache_token_cap=600)), auto_import_beta_modules=True, log_level='INFO', log_verbose=False, max_tool_description_length=1000, max_tool_output_length=150)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import marvin\n",
    "marvin.settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "id": "K5sMc8kvKPnC"
   },
   "outputs": [],
   "source": [
    "marvin.settings.openai.api_key=API_KEY\n",
    "marvin.settings.openai.chat.completions.model='gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i34eQ7KBKkwm",
    "outputId": "19d46d15-dde1-410d-bd7b-5f735d7a2ee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ciastek',\n",
       " 'Makaronik',\n",
       " 'Brownie',\n",
       " 'Tiramisu',\n",
       " 'Snickerdoodle',\n",
       " 'Beza',\n",
       " 'Sernik',\n",
       " 'Trufla',\n",
       " 'Babka',\n",
       " 'Eklerek',\n",
       " 'Piegusek',\n",
       " 'Wafel',\n",
       " 'Rogal',\n",
       " 'Szarlotka',\n",
       " 'Keksik',\n",
       " 'Klusek',\n",
       " 'Muffinka',\n",
       " 'Galaretka',\n",
       " 'Kruchek',\n",
       " 'Torcik']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fajnie zwraca obiekt pythonowy\n",
    "names = marvin.generate(n=20, instructions=\"Wymień 20 imion dla kota nawiązujących do nazw ciasteczek albo ciast\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QJ7XfNxLQbg",
    "outputId": "89444f4e-16ef-4e2b-e18e-0509ecc79012"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I recently had the pleasure of dining at Bangkok Spice, a delightful Thai restaurant where the Khao Soi is simply to die for. The rich, creamy coconut curry with perfectly cooked noodles and tender chicken was a blissful experience that left my taste buds dancing.\\n\\nThe atmosphere of the restaurant was warm and inviting, but what truly made my visit exceptional was the service. Our waiter, Aroon, was attentive and friendly, ensuring that every need was met with a smile. He was knowledgeable about the menu and offered fantastic recommendations, including the highly praised Khao Soi.\\n\\nI also want to extend my compliments to Chef Rung, whose culinary skills are evidently superb. Each dish was crafted with precision and passion, making for a memorable dining experience.\\n\\nI highly recommend Bangkok Spice to anyone craving authentic Thai cuisine, especially if you're a fan of Khao Soi. I will certainly be returning soon!\"]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=marvin.generate(n=1,instructions=\"write a positive review about a thai restaurant where khao soi is delicious. Please mention the waiter and the chef by name\")\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "id": "Xf1IEGWgLsia"
   },
   "outputs": [],
   "source": [
    "names=marvin.extract(review,instructions=\"does the review mention any employees?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RMp44KkgMJGr",
    "outputId": "50ec22ab-ae94-469d-ece4-5e630870ec9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marvin.classify(review,labels=[\"positive\",\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "JJ_BLjtcMtwp"
   },
   "outputs": [],
   "source": [
    "class Restaurant(BaseModel):\n",
    "  restaurant_name:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miQ3IiqRMy0f",
    "outputId": "e6257353-3314-4838-a674-192a90fde65f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant(restaurant_name='Bangkok Spice')"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ponizsze zwraca obiekt pythonowy\n",
    "marvin.cast(review,target=Restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "id": "OGwuoJtwNOsz"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def classify(text: str) -> str:\n",
    "  \"\"\"Classifies a given review as positive or negative\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "id": "1MPMlPGZN6KL"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def extract_name(text: str) -> Restaurant:\n",
    "  \"\"\"Find the restaurant's name in the review\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VnbSUkqQjUR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "P7jHkCiLNcX-",
    "outputId": "c065f8d5-619a-4f38-fe25-b49aed7f7b1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA2SG-bDOAOA",
    "outputId": "73446596-3c13-4a51-f22d-7646c6974b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant(restaurant_name='Bangkok Spice')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_name(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqYVGt22OSoH",
    "outputId": "0d442677-ea73-41f8-cbd7-4c652ff76025"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImagesResponse(created=1732888997, data=[Image(b64_json=None, revised_prompt='A highly agitated Ragdoll cat, characterized by its lush, long fur and striking blue eyes, is intensely staring at the computer screen of a man. With his Slavic facial features, and blonde hair, he is deeply engrossed in typing away on his keyboard, signifying that he is busy programming. The text on the screen indicates that he is using LangGraph, and the entire scene gives off an aura of intense focus and determination.', url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-c0tZPPWsoTQlzKUTXWluFXhA/user-qlTaErXc0XEnvKUULHwOBKec/img-EGYQ5A2UFl6r5p5JXi9cNEi4.png?st=2024-11-29T13%3A03%3A17Z&se=2024-11-29T15%3A03%3A17Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-29T03%3A11%3A10Z&ske=2024-11-30T03%3A11%3A10Z&sks=b&skv=2024-08-04&sig=YcD5cxdWbzImHudrINrNPYdw/8TvlfMIrqUEbKP6Nfw%3D')])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marvin.paint(\"a very angry ragdoll cat looking at the computer of a man with slavic look and blomde hair who is programming using LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8p8VhnIRzpL"
   },
   "source": [
    "# zadanie 5\n",
    "LangGraph --> Marvin\n",
    "Podobnie jak poprzednie zadanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "id": "LBgOeX3fQkXg"
   },
   "outputs": [],
   "source": [
    "DB_DESCRIPTION = \"\"\"The database contains data from the Titanic dataset.\n",
    "\n",
    "* \"survivors\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger\n",
    "Survived - indicates whether the person survived the sinking of the Titanic (1 survived, 0 did not survive)\n",
    "\n",
    "* \"tickets\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger, links to the survivors table\n",
    "Ticket - the ticket number\n",
    "Pclass - the passenger's class. Values 1, 2, 3\n",
    "Fare - the amount of money paid for the ticket\n",
    "Cabin - the cabin number where the passenger stayed\n",
    "Embarked - the port at which the passenger embarked (C: Cherbourg, Q: Queeenstown, S: Southampton)\n",
    "\n",
    "* \"passengers\" table:\n",
    "Columns:\n",
    "PassengerId - a unique identifier of the passenger, links to the survivors table\n",
    "Name - the full name of the passenger\n",
    "Sex - the gender of the passenger (text: male or female)\n",
    "Age - the age of the passenger at the time of the Titanic's accident\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "i66cNTBcQn7n"
   },
   "outputs": [],
   "source": [
    "def run_query(sql_query):\n",
    "  con = sqlite3.connect(\"titanic.db\")\n",
    "  try:\n",
    "    response = pd.read_sql_query(sql_query, con)\n",
    "    return response.to_markdown()\n",
    "  except Exception as e:\n",
    "    return str(e)\n",
    "  finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "58ZOC3m8QqkC"
   },
   "outputs": [],
   "source": [
    "class CanAnswerQuestion(BaseModel):\n",
    "  reasoning: str\n",
    "  can_answer: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "JQobvOcDQsKP"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "# z opisu trzeba usunąc nawiasy klamrowe bo w Marvinie mogą być użyte tylko tam gdzie są zmienne\n",
    "def check_if_question_can_be_answered(DB_description: str, question: str) -> CanAnswerQuestion:\n",
    "  \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "\n",
    "    Given the user's question, decide whether the question can be answered using the information from the database.\n",
    "    Return a JSON object with two keys: resoning, can_answer.\n",
    "\n",
    "    Question: Find the number of people who survived\n",
    "    \"reasoning\": \"I can find the number of people who survived by counting the number of 1 values in the Survived column of the survivors table\", \"can_answer\": true\n",
    "    Question: Count the number of first class passengers who survived\n",
    "    \"reasoning\": \"I can find the number of first class passengers who survived by joining the passenger table with the survivors table and filtering by Survived = 1 and Pclass = 1\", \"can_answer\": true\n",
    "    Question: Count the number of people who traveled in the cabin on the top deck.\n",
    "    \"reasoning\": \"Cabins are not assigned to decks.\", \"can_answer\": false\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "id": "osWI3UFkWHZa"
   },
   "outputs": [],
   "source": [
    "question=\"How many people survived?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cuSKDCQQ9i3",
    "outputId": "b707a0c7-f1e2-49d7-b812-2d9f43faee20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CanAnswerQuestion(reasoning='I can find the number of people who survived by counting the number of 1 values in the Survived column of the survivors table.', can_answer=True)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer=check_if_question_can_be_answered(DB_DESCRIPTION, question)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "id": "Jnl-iJcLUQn3"
   },
   "outputs": [],
   "source": [
    "class WriteQuery(BaseModel):\n",
    "  sqlquery: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "ZxckAfutR9Yy"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "\n",
    "def write_query(DB_DESCRIPTION: str, question: str, answer: str) -> WriteQuery:\n",
    "  \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    In the previous step, a query plan was generated:\n",
    "    {answer}\n",
    "\n",
    "    Use the plan to generate a SQL query to retrieve the data required to answer the user's question.\n",
    "\n",
    "    Return the SQL query with no explanation and no markdown characters.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKTfNAJXV-dQ",
    "outputId": "751f92e7-766e-4ba4-b93f-33045a15473a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WriteQuery(sqlquery='SELECT COUNT(*) FROM survivors WHERE Survived = 1;')"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writequeryresult=write_query(DB_DESCRIPTION, question, answer)\n",
    "# writequeryresult=WriteQuery(sqlquery)\n",
    "writequeryresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-75V1MEfYAqi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "YS3lrkTgWvOC"
   },
   "outputs": [],
   "source": [
    "class ExecuteQuery:\n",
    "  execquery: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkj1ay11WmLu"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "\n",
    "def execute_query(DB_DESCRIPTION: str, question: str, query: WriteQuery) -> ExecuteQuery:\n",
    "  \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    In the previous step, a query of type WriteQuery was generated:\n",
    "    {query}\n",
    "\n",
    "    Execute this query in titanic database adn retrieve the answer\n",
    "\n",
    "    Return the SQL query with no explanation and no markdown characters.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "id": "p7INSK-RXdmk"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "\n",
    "def run_query(sql_query):\n",
    "  con = sqlite3.connect(\"titanic.db\")\n",
    "  try:\n",
    "    response = pd.read_sql_query(sql_query, con)\n",
    "    return response.to_markdown()\n",
    "  except Exception as e:\n",
    "    return str(e)\n",
    "  finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "aHYT-AnvXruT",
    "outputId": "c4af9865-09bb-4a9c-979d-4ed7ec70a8c4"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "sqlquery",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-089608c9b3fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWriteQuery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqlquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprivate_attributes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprivate_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprivate_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: sqlquery"
     ]
    }
   ],
   "source": [
    "run_query(WriteQuery.sqlquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKoJXPIvYUdD"
   },
   "source": [
    "#ponizej modelowe rozwiazanie zadania\n",
    "dużo bardizej przejrzyste niż LangGraph, ale nie ma w ogóle debugu więc na produkcję lepszy będzie LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZYYSV_uadsH"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "# z opisu trzeba usunąc nawiasy klamrowe bo w Marvinie mogą być użyte tylko tam gdzie są zmienne\n",
    "def check_if_question_can_be_answered(DB_description: str, question: str) -> CanAnswerQuestion:\n",
    "  \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "\n",
    "    Given the user's question, decide whether the question can be answered using the information from the database.\n",
    "    Return a JSON object with two keys: resoning, can_answer.\n",
    "\n",
    "    Question: Find the number of people who survived\n",
    "    \"reasoning\": \"I can find the number of people who survived by counting the number of 1 values in the Survived column of the survivors table\", \"can_answer\": true\n",
    "    Question: Count the number of first class passengers who survived\n",
    "    \"reasoning\": \"I can find the number of first class passengers who survived by joining the passenger table with the survivors table and filtering by Survived = 1 and Pclass = 1\", \"can_answer\": true\n",
    "    Question: Count the number of people who traveled in the cabin on the top deck.\n",
    "    \"reasoning\": \"Cabins are not assigned to decks.\", \"can_answer\": false\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "sPkR7VvCYWXS"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def write_sql_query(data_description: str, plan: str, question: str) -> str:\n",
    "  \"\"\"You are a database reading bot that can answer user's question using information from the database.\n",
    "\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    In the previous step, a query plan was generated:\n",
    "    {plan}\n",
    "\n",
    "    Use the plan to generate a SQL query to retrieve the data required to answer the user's question.\n",
    "\n",
    "    Return the SQL query with no explanation and no markdown characters.\n",
    "\n",
    "    Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "doviXT5MaKYB"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def write_answer(data_description: str, plan: str, question: str, answer: str) -> str:\n",
    "  \"\"\"\n",
    "    Database description:\n",
    "    {data_description}\n",
    "\n",
    "    Based on the result of query plan and of result of sql query, please provide to the user a descriptive answer to his question\n",
    "    question.\n",
    "\n",
    "    Plan: {plan}\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "sYNsPcR1aNRy"
   },
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def explain_why_cannot_answer(problem: str, question: str) -> str:\n",
    "  \"\"\"You cannot answer the user's question because of the following problem: {problem}\n",
    "\n",
    "    Explain the issue and apologize.\n",
    "\n",
    "    Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "x94pdmDDaR9B"
   },
   "outputs": [],
   "source": [
    "def answer_user_question(question: str) -> str:\n",
    "  can_answer = check_if_question_can_be_answered(DB_DESCRIPTION, question)\n",
    "\n",
    "  if can_answer.can_answer:\n",
    "    sql_query = write_sql_query(DB_DESCRIPTION, can_answer.reasoning, question)\n",
    "    sql_result = run_query(sql_query)\n",
    "    return write_answer(DB_DESCRIPTION, can_answer.reasoning, question, sql_result)\n",
    "  else:\n",
    "    return explain_why_cannot_answer(can_answer.reasoning, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xdDNLJEZaVAa",
    "outputId": "8886e912-1fd5-46c6-a758-e9b04bc46736"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'According to the database description, we have data from the Titanic dataset involving survivors, tickets, and passengers. To answer the user\\'s question about the number of survivors, the query plan was to utilize the \"survivors\" table and count the entries where the value in the \"Survived\" column is 1, indicating survival. Based on this plan, the result of the query determined that 342 people survived the sinking of the Titanic. Therefore, the number of survivors is 342.'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_user_question(\"Count the number of people who survived\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BVjTwytxR46W"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
